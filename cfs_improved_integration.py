#!/usr/bin/env python3
"""
æ”¹å–„ç‰ˆæ–¹å‘ãƒ”ãƒ¼ã‚¹ç”Ÿæˆã®CFS-Chameleonçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®æ„å‘³çš„æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’CFSã‚·ã‚¹ãƒ†ãƒ ã«çµ±åˆ
"""

import numpy as np
import torch
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
import logging
from improved_direction_pieces_generator import generate_improved_direction_pieces, DirectionPiece

# æ—¢å­˜CFS-Chameleonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from chameleon_cfs_integrator import CollaborativeChameleonEditor
    from cfs_chameleon_extension import CollaborativeDirectionPool, DirectionPiece as CFSDirectionPiece
    CFS_AVAILABLE = True
except ImportError:
    logger.warning("CFS-Chameleon modules not available, using mock implementations")
    CFS_AVAILABLE = False

logger = logging.getLogger(__name__)

class ImprovedCFSChameleonEditor(CollaborativeChameleonEditor if CFS_AVAILABLE else object):
    """
    æ”¹å–„ç‰ˆæ–¹å‘ãƒ”ãƒ¼ã‚¹ç”Ÿæˆã‚’çµ±åˆã—ãŸCFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
    """
    
    def __init__(self, 
                 model_name: str = "meta-llama/Llama-3.2-3B-Instruct",
                 device: str = "cuda",
                 use_collaboration: bool = True,
                 config_path: str = None,
                 enable_improved_pieces: bool = True):
        """
        æ”¹å–„ç‰ˆCFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        
        Args:
            model_name: ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«å
            device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
            use_collaboration: å”èª¿æ©Ÿèƒ½ä½¿ç”¨ãƒ•ãƒ©ã‚°
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            enable_improved_pieces: æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ç”Ÿæˆä½¿ç”¨ãƒ•ãƒ©ã‚°
        """
        
        if CFS_AVAILABLE:
            # æ—¢å­˜ã®CFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
            super().__init__(
                model_name=model_name,
                device=device,
                use_collaboration=use_collaboration,
                config_path=config_path
            )
        
        self.enable_improved_pieces = enable_improved_pieces
        self.improved_pieces_cache = {}  # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥æ”¹å–„ãƒ”ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        logger.info(f"âœ… ImprovedCFSChameleonEditor initialized")
        logger.info(f"   Improved pieces: {'enabled' if enable_improved_pieces else 'disabled'}")
        
    def add_user_history_to_pool(self, 
                                user_id: str, 
                                history_texts: List[str],
                                neutral_reference: str = "ã“ã‚Œã¯ä¸€èˆ¬çš„ãªæ–‡ç« ã§ã™",
                                rank_reduction: int = 16) -> bool:
        """
        æ”¹å–„ç‰ˆæ–¹å‘ãƒ”ãƒ¼ã‚¹ç”Ÿæˆã§ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‚’ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            history_texts: ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ
            neutral_reference: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«å‚ç…§ãƒ†ã‚­ã‚¹ãƒˆ
            rank_reduction: SVDåˆ†è§£ãƒ©ãƒ³ã‚¯å‰Šæ¸›æ•°
            
        Returns:
            è¿½åŠ æˆåŠŸã‹ã©ã†ã‹
        """
        if not self.enable_improved_pieces or not self.use_collaboration:
            logger.warning("Improved pieces or collaboration not enabled")
            return False
        
        try:
            logger.info(f"ğŸ”„ Generating improved direction pieces for user {user_id}")
            
            # æ”¹å–„ç‰ˆæ–¹å‘ãƒ”ãƒ¼ã‚¹ç”Ÿæˆ
            pieces_data = generate_improved_direction_pieces(
                user_history_texts=history_texts,
                neutral_reference_text=neutral_reference,
                rank_reduction=rank_reduction
            )
            
            if not pieces_data:
                logger.error(f"âŒ No pieces generated for user {user_id}")
                return False
            
            # CFSæ–¹å‘ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
            added_count = 0
            for piece_data in pieces_data:
                if self._add_improved_piece_to_pool(user_id, piece_data):
                    added_count += 1
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self.improved_pieces_cache[user_id] = pieces_data
            
            logger.info(f"âœ… Added {added_count}/{len(pieces_data)} improved pieces for user {user_id}")
            return added_count > 0
            
        except Exception as e:
            logger.error(f"âŒ Failed to add improved pieces for user {user_id}: {e}")
            return False
    
    def _add_improved_piece_to_pool(self, user_id: str, piece_data: Dict[str, Any]) -> bool:
        """
        æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’CFSæ–¹å‘ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            piece_data: æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
            
        Returns:
            è¿½åŠ æˆåŠŸã‹ã©ã†ã‹
        """
        if not CFS_AVAILABLE or not hasattr(self, 'direction_pool'):
            return False
        
        try:
            # Væˆåˆ†ï¼ˆå³ç‰¹ç•°ãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã‚’æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã¨ã—ã¦ä½¿ç”¨
            direction_vector = np.array(piece_data['v_component'])
            
            # CFSDirectionPieceã«å¤‰æ›
            cfs_piece = CFSDirectionPiece(
                vector=direction_vector,
                user_id=user_id,
                semantic_tags=[piece_data['semantic_context']],
                usage_count=0,
                quality_score=piece_data['quality_score'],
                creation_time=piece_data['creation_timestamp'],
                context_embedding=direction_vector[:min(len(direction_vector), 768)]  # é©åˆ‡ãªæ¬¡å…ƒã«èª¿æ•´
            )
            
            # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ãƒã‚¤ã‚ºé©ç”¨
            if hasattr(self, 'collaboration_config'):
                noise_std = self.collaboration_config.get('privacy_noise_std', 0.01)
                if noise_std > 0:
                    noise = np.random.normal(0, noise_std, cfs_piece.vector.shape)
                    cfs_piece.vector = cfs_piece.vector + noise
                    cfs_piece.vector = cfs_piece.vector / (np.linalg.norm(cfs_piece.vector) + 1e-8)
            
            # ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
            self.direction_pool.pieces.append(cfs_piece)
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒƒãƒ”ãƒ³ã‚°æ›´æ–°
            if user_id not in self.direction_pool.user_mapping:
                self.direction_pool.user_mapping[user_id] = []
            self.direction_pool.user_mapping[user_id].append(len(self.direction_pool.pieces) - 1)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ Failed to add piece to pool: {e}")
            return False
    
    def generate_with_improved_collaboration(self, 
                                           prompt: str, 
                                           user_id: str,
                                           user_history: Optional[List[str]] = None,
                                           alpha_personal: float = 0.1,
                                           alpha_neutral: float = -0.05,
                                           target_layers: List[str] = None,
                                           max_length: int = 100) -> str:
        """
        æ”¹å–„ç‰ˆå”èª¿æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            user_history: ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ï¼ˆæŒ‡å®šæ™‚ã¯å‹•çš„ãƒ”ãƒ¼ã‚¹ç”Ÿæˆï¼‰
            alpha_personal: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦
            alpha_neutral: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦
            target_layers: ç·¨é›†å¯¾è±¡å±¤
            max_length: æœ€å¤§ç”Ÿæˆé•·
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ãŒæä¾›ã•ã‚ŒãŸå ´åˆã€å‹•çš„ã«ãƒ”ãƒ¼ã‚¹ç”Ÿæˆ
            if user_history and self.enable_improved_pieces:
                logger.info(f"ğŸ”„ Dynamic improved pieces generation for user {user_id}")
                self.add_user_history_to_pool(user_id, user_history)
            
            # æ—¢å­˜ã®CFS-Chameleonç”Ÿæˆã‚’ä½¿ç”¨
            if CFS_AVAILABLE and hasattr(super(), 'generate_with_collaborative_chameleon'):
                return super().generate_with_collaborative_chameleon(
                    prompt=prompt,
                    user_id=user_id,
                    alpha_personal=alpha_personal,
                    alpha_neutral=alpha_neutral,
                    target_layers=target_layers or ["model.layers.16.mlp"],
                    max_length=max_length
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬ç”Ÿæˆ
                return self.generate_with_chameleon(
                    prompt=prompt,
                    alpha_personal=alpha_personal,
                    alpha_neutral=alpha_neutral,
                    target_layers=target_layers or ["model.layers.16.mlp"],
                    max_length=max_length
                )
                
        except Exception as e:
            logger.error(f"âŒ Improved collaboration generation error: {e}")
            return f"Error in generation: {e}"
    
    def analyze_improved_pieces_quality(self, user_id: str) -> Dict[str, Any]:
        """
        æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ã®å“è³ªåˆ†æ
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            
        Returns:
            å“è³ªåˆ†æçµæœ
        """
        if user_id not in self.improved_pieces_cache:
            return {"error": "No improved pieces found for user"}
        
        pieces = self.improved_pieces_cache[user_id]
        
        # çµ±è¨ˆè¨ˆç®—
        singular_values = [p['singular_value'] for p in pieces]
        importance_scores = [p['importance'] for p in pieces]
        quality_scores = [p['quality_score'] for p in pieces]
        
        analysis = {
            "user_id": user_id,
            "total_pieces": len(pieces),
            "singular_values": {
                "mean": np.mean(singular_values),
                "std": np.std(singular_values),
                "max": np.max(singular_values),
                "min": np.min(singular_values)
            },
            "importance_distribution": {
                "mean": np.mean(importance_scores),
                "std": np.std(importance_scores),
                "cumulative_top3": sum(sorted(importance_scores, reverse=True)[:3])
            },
            "quality_metrics": {
                "average_quality": np.mean(quality_scores),
                "high_quality_count": sum(1 for q in quality_scores if q > 0.1),
                "quality_variance": np.var(quality_scores)
            },
            "semantic_diversity": len(set(p['semantic_context'] for p in pieces))
        }
        
        return analysis
    
    def save_improved_pieces_cache(self, filepath: str):
        """æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(self.improved_pieces_cache, f, indent=2, ensure_ascii=False)
            logger.info(f"âœ… Improved pieces cache saved to {filepath}")
        except Exception as e:
            logger.error(f"âŒ Failed to save cache: {e}")
    
    def load_improved_pieces_cache(self, filepath: str):
        """æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿"""
        try:
            if Path(filepath).exists():
                with open(filepath, 'r', encoding='utf-8') as f:
                    self.improved_pieces_cache = json.load(f)
                logger.info(f"âœ… Improved pieces cache loaded from {filepath}")
            else:
                logger.warning(f"âš ï¸ Cache file not found: {filepath}")
        except Exception as e:
            logger.error(f"âŒ Failed to load cache: {e}")

def demo_improved_cfs_integration():
    """æ”¹å–„ç‰ˆCFSçµ±åˆã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸ¦ æ”¹å–„ç‰ˆCFS-Chameleonçµ±åˆãƒ‡ãƒ¢")
    print("="*60)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿
    user_histories = {
        "user_1": [
            "ä»Šæ—¥ã¯ç´ æ™´ã‚‰ã—ã„æ˜ ç”»ã‚’è¦‹ã¾ã—ãŸ",
            "SFæ˜ ç”»ãŒå¤§å¥½ãã§ã€ç‰¹ã«ã‚¿ã‚¤ãƒ ãƒˆãƒ©ãƒ™ãƒ«ç³»ãŒèˆˆå‘³æ·±ã„ã§ã™",
            "æ˜ ç”»é¤¨ã§ã®ä½“é¨“ã¯å®¶ã§è¦‹ã‚‹ã®ã¨ã¯å…¨ãé•ã„ã¾ã™",
            "å‹é”ã¨æ˜ ç”»ã«ã¤ã„ã¦èªã‚Šåˆã†ã®ãŒæ¥½ã—ã„ã§ã™"
        ],
        "user_2": [
            "æ–™ç†ã‚’ã™ã‚‹ã®ãŒè¶£å‘³ã§ã€æ–°ã—ã„ãƒ¬ã‚·ãƒ”ã«æŒ‘æˆ¦ã—ã¦ã„ã¾ã™",
            "ç‰¹ã«å’Œé£Ÿã®å¥¥æ·±ã•ã«é­…åŠ›ã‚’æ„Ÿã˜ã¦ã„ã¾ã™",
            "å­£ç¯€ã®é£Ÿæã‚’ä½¿ã£ãŸæ–™ç†ãŒå¥½ãã§ã™",
            "æ–™ç†ã‚’é€šã˜ã¦å®¶æ—ã¨ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãŒæ·±ã¾ã‚Šã¾ã™"
        ]
    }
    
    try:
        # æ”¹å–„ç‰ˆã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        editor = ImprovedCFSChameleonEditor(
            use_collaboration=True,
            enable_improved_pieces=True
        )
        
        # å„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å±¥æ­´ã‚’å‡¦ç†
        for user_id, history in user_histories.items():
            print(f"\nğŸ‘¤ å‡¦ç†ä¸­: {user_id}")
            
            # æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ç”Ÿæˆã¨ãƒ—ãƒ¼ãƒ«è¿½åŠ 
            success = editor.add_user_history_to_pool(
                user_id=user_id,
                history_texts=history,
                neutral_reference="ã“ã‚Œã¯ä¸€èˆ¬çš„ãªå†…å®¹ã§ã™",
                rank_reduction=8
            )
            
            if success:
                print(f"âœ… {user_id}ã®æ”¹å–„ç‰ˆãƒ”ãƒ¼ã‚¹ç”Ÿæˆå®Œäº†")
                
                # å“è³ªåˆ†æ
                analysis = editor.analyze_improved_pieces_quality(user_id)
                print(f"ğŸ“Š å“è³ªåˆ†æ:")
                print(f"   ç·ãƒ”ãƒ¼ã‚¹æ•°: {analysis['total_pieces']}")
                print(f"   å¹³å‡é‡è¦åº¦: {analysis['importance_distribution']['mean']:.4f}")
                print(f"   å¹³å‡å“è³ª: {analysis['quality_metrics']['average_quality']:.4f}")
                print(f"   æ„å‘³çš„å¤šæ§˜æ€§: {analysis['semantic_diversity']}")
                
                # æ”¹å–„ç‰ˆå”èª¿ç”Ÿæˆãƒ†ã‚¹ãƒˆ
                test_prompt = "ãŠã™ã™ã‚ã‚’æ•™ãˆã¦ãã ã•ã„"
                result = editor.generate_with_improved_collaboration(
                    prompt=test_prompt,
                    user_id=user_id,
                    alpha_personal=0.1,
                    max_length=50
                )
                print(f"ğŸ”® ç”Ÿæˆçµæœ: {result[:100]}...")
            else:
                print(f"âŒ {user_id}ã®ãƒ”ãƒ¼ã‚¹ç”Ÿæˆã«å¤±æ•—")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        cache_path = "improved_cfs_pieces_cache.json"
        editor.save_improved_pieces_cache(cache_path)
        print(f"\nğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {cache_path}")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Demo execution error: {e}")
    
    print("\nğŸ‰ æ”¹å–„ç‰ˆCFSçµ±åˆãƒ‡ãƒ¢å®Œäº†!")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    demo_improved_cfs_integration()