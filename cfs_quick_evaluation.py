#!/usr/bin/env python3
"""
CFS-Chameleoné‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿çµ„ã¿åˆã‚ã›è©•ä¾¡
åŠ¹ç‡çš„ãªè©•ä¾¡ã®ãŸã‚æ¡ä»¶ã‚’çµã‚Šè¾¼ã¿
"""

import subprocess
import json
import time
import pandas as pd
from pathlib import Path
from typing import List, Dict, Any
import logging
import os

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_single_evaluation(hook_layer: str, alpha_p: float, rank_reduction: int) -> Dict[str, Any]:
    """å˜ä¸€æ¡ä»¶ã§ã®è©•ä¾¡å®Ÿè¡Œ"""
    logger.info(f"ğŸ”„ å®Ÿé¨“: hook={hook_layer}, Î±_p={alpha_p}, rank={rank_reduction}")
    
    # ã‚³ãƒãƒ³ãƒ‰æ§‹ç¯‰
    cmd = [
        "python", "lampqa_cfs_benchmark.py",
        "--compare_modes",
        "--use_collaboration", 
        f"--config=cfs_config.yaml",
        f"--hook_layer={hook_layer}",
        f"--alpha_p={alpha_p}",
        f"--alpha_g=-0.05",
        f"--rank_reduction={rank_reduction}"
    ]
    
    try:
        # è©•ä¾¡å®Ÿè¡Œ
        start_time = time.time()
        env = dict(os.environ)
        env["CUDA_VISIBLE_DEVICES"] = "0"
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=600,  # 10åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            shell=False,
            env=env
        )
        execution_time = time.time() - start_time
        
        if result.returncode != 0:
            logger.error(f"âŒ Command failed: {result.stderr}")
            raise subprocess.CalledProcessError(result.returncode, cmd, result.stdout, result.stderr)
        
        # æœ€æ–°çµæœãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
        results_dir = Path("lampqa_evaluation_results")
        if not results_dir.exists():
            raise FileNotFoundError("Results directory not found")
        
        latest_result_file = max(results_dir.glob("lampqa_comparison_*.json"), key=lambda x: x.stat().st_mtime)
        
        with open(latest_result_file, 'r') as f:
            evaluation_data = json.load(f)
        
        # çµæœæŠ½å‡º
        legacy = evaluation_data.get("legacy_chameleon", {})
        cfs = evaluation_data.get("cfs_chameleon", {})
        improvements = evaluation_data.get("improvement_metrics", {})
        significance = evaluation_data.get("statistical_significance", {})
        
        result_data = {
            # å®Ÿé¨“æ¡ä»¶
            "hook_layer": hook_layer,
            "alpha_p": alpha_p,
            "rank_reduction": rank_reduction,
            "execution_time_total": round(execution_time, 2),
            
            # Legacy Chameleonçµæœ
            "legacy_rouge_l": round(legacy.get("rouge_l", 0.0), 4),
            "legacy_bleu": round(legacy.get("bleu_score", 0.0), 4),
            "legacy_bert_score": round(legacy.get("bert_score_f1", 0.0), 4),
            "legacy_inference_time": round(legacy.get("inference_time", 0.0), 4),
            
            # CFS-Chameleonçµæœ
            "cfs_rouge_l": round(cfs.get("rouge_l", 0.0), 4),
            "cfs_bleu": round(cfs.get("bleu_score", 0.0), 4),
            "cfs_bert_score": round(cfs.get("bert_score_f1", 0.0), 4),
            "cfs_inference_time": round(cfs.get("inference_time", 0.0), 4),
            "cfs_pool_utilization": round(cfs.get("pool_utilization", 0.0) * 100, 2),  # %è¡¨ç¤º
            
            # æ”¹å–„æŒ‡æ¨™
            "rouge_l_improvement": round(improvements.get("rouge_l_improvement", 0.0), 4),
            "bleu_improvement": round(improvements.get("bleu_improvement", 0.0), 4),
            "bert_improvement": round(improvements.get("bert_improvement", 0.0), 4),
            "speed_improvement": round(improvements.get("speed_improvement", 0.0), 4),
            
            # çµ±è¨ˆçš„æœ‰æ„æ€§
            "p_value": round(significance.get("p_value", 1.0), 6),
            "is_significant": significance.get("is_significant", False),
            
            # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
            "status": "SUCCESS"
        }
        
        logger.info(f"âœ… å®Ÿé¨“å®Œäº†: ROUGE-L={result_data['cfs_rouge_l']}, BLEU={result_data['cfs_bleu']}, BERTScore={result_data['cfs_bert_score']}")
        return result_data
        
    except subprocess.TimeoutExpired:
        logger.error(f"âŒ å®Ÿé¨“ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {hook_layer}, Î±_p={alpha_p}, rank={rank_reduction}")
        return {"status": "TIMEOUT", "hook_layer": hook_layer, "alpha_p": alpha_p, "rank_reduction": rank_reduction}
        
    except Exception as e:
        logger.error(f"âŒ å®Ÿé¨“ã‚¨ãƒ©ãƒ¼: {hook_layer}, Î±_p={alpha_p}, rank={rank_reduction} - {e}")
        return {"status": "ERROR", "hook_layer": hook_layer, "alpha_p": alpha_p, "rank_reduction": rank_reduction}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    # é‡è¦ãªæ¡ä»¶ã®ã¿ã«çµã‚Šè¾¼ã¿ï¼ˆ16æ¡ä»¶ï¼‰
    conditions = [
        # Hook Layer 14 (config default)
        ("model.layers.14.mlp", 0.05, 16),
        ("model.layers.14.mlp", 0.1, 16),
        ("model.layers.14.mlp", 0.2, 16),
        ("model.layers.14.mlp", 0.3, 16),
        
        # Hook Layer 16 (ä¸­é–“å±¤)
        ("model.layers.16.mlp", 0.05, 16),
        ("model.layers.16.mlp", 0.1, 16),
        ("model.layers.16.mlp", 0.2, 16),
        ("model.layers.16.mlp", 0.3, 16),
        
        # Hook Layer 18 (æ·±ã„å±¤)
        ("model.layers.18.mlp", 0.05, 16),
        ("model.layers.18.mlp", 0.1, 16),
        ("model.layers.18.mlp", 0.2, 16),
        ("model.layers.18.mlp", 0.3, 16),
        
        # Rank Reduction ã®å½±éŸ¿ç¢ºèªï¼ˆLayer 16, Alpha 0.1å›ºå®šï¼‰
        ("model.layers.16.mlp", 0.1, 8),
        ("model.layers.16.mlp", 0.1, 32),
        
        # æ¥µå€¤ç¢ºèª
        ("model.layers.16.mlp", 0.01, 16),  # éå¸¸ã«å°ã•ã„Alpha
        ("model.layers.16.mlp", 0.5, 16),   # å¤§ããªAlpha
    ]
    
    logger.info(f"ğŸ§ª CFS-Chameleoné‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©•ä¾¡é–‹å§‹")
    logger.info(f"ğŸ“Š ç·å®Ÿé¨“æ¡ä»¶æ•°: {len(conditions)}")
    
    results = []
    total_start_time = time.time()
    
    for i, (hook_layer, alpha_p, rank_reduction) in enumerate(conditions, 1):
        logger.info(f"ğŸ“ˆ é€²æ—: {i}/{len(conditions)} ({i/len(conditions)*100:.1f}%)")
        
        result = run_single_evaluation(hook_layer, alpha_p, rank_reduction)
        results.append(result)
        
        # é€”ä¸­çµŒéè¡¨ç¤º
        if i % 4 == 0:
            elapsed = time.time() - total_start_time
            remaining = (elapsed / i) * (len(conditions) - i)
            logger.info(f"â±ï¸  çµŒéæ™‚é–“: {elapsed/60:.1f}åˆ†, æ¨å®šæ®‹ã‚Šæ™‚é–“: {remaining/60:.1f}åˆ†")
    
    total_execution_time = time.time() - total_start_time
    logger.info(f"ğŸ‰ å…¨å®Ÿé¨“å®Œäº†! ç·å®Ÿè¡Œæ™‚é–“: {total_execution_time/60:.1f}åˆ†")
    
    # çµæœä¿å­˜
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # DataFrameä½œæˆï¼ˆæˆåŠŸã—ãŸå®Ÿé¨“ã®ã¿ï¼‰
    success_results = [r for r in results if r.get("status") == "SUCCESS"]
    
    if success_results:
        df = pd.DataFrame(success_results)
        
        # CSVä¿å­˜
        csv_path = f"cfs_quick_evaluation_{timestamp}.csv"
        df.to_csv(csv_path, index=False)
        logger.info(f"ğŸ“ çµæœä¿å­˜: {csv_path}")
        
        # çµæœåˆ†æ
        print("\n" + "="*80)
        print("ğŸ¯ CFS-CHAMELEONé‡è¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è©•ä¾¡çµæœ")
        print("="*80)
        
        # å„æŒ‡æ¨™ã§ã®æœ€è‰¯æ¡ä»¶
        best_rouge_l = df.loc[df['cfs_rouge_l'].idxmax()]
        best_bleu = df.loc[df['cfs_bleu'].idxmax()]
        best_bert_score = df.loc[df['cfs_bert_score'].idxmax()]
        
        print(f"\nğŸ† å„æŒ‡æ¨™ã§ã®æœ€è‰¯æ¡ä»¶:")
        print(f"ROUGE-Læœ€é«˜å€¤: {best_rouge_l['cfs_rouge_l']:.4f}")
        print(f"  æ¡ä»¶: hook={best_rouge_l['hook_layer']}, Î±_p={best_rouge_l['alpha_p']}, rank={best_rouge_l['rank_reduction']}")
        
        print(f"BLEUæœ€é«˜å€¤: {best_bleu['cfs_bleu']:.4f}")
        print(f"  æ¡ä»¶: hook={best_bleu['hook_layer']}, Î±_p={best_bleu['alpha_p']}, rank={best_bleu['rank_reduction']}")
        
        print(f"BERTScoreæœ€é«˜å€¤: {best_bert_score['cfs_bert_score']:.4f}")
        print(f"  æ¡ä»¶: hook={best_bert_score['hook_layer']}, Î±_p={best_bert_score['alpha_p']}, rank={best_bert_score['rank_reduction']}")
        
        # ç·åˆã‚¹ã‚³ã‚¢
        df['total_improvement'] = (df['rouge_l_improvement'] + df['bleu_improvement'] + df['bert_improvement']) / 3
        best_overall = df.loc[df['total_improvement'].idxmax()]
        
        print(f"\nğŸ¯ ç·åˆæœ€é©æ¡ä»¶:")
        print(f"  Hook Layer: {best_overall['hook_layer']}")
        print(f"  Alpha Personal: {best_overall['alpha_p']}")
        print(f"  Rank Reduction: {best_overall['rank_reduction']}")
        print(f"  å¹³å‡æ”¹å–„ç‡: {best_overall['total_improvement']:.4f}%")
        print(f"  ROUGE-L: {best_overall['cfs_rouge_l']:.4f}")
        print(f"  BLEU: {best_overall['cfs_bleu']:.4f}") 
        print(f"  BERTScore: {best_overall['cfs_bert_score']:.4f}")
        print(f"  æ¨è«–æ™‚é–“: {best_overall['cfs_inference_time']:.4f}ç§’")
        print(f"  ãƒ—ãƒ¼ãƒ«åˆ©ç”¨ç‡: {best_overall['cfs_pool_utilization']:.2f}%")
        
        # è©³ç´°è¡¨
        print(f"\nğŸ“Š è©³ç´°çµæœè¡¨:")
        display_columns = ['hook_layer', 'alpha_p', 'rank_reduction', 'cfs_rouge_l', 'cfs_bleu', 'cfs_bert_score', 'cfs_inference_time', 'cfs_pool_utilization']
        print(df[display_columns].to_string(index=False, float_format=lambda x: f'{x:.4f}' if isinstance(x, float) else str(x)))
        
        print("="*80)
        
    else:
        logger.error("âŒ æˆåŠŸã—ãŸå®Ÿé¨“ãŒã‚ã‚Šã¾ã›ã‚“")
        # ã‚¨ãƒ©ãƒ¼çµæœã‚‚ä¿å­˜
        error_df = pd.DataFrame(results)
        error_csv = f"cfs_evaluation_errors_{timestamp}.csv"
        error_df.to_csv(error_csv, index=False)
        logger.info(f"ğŸ“ ã‚¨ãƒ©ãƒ¼çµæœä¿å­˜: {error_csv}")

if __name__ == "__main__":
    main()