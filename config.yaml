chameleon:
  alpha_personal: 1.5
  alpha_general: -0.8
  num_self_generated: 10
  target_layers:
  - model.layers.20
  - model.layers.22
data_sources:
  answers_backup: data/raw/LaMP_all/LaMP_2/user-based/dev/dev_outputs.json
  answers_primary: chameleon_prime_personalization/data/raw/LaMP-2/answers.json
  backup: data/raw/LaMP_all/LaMP_2/user-based/dev/dev_questions.json
  primary: chameleon_prime_personalization/data/raw/LaMP-2/merged.json
evaluation:
  max_users: 20
  metrics:
  - exact_match
  - bleu_score
  save_predictions: true
model:
  batch_size: 4
  device: cuda
  max_length: 512
  name: meta-llama/Llama-3.2-3B-Instruct
  torch_dtype: float32
