#!/usr/bin/env python3
"""
é©å¿œçš„ãƒ”ãƒ¼ã‚¹çµ±åˆã®CFS-Chameleonå®Œå…¨çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å››å¤§æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
"""

import numpy as np
import torch
from typing import List, Dict, Any, Optional, Tuple, Callable, Union
import logging
import time
import json
from pathlib import Path
from dataclasses import dataclass

# å››å¤§æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ 
from adaptive_piece_fusion import (
    fuse_pieces_adaptive,
    AdaptiveFusionConfig,
    AdaptiveFusionChameleonEditor
)
from task_based_quality_evaluator import (
    TaskBasedQualityEvaluator,
    calculate_improved_quality_score
)
from semantic_similarity_engine import (
    SemanticSimilarityEngine,
    compute_semantic_similarity_rich
)
from dual_direction_cfs_integration import (
    DualDirectionPool,
    DualDirectionChameleonEditor
)

# CFS-Chameleoné–¢é€£ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from cfs_chameleon_extension import DirectionPiece, CollaborativeDirectionPool
    from chameleon_cfs_integrator import CollaborativeChameleonEditor
    CFS_AVAILABLE = True
except ImportError:
    print("âš ï¸ CFS modules not available. Using mock implementations.")
    CFS_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class IntegratedChameleonConfig:
    """çµ±åˆChameleonã‚·ã‚¹ãƒ†ãƒ è¨­å®š"""
    # é©å¿œçš„çµ±åˆè¨­å®š
    adaptive_fusion_config: AdaptiveFusionConfig = None
    
    # æ„å‘³çš„é¡ä¼¼åº¦è¨­å®š
    use_semantic_similarity: bool = True
    semantic_threshold: float = 0.3
    
    # ã‚¿ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹å“è³ªè©•ä¾¡è¨­å®š
    use_quality_evaluation: bool = True
    quality_threshold: float = 0.5
    
    # åŒæ–¹å‘ãƒ”ãƒ¼ã‚¹è¨­å®š
    use_dual_direction: bool = True
    personal_weight: float = 1.0
    neutral_weight: float = -0.5
    
    # çµ±åˆæˆ¦ç•¥
    integration_strategy: str = "full"  # full, adaptive_only, quality_only, semantic_only
    
    def __post_init__(self):
        if self.adaptive_fusion_config is None:
            self.adaptive_fusion_config = AdaptiveFusionConfig()

class IntegratedChameleonSystem:
    """å››å¤§æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ çµ±åˆChameleonã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config: IntegratedChameleonConfig = None):
        """
        åˆæœŸåŒ–
        
        Args:
            config: çµ±åˆã‚·ã‚¹ãƒ†ãƒ è¨­å®š
        """
        self.config = config or IntegratedChameleonConfig()
        
        # å„ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self._initialize_subsystems()
        
        logger.info("âœ… IntegratedChameleonSystem initialized")
        logger.info(f"   Integration strategy: {self.config.integration_strategy}")
        logger.info(f"   Semantic similarity: {self.config.use_semantic_similarity}")
        logger.info(f"   Quality evaluation: {self.config.use_quality_evaluation}")
        logger.info(f"   Dual direction: {self.config.use_dual_direction}")
    
    def _initialize_subsystems(self):
        """ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        # 1. é©å¿œçš„çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
        self.adaptive_fusion_editor = AdaptiveFusionChameleonEditor(
            fusion_config=self.config.adaptive_fusion_config
        )
        
        # 2. ã‚¿ã‚¹ã‚¯ãƒ™ãƒ¼ã‚¹å“è³ªè©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
        if self.config.use_quality_evaluation:
            self.quality_evaluator = TaskBasedQualityEvaluator()
        else:
            self.quality_evaluator = None
        
        # 3. æ„å‘³çš„é¡ä¼¼åº¦ã‚·ã‚¹ãƒ†ãƒ 
        if self.config.use_semantic_similarity:
            self.semantic_engine = SemanticSimilarityEngine()
        else:
            self.semantic_engine = None
        
        # 4. åŒæ–¹å‘ãƒ”ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ 
        if self.config.use_dual_direction:
            self.dual_direction_editor = DualDirectionChameleonEditor()
        else:
            self.dual_direction_editor = None
        
        logger.info("âœ… All subsystems initialized")
    
    def select_and_fuse_pieces_integrated(self,
                                        user_context: str,
                                        available_pieces: List[Any],
                                        eval_dataset: List[Tuple[str, str]],
                                        user_id: str = None,
                                        top_k: int = 5) -> np.ndarray:
        """
        çµ±åˆçš„ãƒ”ãƒ¼ã‚¹é¸æŠãƒ»èåˆ
        
        Args:
            user_context: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            available_pieces: åˆ©ç”¨å¯èƒ½ãªãƒ”ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
            eval_dataset: è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            top_k: é¸æŠã™ã‚‹ãƒ”ãƒ¼ã‚¹æ•°
            
        Returns:
            èåˆã•ã‚ŒãŸæ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
        """
        logger.info(f"ğŸ¦ Integrated piece selection and fusion")
        logger.info(f"   Available pieces: {len(available_pieces)}")
        logger.info(f"   Strategy: {self.config.integration_strategy}")
        
        selected_pieces = []
        
        try:
            if self.config.integration_strategy == "full":
                # å®Œå…¨çµ±åˆæˆ¦ç•¥
                selected_pieces = self._full_integration_selection(
                    user_context, available_pieces, eval_dataset, user_id, top_k
                )
                
            elif self.config.integration_strategy == "adaptive_only":
                # é©å¿œçš„çµ±åˆã®ã¿
                selected_pieces = available_pieces[:top_k]
                
            elif self.config.integration_strategy == "quality_only":
                # å“è³ªè©•ä¾¡ãƒ™ãƒ¼ã‚¹é¸æŠã®ã¿
                selected_pieces = self._quality_based_selection(
                    available_pieces, eval_dataset, top_k
                )
                
            elif self.config.integration_strategy == "semantic_only":
                # æ„å‘³çš„é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹é¸æŠã®ã¿
                selected_pieces = self._semantic_based_selection(
                    user_context, available_pieces, top_k
                )
            
            logger.info(f"âœ… Selected {len(selected_pieces)} pieces for fusion")
            
            # é©å¿œçš„çµ±åˆå®Ÿè¡Œ
            if selected_pieces:
                def mock_generate_with_piece(prompt: str, piece: Any) -> str:
                    piece_id = getattr(piece, 'piece_id', str(id(piece))[:8])
                    return f"Generated for '{prompt[:20]}...' using {piece_id}"
                
                fused_vector = fuse_pieces_adaptive(
                    pieces=selected_pieces,
                    eval_dataset=eval_dataset,
                    generate_with_piece=mock_generate_with_piece,
                    config=self.config.adaptive_fusion_config
                )
                
                return fused_vector
            else:
                logger.warning("No pieces selected, returning zero vector")
                return np.zeros(384)
                
        except Exception as e:
            logger.error(f"âŒ Integrated fusion error: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç°¡å˜ãªå¹³å‡çµ±åˆ
            if available_pieces:
                vectors = []
                for piece in available_pieces[:top_k]:
                    if hasattr(piece, 'u_component'):
                        vectors.append(np.array(piece.u_component))
                    elif isinstance(piece, dict) and 'u_component' in piece:
                        vectors.append(np.array(piece['u_component']))
                
                if vectors:
                    fused = np.mean(vectors, axis=0)
                    norm = np.linalg.norm(fused)
                    return fused / norm if norm > 0 else fused
            
            return np.zeros(384)
    
    def _full_integration_selection(self,
                                  user_context: str,
                                  available_pieces: List[Any],
                                  eval_dataset: List[Tuple[str, str]],
                                  user_id: str,
                                  top_k: int) -> List[Any]:
        """å®Œå…¨çµ±åˆæˆ¦ç•¥ã§ã®ãƒ”ãƒ¼ã‚¹é¸æŠ"""
        logger.info("ğŸ”— Full integration piece selection")
        
        candidate_pieces = available_pieces.copy()
        
        # 1. å“è³ªè©•ä¾¡ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if self.config.use_quality_evaluation and self.quality_evaluator:
            logger.info("   ğŸ“Š Quality-based filtering")
            filtered_pieces = []
            
            for piece in candidate_pieces:
                # ç°¡å˜ãªå“è³ªæ¨å®šï¼ˆå®Ÿéš›ã®è©•ä¾¡ã¯è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼‰
                estimated_quality = getattr(piece, 'quality_score', 0.5)
                if isinstance(piece, dict):
                    estimated_quality = piece.get('quality_score', 0.5)
                
                if estimated_quality >= self.config.quality_threshold:
                    filtered_pieces.append(piece)
            
            candidate_pieces = filtered_pieces
            logger.info(f"   Quality filtered: {len(candidate_pieces)} pieces")
        
        # 2. æ„å‘³çš„é¡ä¼¼åº¦ã«ã‚ˆã‚‹é¸æŠ
        if self.config.use_semantic_similarity and self.semantic_engine:
            logger.info("   ğŸ§  Semantic similarity selection")
            similarities = []
            
            for piece in candidate_pieces:
                try:
                    similarity = compute_semantic_similarity_rich(
                        user_context, piece, self.semantic_engine
                    )
                    similarities.append((piece, similarity))
                except Exception as e:
                    logger.warning(f"Semantic similarity error: {e}")
                    similarities.append((piece, 0.1))
            
            # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
            similarities.sort(key=lambda x: x[1], reverse=True)
            
            # é–¾å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            semantic_filtered = [
                piece for piece, sim in similarities 
                if sim >= self.config.semantic_threshold
            ]
            
            candidate_pieces = semantic_filtered[:top_k * 2]  # ä½™è£•ã‚’æŒã£ã¦é¸æŠ
            logger.info(f"   Semantic filtered: {len(candidate_pieces)} pieces")
        
        # 3. æœ€çµ‚é¸æŠï¼ˆtop-kï¼‰
        final_pieces = candidate_pieces[:top_k]
        
        logger.info(f"âœ… Full integration selected: {len(final_pieces)} pieces")
        return final_pieces
    
    def _quality_based_selection(self,
                               available_pieces: List[Any],
                               eval_dataset: List[Tuple[str, str]],
                               top_k: int) -> List[Any]:
        """å“è³ªè©•ä¾¡ãƒ™ãƒ¼ã‚¹ãƒ”ãƒ¼ã‚¹é¸æŠ"""
        logger.info("ğŸ“Š Quality-based piece selection")
        
        quality_scores = []
        for piece in available_pieces:
            # æ—¢å­˜ã®å“è³ªã‚¹ã‚³ã‚¢ã‚’ä½¿ç”¨
            quality = getattr(piece, 'quality_score', 0.5)
            if isinstance(piece, dict):
                quality = piece.get('quality_score', 0.5)
            quality_scores.append((piece, quality))
        
        # å“è³ªã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        quality_scores.sort(key=lambda x: x[1], reverse=True)
        
        selected = [piece for piece, _ in quality_scores[:top_k]]
        logger.info(f"âœ… Quality-based selected: {len(selected)} pieces")
        return selected
    
    def _semantic_based_selection(self,
                                user_context: str,
                                available_pieces: List[Any],
                                top_k: int) -> List[Any]:
        """æ„å‘³çš„é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ãƒ”ãƒ¼ã‚¹é¸æŠ"""
        logger.info("ğŸ§  Semantic-based piece selection")
        
        if not self.semantic_engine:
            logger.warning("Semantic engine not available, using random selection")
            return available_pieces[:top_k]
        
        similarities = []
        for piece in available_pieces:
            try:
                similarity = compute_semantic_similarity_rich(
                    user_context, piece, self.semantic_engine
                )
                similarities.append((piece, similarity))
            except Exception as e:
                logger.warning(f"Semantic similarity error: {e}")
                similarities.append((piece, 0.1))
        
        # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        selected = [piece for piece, _ in similarities[:top_k]]
        logger.info(f"âœ… Semantic-based selected: {len(selected)} pieces")
        return selected
    
    def generate_with_integrated_system(self,
                                      prompt: str,
                                      user_context: str = None,
                                      user_id: str = None,
                                      available_pieces: List[Any] = None,
                                      eval_dataset: List[Tuple[str, str]] = None,
                                      max_length: int = 100) -> str:
        """
        çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã‚’ä½¿ç”¨ã—ãŸç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_context: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            available_pieces: åˆ©ç”¨å¯èƒ½ãªãƒ”ãƒ¼ã‚¹ãƒªã‚¹ãƒˆ
            eval_dataset: è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            max_length: æœ€å¤§ç”Ÿæˆé•·
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        context_for_selection = user_context or prompt
        
        logger.info(f"ğŸ¦ Integrated generation started")
        logger.info(f"   Prompt: '{prompt[:50]}...'")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ã®è¨­å®š
        if available_pieces is None:
            available_pieces = self._create_default_pieces()
        
        if eval_dataset is None:
            eval_dataset = self._create_default_eval_dataset()
        
        try:
            # çµ±åˆçš„ãƒ”ãƒ¼ã‚¹é¸æŠãƒ»èåˆ
            fused_vector = self.select_and_fuse_pieces_integrated(
                user_context=context_for_selection,
                available_pieces=available_pieces,
                eval_dataset=eval_dataset,
                user_id=user_id,
                top_k=3
            )
            
            # ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…ï¼‰
            generation_info = {
                "vector_norm": np.linalg.norm(fused_vector),
                "strategy": self.config.integration_strategy,
                "pieces_count": len(available_pieces)
            }
            
            response = f"Integrated Chameleon response to: {prompt[:40]}..."
            response += f" (norm: {generation_info['vector_norm']:.3f}, strategy: {generation_info['strategy']})"
            
            logger.info(f"âœ… Generation completed with {generation_info['strategy']} strategy")
            return response
            
        except Exception as e:
            logger.error(f"âŒ Integrated generation error: {e}")
            return f"Generation error: {prompt[:30]}..."
    
    def _create_default_pieces(self) -> List[Dict[str, Any]]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ”ãƒ¼ã‚¹ã®ä½œæˆ"""
        return [
            {
                "piece_id": "default_general",
                "u_component": np.random.randn(384),
                "importance": 0.7,
                "quality_score": 0.6,
                "semantic_tags": ["general", "common"]
            },
            {
                "piece_id": "default_specific",
                "u_component": np.random.randn(384),
                "importance": 0.8,
                "quality_score": 0.8,
                "semantic_tags": ["specific", "detailed"]
            }
        ]
    
    def _create_default_eval_dataset(self) -> List[Tuple[str, str]]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ"""
        return [
            ("ä¸€èˆ¬çš„ãªè³ªå•ã§ã™", "ä¸€èˆ¬çš„ãªå›ç­”ã‚’ã—ã¾ã™"),
            ("å…·ä½“çš„ãªè³ªå•ã§ã™", "å…·ä½“çš„ãªå›ç­”ã‚’ã—ã¾ã™"),
            ("è©³ç´°ãªèª¬æ˜ã‚’ãŠé¡˜ã„ã—ã¾ã™", "è©³ç´°ãªèª¬æ˜ã‚’ã„ãŸã—ã¾ã™")
        ]
    
    def get_system_statistics(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆæƒ…å ±å–å¾—"""
        stats = {
            "integration_strategy": self.config.integration_strategy,
            "subsystems": {
                "adaptive_fusion": True,
                "quality_evaluation": self.config.use_quality_evaluation,
                "semantic_similarity": self.config.use_semantic_similarity,
                "dual_direction": self.config.use_dual_direction
            },
            "thresholds": {
                "semantic_threshold": self.config.semantic_threshold,
                "quality_threshold": self.config.quality_threshold
            }
        }
        
        if self.semantic_engine:
            cache_size = len(self.semantic_engine.embedding_cache.text_to_embedding)
            stats["semantic_cache_size"] = cache_size
        
        return stats

def compare_integration_strategies():
    """çµ±åˆæˆ¦ç•¥ã®æ€§èƒ½æ¯”è¼ƒ"""
    print("ğŸ”¬ çµ±åˆæˆ¦ç•¥æ€§èƒ½æ¯”è¼ƒãƒ‡ãƒ¢")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_pieces = [
        {
            "piece_id": "high_quality",
            "u_component": np.random.randn(384),
            "importance": 0.9,
            "quality_score": 0.9,
            "semantic_tags": ["movies", "entertainment"]
        },
        {
            "piece_id": "medium_quality",
            "u_component": np.random.randn(384),
            "importance": 0.6,
            "quality_score": 0.6,
            "semantic_tags": ["cooking", "recipes"]
        },
        {
            "piece_id": "low_quality",
            "u_component": np.random.randn(384),
            "importance": 0.3,
            "quality_score": 0.3,
            "semantic_tags": ["general", "misc"]
        }
    ]
    
    eval_dataset = [
        ("æ˜ ç”»ã®æ¨è–¦ã‚’ã—ã¦ãã ã•ã„", "ãŠã™ã™ã‚ã®æ˜ ç”»ã‚’ã”ç´¹ä»‹ã—ã¾ã™"),
        ("æ–™ç†ã®ãƒ¬ã‚·ãƒ”ã‚’æ•™ãˆã¦", "ç¾å‘³ã—ã„æ–™ç†ã®ä½œã‚Šæ–¹ã‚’ãŠæ•™ãˆã—ã¾ã™"),
        ("ä¸€èˆ¬çš„ãªè³ªå•ã§ã™", "ä¸€èˆ¬çš„ãªå›ç­”ã‚’ã„ãŸã—ã¾ã™")
    ]
    
    test_prompt = "é¢ç™½ã„æ˜ ç”»ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„"
    test_context = "ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ†ã‚¤ãƒ¡ãƒ³ãƒˆã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™"
    
    strategies = ["full", "adaptive_only", "quality_only", "semantic_only"]
    
    print(f"\nğŸ“‹ Test setup:")
    print(f"   Pieces: {len(test_pieces)}")
    print(f"   Eval samples: {len(eval_dataset)}")
    print(f"   Test prompt: '{test_prompt}'")
    print(f"   Test context: '{test_context}'")
    
    results = {}
    
    for strategy in strategies:
        print(f"\nğŸ§ª Testing strategy: {strategy}")
        print("-" * 40)
        
        start_time = time.time()
        
        # æˆ¦ç•¥åˆ¥è¨­å®š
        config = IntegratedChameleonConfig(
            integration_strategy=strategy,
            use_semantic_similarity=True,
            use_quality_evaluation=True,
            semantic_threshold=0.2,
            quality_threshold=0.4
        )
        
        system = IntegratedChameleonSystem(config)
        
        # ç”Ÿæˆå®Ÿè¡Œ
        result = system.generate_with_integrated_system(
            prompt=test_prompt,
            user_context=test_context,
            available_pieces=test_pieces,
            eval_dataset=eval_dataset
        )
        
        execution_time = time.time() - start_time
        
        # çµ±è¨ˆå–å¾—
        stats = system.get_system_statistics()
        
        results[strategy] = {
            "result": result,
            "execution_time": execution_time,
            "stats": stats
        }
        
        print(f"   Execution time: {execution_time:.3f}s")
        print(f"   Result: {result[:80]}...")
        print(f"   Subsystems active: {sum(stats['subsystems'].values())}/4")
    
    # çµæœæ¯”è¼ƒ
    print(f"\nğŸ“Š Strategy Comparison Summary:")
    print("=" * 60)
    print(f"{'Strategy':<15} | {'Time (s)':<8} | {'Active Systems':<14} | {'Result Quality'}")
    print("-" * 60)
    
    for strategy, data in results.items():
        time_str = f"{data['execution_time']:.3f}"
        active_systems = sum(data['stats']['subsystems'].values())
        
        # ç°¡å˜ãªçµæœå“è³ªæ¨å®šï¼ˆæ–‡å­—æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
        result_length = len(data['result'])
        quality_estimate = "High" if result_length > 100 else "Medium" if result_length > 60 else "Low"
        
        print(f"{strategy:<15} | {time_str:<8} | {active_systems}/4{'':<10} | {quality_estimate}")
    
    # æ¨å¥¨æˆ¦ç•¥
    print(f"\nğŸ’¡ Recommendations:")
    print(f"   â€¢ Full integration: æœ€é«˜æ€§èƒ½ã€å…¨æ©Ÿèƒ½æ´»ç”¨")
    print(f"   â€¢ Quality-only: ãƒãƒ©ãƒ³ã‚¹é‡è¦–ã€ä¸­ç¨‹åº¦ã®æ€§èƒ½")
    print(f"   â€¢ Semantic-only: é«˜é€Ÿå‡¦ç†ã€æ„å‘³çš„ãƒãƒƒãƒãƒ³ã‚°é‡è¦–")
    print(f"   â€¢ Adaptive-only: åŸºæœ¬æ©Ÿèƒ½ã€æœ€å°ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰")
    
    print("\nğŸ‰ çµ±åˆæˆ¦ç•¥æ¯”è¼ƒå®Œäº†!")

def demonstrate_integrated_system():
    """çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    print("ğŸ¦ å››å¤§æ”¹è‰¯ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ‡ãƒ¢")
    print("=" * 60)
    
    # è¨­å®š
    config = IntegratedChameleonConfig(
        integration_strategy="full",
        use_semantic_similarity=True,
        use_quality_evaluation=True,
        use_dual_direction=True
    )
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = IntegratedChameleonSystem(config)
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    test_cases = [
        {
            "prompt": "æ˜ ç”»ã®æ¨è–¦ã‚’ãŠé¡˜ã„ã—ã¾ã™",
            "context": "SFæ˜ ç”»ãŒå¥½ãã§ã™",
            "user_id": "movie_lover"
        },
        {
            "prompt": "æ–™ç†ã®ã‚³ãƒ„ã‚’æ•™ãˆã¦ãã ã•ã„", 
            "context": "æ–™ç†åˆå¿ƒè€…ã§ã™",
            "user_id": "cooking_beginner"
        },
        {
            "prompt": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å­¦ç¿’ã«ã¤ã„ã¦",
            "context": "Python ã‚’å­¦ç¿’ä¸­ã§ã™",
            "user_id": "developer"
        }
    ]
    
    print(f"\nğŸ§ª Testing integrated system with {len(test_cases)} cases:")
    
    for i, case in enumerate(test_cases, 1):
        print(f"\nğŸ“ Test Case {i}:")
        print(f"   Prompt: '{case['prompt']}'")
        print(f"   Context: '{case['context']}'")
        print(f"   User ID: {case['user_id']}")
        
        start_time = time.time()
        
        result = system.generate_with_integrated_system(
            prompt=case["prompt"],
            user_context=case["context"],
            user_id=case["user_id"]
        )
        
        execution_time = time.time() - start_time
        
        print(f"   Result: {result}")
        print(f"   Time: {execution_time:.3f}s")
    
    # ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ
    stats = system.get_system_statistics()
    print(f"\nğŸ“Š System Statistics:")
    print(f"   Integration strategy: {stats['integration_strategy']}")
    print(f"   Active subsystems: {sum(stats['subsystems'].values())}/4")
    print(f"   Semantic threshold: {stats['thresholds']['semantic_threshold']}")
    print(f"   Quality threshold: {stats['thresholds']['quality_threshold']}")
    
    if "semantic_cache_size" in stats:
        print(f"   Semantic cache size: {stats['semantic_cache_size']}")
    
    print("\nğŸ‰ çµ±åˆã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢å®Œäº†!")

if __name__ == "__main__":
    demonstrate_integrated_system()
    print("\n" + "="*60)
    compare_integration_strategies()