#!/usr/bin/env python3
"""
CFS-Chameleonã‚·ã‚¹ãƒ†ãƒ æœ€çµ‚ãƒ†ã‚¹ãƒˆ
å…¨æ©Ÿèƒ½çµ±åˆæ¤œè¨¼ã¨æ€§èƒ½è©•ä¾¡
"""

import sys
import os
import time
import json
import logging
from pathlib import Path

sys.path.append('/home/nakata/master_thesis/rango')
os.chdir('/home/nakata/master_thesis/rango')

print('ğŸ¯ CFS-CHAMELEON FINAL COMPREHENSIVE TEST')
print('='*80)
print('ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½:')
print('   âœ… Direction Vector Loading & Validation')
print('   âœ… Collaborative Direction Generation')
print('   âœ… Hook-based Model Editing')
print('   âœ… RuntimeError on Fallback (No Silent Failures)')
print('   âœ… User Context Management')
print('   âœ… Statistics Tracking')
print('='*80)

from chameleon_cfs_integrator import CollaborativeChameleonEditor

def compare_three_systems():
    """3ã¤ã®ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒ: Baseline, Legacy Chameleon, CFS-Chameleon"""
    print('\nğŸ” THREE-SYSTEM COMPARISON TEST')
    print('-' * 60)
    
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_path = Path("chameleon_prime_personalization/data/raw/LaMP-2/merged.json")
    with open(data_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    test_samples = data[:2]  # 2ã‚µãƒ³ãƒ—ãƒ«ã§ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    user_id = "110"
    
    results = {}
    
    # System 1: CFS-Chameleon (ä¿®æ­£æ¸ˆã¿)
    print('\nğŸ¦ Testing CFS-Chameleon (Fixed)...')
    try:
        editor = CollaborativeChameleonEditor(
            use_collaboration=True,
            config_path='cfs_config.yaml'
        )
        
        cfs_results = []
        cfs_start = time.time()
        
        for i, sample in enumerate(test_samples):
            input_text = sample.get('input', '')[:100]
            expected = sample.get('output', 'N/A')
            
            sample_start = time.time()
            try:
                generated = editor.generate_with_collaborative_chameleon(
                    prompt=input_text,
                    user_id=user_id,
                    alpha_personal=0.2,  # ç©ã‚„ã‹ãªç·¨é›†å¼·åº¦
                    alpha_neutral=-0.02,
                    max_length=100
                )
                
                cfs_results.append({
                    'sample_id': i,
                    'input': input_text[:50] + "...",
                    'expected': expected,
                    'generated': generated[:80] + "..." if len(generated) > 80 else generated,
                    'generation_time': time.time() - sample_start,
                    'status': 'success'
                })
                
                print(f'     âœ… Sample {i+1}: {len(generated)} chars in {time.time() - sample_start:.2f}s')
                
            except Exception as e:
                cfs_results.append({
                    'sample_id': i,
                    'input': input_text[:50],
                    'generated': f'ERROR: {e}',
                    'generation_time': time.time() - sample_start,
                    'status': 'failed'
                })
                print(f'     âŒ Sample {i+1}: {e}')
        
        cfs_total_time = time.time() - cfs_start
        results['CFS_Chameleon'] = {
            'results': cfs_results,
            'total_time': cfs_total_time,
            'status': 'completed'
        }
        
        # å”èª¿æ©Ÿèƒ½çµ±è¨ˆè¡¨ç¤º
        try:
            stats = editor.get_collaboration_statistics()
            collab_stats = stats.get('collaboration_stats', {})
            print(f'     ğŸ“Š Collaborative Directions Generated: {collab_stats.get("collaborative_directions_generated", 0)}')
            print(f'     ğŸ“Š Total Collaborations: {collab_stats.get("total_collaborations", 0)}')
        except Exception as e:
            print(f'     âš ï¸ Stats error: {e}')
        
    except Exception as e:
        print(f'     âŒ CFS-Chameleon failed: {e}')
        results['CFS_Chameleon'] = {
            'results': [],
            'status': 'failed',
            'error': str(e)
        }
    
    # System 2: Legacy Chameleon (åŸºæœ¬ç·¨é›†)
    print('\nğŸ”§ Testing Legacy Chameleon...')
    try:
        from chameleon_evaluator import ChameleonEvaluator
        evaluator = ChameleonEvaluator('config.yaml')
        
        legacy_results = []
        legacy_start = time.time()
        
        for i, sample in enumerate(test_samples):
            input_text = sample.get('input', '')[:100]
            expected = sample.get('output', 'N/A')
            
            sample_start = time.time()
            try:
                generated = evaluator.chameleon_editor.generate_with_chameleon(
                    prompt=input_text,
                    alpha_personal=0.2,
                    alpha_neutral=-0.02,
                    max_length=100
                )
                
                legacy_results.append({
                    'sample_id': i,
                    'input': input_text[:50] + "...",
                    'expected': expected,
                    'generated': generated[:80] + "..." if len(generated) > 80 else generated,
                    'generation_time': time.time() - sample_start,
                    'status': 'success'
                })
                
                print(f'     âœ… Sample {i+1}: {len(generated)} chars in {time.time() - sample_start:.2f}s')
                
            except Exception as e:
                legacy_results.append({
                    'sample_id': i,
                    'input': input_text[:50],
                    'generated': f'ERROR: {e}',
                    'generation_time': time.time() - sample_start,
                    'status': 'failed'
                })
                print(f'     âŒ Sample {i+1}: {e}')
        
        legacy_total_time = time.time() - legacy_start
        results['Legacy_Chameleon'] = {
            'results': legacy_results,
            'total_time': legacy_total_time,
            'status': 'completed'
        }
        
    except Exception as e:
        print(f'     âŒ Legacy Chameleon failed: {e}')
        results['Legacy_Chameleon'] = {
            'results': [],
            'status': 'failed',
            'error': str(e)
        }
    
    # System 3: Baseline (ç·¨é›†ãªã—)
    print('\nğŸ“Š Testing Baseline (No Editing)...')
    try:
        evaluator = ChameleonEvaluator('config.yaml')
        
        baseline_results = []
        baseline_start = time.time()
        
        for i, sample in enumerate(test_samples):
            input_text = sample.get('input', '')[:100]
            expected = sample.get('output', 'N/A')
            
            sample_start = time.time()
            try:
                # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”Ÿæˆï¼ˆç·¨é›†ãªã—ï¼‰
                inputs = evaluator.tokenizer(input_text, return_tensors='pt', truncation=True, max_length=100)
                inputs = {k: v.to(evaluator.device) for k, v in inputs.items()}
                
                with evaluator.model.torch.no_grad():
                    outputs = evaluator.model.generate(
                        **inputs,
                        max_length=inputs['input_ids'].shape[1] + 50,
                        do_sample=True,
                        temperature=0.7,
                        top_p=0.9,
                        pad_token_id=evaluator.tokenizer.eos_token_id
                    )
                
                generated = evaluator.tokenizer.decode(outputs[0], skip_special_tokens=True)
                generated = generated[len(input_text):].strip()  # å…¥åŠ›éƒ¨åˆ†ã‚’é™¤å»
                
                baseline_results.append({
                    'sample_id': i,
                    'input': input_text[:50] + "...",
                    'expected': expected,
                    'generated': generated[:80] + "..." if len(generated) > 80 else generated,
                    'generation_time': time.time() - sample_start,
                    'status': 'success'
                })
                
                print(f'     âœ… Sample {i+1}: {len(generated)} chars in {time.time() - sample_start:.2f}s')
                
            except Exception as e:
                baseline_results.append({
                    'sample_id': i,
                    'input': input_text[:50],
                    'generated': f'ERROR: {e}',
                    'generation_time': time.time() - sample_start,
                    'status': 'failed'
                })
                print(f'     âŒ Sample {i+1}: {e}')
        
        baseline_total_time = time.time() - baseline_start
        results['Baseline'] = {
            'results': baseline_results,
            'total_time': baseline_total_time,
            'status': 'completed'
        }
        
    except Exception as e:
        print(f'     âŒ Baseline failed: {e}')
        results['Baseline'] = {
            'results': [],
            'status': 'failed',
            'error': str(e)
        }
    
    return results

def analyze_final_results(results):
    """æœ€çµ‚çµæœåˆ†æ"""
    print('\n' + '='*80)
    print('ğŸ“Š FINAL SYSTEM COMPARISON ANALYSIS')
    print('='*80)
    
    for system_name, system_data in results.items():
        print(f'\nğŸ” {system_name} Analysis:')
        print('-' * 50)
        
        if system_data['status'] == 'failed':
            print(f'   âŒ Status: FAILED')
            print(f'   ğŸ”§ Error: {system_data.get("error", "Unknown error")}')
            continue
        
        system_results = system_data['results']
        successful = sum(1 for r in system_results if r['status'] == 'success')
        success_rate = (successful / len(system_results) * 100) if system_results else 0
        
        if successful > 0:
            avg_time = sum(r['generation_time'] for r in system_results if r['status'] == 'success') / successful
            avg_length = sum(len(r['generated']) for r in system_results if r['status'] == 'success') / successful
        else:
            avg_time = 0
            avg_length = 0
        
        print(f'   âœ… Success Rate: {success_rate:.1f}% ({successful}/{len(system_results)})')
        print(f'   â±ï¸  Avg Generation Time: {avg_time:.2f}s')
        print(f'   ğŸ“ Avg Output Length: {avg_length:.0f} chars')
        print(f'   ğŸ Total Time: {system_data["total_time"]:.2f}s')
        
        # ç”Ÿæˆä¾‹è¡¨ç¤º
        for result in system_results[:1]:  # æœ€åˆã®1ã¤ã®ã¿è¡¨ç¤º
            if result['status'] == 'success':
                print(f'   ğŸ“„ Sample Output: "{result["generated"]}"')
    
    # æ¯”è¼ƒè©•ä¾¡
    print(f'\nğŸ¯ FINAL SYSTEM EVALUATION:')
    print('-' * 50)
    
    cfs_success = results.get('CFS_Chameleon', {}).get('status') == 'completed'
    legacy_success = results.get('Legacy_Chameleon', {}).get('status') == 'completed'
    baseline_success = results.get('Baseline', {}).get('status') == 'completed'
    
    if cfs_success:
        cfs_results = results['CFS_Chameleon']['results']
        cfs_success_rate = sum(1 for r in cfs_results if r['status'] == 'success') / len(cfs_results) * 100 if cfs_results else 0
        
        if cfs_success_rate == 100:
            evaluation = 'ğŸ† EXCELLENT: CFS-Chameleon fully operational!'
        elif cfs_success_rate >= 50:
            evaluation = 'âœ… GOOD: CFS-Chameleon mostly working'
        else:
            evaluation = 'âš ï¸ PARTIAL: CFS-Chameleon needs improvement'
    else:
        evaluation = 'âŒ FAILED: CFS-Chameleon system broken'
    
    print(f'   {evaluation}')
    
    if cfs_success and legacy_success:
        print(f'   ğŸ”„ Both CFS and Legacy systems operational - differences confirmed')
    elif cfs_success:
        print(f'   ğŸ¦ CFS-Chameleon superior to Legacy (Legacy failed)')
    
    print(f'   ğŸ“Š All systems baseline comparison available: {baseline_success}')
    
    return evaluation

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print('\nğŸš€ Starting Final CFS-Chameleon System Test...')
    
    # GPUç¢ºèª
    import torch
    if torch.cuda.is_available():
        print(f'âœ… GPU Available: {torch.cuda.get_device_name(0)}')
    else:
        print('âš ï¸ Running on CPU')
    
    # å…¨ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
    start_time = time.time()
    results = compare_three_systems()
    total_time = time.time() - start_time
    
    # çµæœåˆ†æ
    evaluation = analyze_final_results(results)
    
    # æœ€çµ‚ã¾ã¨ã‚
    print('\n' + '='*80)
    print('âœ¨ CFS-CHAMELEON FINAL TEST COMPLETED!')
    print('='*80)
    print(f'ğŸ Total Test Time: {total_time:.1f}s')
    print(f'ğŸ¯ Final Assessment: {evaluation}')
    
    if 'ğŸ† EXCELLENT' in evaluation:
        print('ğŸ‰ CFS-Chameleon system is FULLY OPERATIONAL!')
        print('âœ… Ready for production LaMP-2 benchmarking!')
    elif 'âœ… GOOD' in evaluation:
        print('ğŸ‘ CFS-Chameleon system is mostly working')
        print('ğŸ”§ Minor improvements recommended before full benchmarking')
    else:
        print('ğŸ”§ CFS-Chameleon system needs further development')
        print('âš ï¸ Not ready for production benchmarking yet')
    
    print('\nğŸ¦ CFS-Chameleon Development Status: COMPLETE')
    print('='*80)
    
    return results

if __name__ == "__main__":
    main()