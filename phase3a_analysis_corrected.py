#!/usr/bin/env python3
"""
Phase 3-A Analysis Corrected: Fix result extraction and provide detailed analysis
"""

import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import numpy as np
from datetime import datetime

def analyze_ablation_results():
    """
    Corrected analysis of Phase 3-A ablation study results
    """
    print("üîç PHASE 3-A ANALYSIS: Result Extraction & Interpretation")
    print("=" * 70)
    
    # From the logs, we can extract the actual performance values
    # All configurations showed 36.36% accuracy (0.3636)
    corrected_results = {
        'Config_A': {
            'name': 'Chameleon Only (Baseline)',
            'baseline_accuracy': 0.3636,
            'enhanced_accuracy': 0.3636,
            'baseline_bleu': 0.0647,
            'enhanced_bleu': 0.0647,
            'baseline_f1': 0.3636,
            'enhanced_f1': 0.3636,
            'inference_time_baseline': 4.39,
            'inference_time_enhanced': 3.65,
            'improvement_rate': 0.0,
            'sample_count': 11
        },
        'Config_B': {
            'name': 'Chameleon + Causal Inference',
            'baseline_accuracy': 0.3636,
            'enhanced_accuracy': 0.3636,
            'baseline_bleu': 0.0647,
            'enhanced_bleu': 0.0647,
            'baseline_f1': 0.3636,
            'enhanced_f1': 0.3636,
            'inference_time_baseline': 3.91,
            'inference_time_enhanced': 3.56,
            'improvement_rate': 0.0,
            'sample_count': 11
        },
        'Config_C': {
            'name': 'Chameleon + Stiefel Manifold',
            'baseline_accuracy': 0.3636,
            'enhanced_accuracy': 0.3636,
            'baseline_bleu': 0.0647,
            'enhanced_bleu': 0.0647,
            'baseline_f1': 0.3636,
            'enhanced_f1': 0.3636,
            'inference_time_baseline': 3.92,
            'inference_time_enhanced': 3.57,
            'improvement_rate': 0.0,
            'sample_count': 11
        },
        'Config_D': {
            'name': 'Full System (All Layers)',
            'baseline_accuracy': 0.3636,
            'enhanced_accuracy': 0.3636,
            'baseline_bleu': 0.0647,
            'enhanced_bleu': 0.0647,
            'baseline_f1': 0.3636,
            'enhanced_f1': 0.3636,
            'inference_time_baseline': 3.91,
            'inference_time_enhanced': 3.57,
            'improvement_rate': 0.0,
            'sample_count': 11
        }
    }
    
    print("\nüìä CORRECTED ABLATION STUDY RESULTS:")
    print("‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
    print("‚îÇ Configuration                   ‚îÇ Accuracy     ‚îÇ BLEU Score   ‚îÇ F1 Score    ‚îÇ Time (s)    ‚îÇ")
    print("‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
    
    for config_id, data in corrected_results.items():
        name = data['name'][:30] + "..." if len(data['name']) > 30 else data['name']
        print(f"‚îÇ {name:<31} ‚îÇ {data['enhanced_accuracy']:<12.4f} ‚îÇ {data['enhanced_bleu']:<12.4f} ‚îÇ {data['enhanced_f1']:<11.4f} ‚îÇ {data['inference_time_enhanced']:<11.2f} ‚îÇ")
    
    print("‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
    
    # Performance Analysis
    print("\nüîç DETAILED PERFORMANCE ANALYSIS:")
    
    # 1. Accuracy Analysis
    print("\n1Ô∏è‚É£ ACCURACY ANALYSIS:")
    print(f"   ‚Ä¢ All configurations achieved identical accuracy: 36.36%")
    print(f"   ‚Ä¢ This suggests the current parameter settings (Œ±=0.4, Œ≤=-0.05) are not providing improvement")
    print(f"   ‚Ä¢ Sample size: 11 questions from 3 users")
    print(f"   ‚Ä¢ Baseline performance is competitive for LaMP-2 benchmark")
    
    # 2. Inference Time Analysis
    print("\n2Ô∏è‚É£ INFERENCE TIME ANALYSIS:")
    inference_times = [(config, data['inference_time_enhanced']) for config, data in corrected_results.items()]
    inference_times.sort(key=lambda x: x[1])
    
    fastest_config, fastest_time = inference_times[0]
    slowest_config, slowest_time = inference_times[-1]
    
    print(f"   ‚Ä¢ Fastest: {corrected_results[fastest_config]['name']} ({fastest_time:.2f}s)")
    print(f"   ‚Ä¢ Slowest: {corrected_results[slowest_config]['name']} ({slowest_time:.2f}s)")
    print(f"   ‚Ä¢ Speed improvement: {((slowest_time - fastest_time) / slowest_time * 100):.1f}% faster")
    
    # All configurations are very close in time
    avg_time = np.mean([data['inference_time_enhanced'] for data in corrected_results.values()])
    std_time = np.std([data['inference_time_enhanced'] for data in corrected_results.values()])
    print(f"   ‚Ä¢ Average inference time: {avg_time:.2f}s ¬± {std_time:.2f}s")
    print(f"   ‚Ä¢ Observation: All enhanced layers have similar computational overhead")
    
    # 3. Hook Call Analysis (from logs)
    print("\n3Ô∏è‚É£ HOOK CALL ANALYSIS (from logs):")
    print(f"   ‚Ä¢ Average hook calls per sample: 25.4")
    print(f"   ‚Ä¢ Average edit ratio: 8.03e-03 (0.803%)")
    print(f"   ‚Ä¢ Hook utilization: Active across layers 20, 24, 27")
    print(f"   ‚Ä¢ Edit ratio target: 2.5% (actual: 0.8% - underutilized)")
    
    # 4. Statistical Significance Assessment
    print("\n4Ô∏è‚É£ STATISTICAL SIGNIFICANCE ASSESSMENT:")
    print(f"   ‚Ä¢ Current p-values: NaN (identical results across configurations)")
    print(f"   ‚Ä¢ No significant differences detected between configurations")
    print(f"   ‚Ä¢ Small sample size (n=11) limits statistical power")
    print(f"   ‚Ä¢ Recommendation: Increase sample size for full evaluation")
    
    # 5. Component Contribution Analysis
    print("\n5Ô∏è‚É£ COMPONENT CONTRIBUTION ANALYSIS:")
    print(f"   ‚Ä¢ Causal Inference (Config B): No measurable impact")
    print(f"   ‚Ä¢ Stiefel Manifold (Config C): No measurable impact")
    print(f"   ‚Ä¢ Combined System (Config D): No measurable impact")
    print(f"   ‚Ä¢ Conclusion: Current implementation needs parameter tuning")
    
    return corrected_results

def diagnose_system_issues():
    """
    Diagnose why the enhanced systems aren't showing improvements
    """
    print("\nüö® SYSTEM DIAGNOSTIC ANALYSIS:")
    print("=" * 50)
    
    issues = [
        {
            'issue': 'Low Edit Ratio',
            'description': 'Actual edit ratio (0.8%) is much lower than target (2.5%)',
            'impact': 'Insufficient personalization signal',
            'solution': 'Increase alpha parameters or adjust threshold'
        },
        {
            'issue': 'Small Sample Size',
            'description': 'Only 11 samples from 3 users in demo mode',
            'impact': 'Limited statistical power and generalization',
            'solution': 'Run full evaluation with larger dataset'
        },
        {
            'issue': 'Parameter Configuration',
            'description': 'Œ±=0.4, Œ≤=-0.05 may be too conservative',
            'impact': 'Minimal impact on model behavior',
            'solution': 'Hyperparameter sweep to find optimal values'
        },
        {
            'issue': 'Theta Vector Quality',
            'description': 'Direction vectors may not capture meaningful personalization',
            'impact': 'No performance improvement despite successful editing',
            'solution': 'Verify theta vector generation with better user data'
        }
    ]
    
    for i, issue in enumerate(issues, 1):
        print(f"\nüîß ISSUE {i}: {issue['issue']}")
        print(f"   Description: {issue['description']}")
        print(f"   Impact: {issue['impact']}")
        print(f"   Solution: {issue['solution']}")
    
    return issues

def generate_recommendations():
    """
    Generate actionable recommendations for Phase 3-B
    """
    print("\nüìã PHASE 3-B RECOMMENDATIONS:")
    print("=" * 40)
    
    recommendations = [
        {
            'priority': 'HIGH',
            'action': 'Hyperparameter Optimization',
            'details': 'Run grid search for Œ± ‚àà [0.8, 1.5, 2.0] and Œ≤ ‚àà [-0.3, -0.8, -1.0]',
            'expected_outcome': 'Find optimal editing strength parameters'
        },
        {
            'priority': 'HIGH', 
            'action': 'Full Dataset Evaluation',
            'details': 'Run evaluation on complete LaMP-2 test set (mode=full)',
            'expected_outcome': 'Statistical significance with n>>11 samples'
        },
        {
            'priority': 'MEDIUM',
            'action': 'Theta Vector Quality Analysis',
            'details': 'Analyze SVD components and user profile diversity',
            'expected_outcome': 'Verify personalization signal strength'
        },
        {
            'priority': 'MEDIUM',
            'action': 'Layer-wise Ablation',
            'details': 'Test different hook layers (embedding, attention, MLP)',
            'expected_outcome': 'Identify most effective editing locations'
        },
        {
            'priority': 'LOW',
            'action': 'Causal Graph Validation',
            'details': 'Verify PC algorithm output with domain knowledge',
            'expected_outcome': 'Ensure causal relationships are meaningful'
        }
    ]
    
    for rec in recommendations:
        print(f"\nüéØ {rec['priority']} PRIORITY: {rec['action']}")
        print(f"   Details: {rec['details']}")
        print(f"   Expected: {rec['expected_outcome']}")
    
    return recommendations

def create_visualization():
    """
    Create visualization of current results
    """
    print("\nüìä GENERATING VISUALIZATION...")
    
    # Create output directory
    output_dir = Path("results/phase3a_analysis")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Performance comparison chart
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Phase 3-A Ablation Study Results', fontsize=16, fontweight='bold')
    
    configs = ['Config A\n(Baseline)', 'Config B\n(+Causal)', 'Config C\n(+Stiefel)', 'Config D\n(Full System)']
    accuracies = [0.3636] * 4
    times = [3.65, 3.56, 3.57, 3.57]
    
    # Accuracy comparison
    bars1 = ax1.bar(configs, accuracies, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    ax1.set_title('Accuracy Comparison', fontweight='bold')
    ax1.set_ylabel('Accuracy')
    ax1.set_ylim(0, 0.5)
    ax1.grid(True, alpha=0.3)
    
    # Add value labels on bars
    for bar, acc in zip(bars1, accuracies):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{acc:.1%}', ha='center', fontweight='bold')
    
    # Inference time comparison
    bars2 = ax2.bar(configs, times, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    ax2.set_title('Inference Time Comparison', fontweight='bold')
    ax2.set_ylabel('Time (seconds)')
    ax2.grid(True, alpha=0.3)
    
    for bar, time in zip(bars2, times):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                f'{time:.2f}s', ha='center', fontweight='bold')
    
    # System complexity vs performance
    complexity = [1, 2, 2, 3]  # Number of layers
    performance = accuracies
    
    ax3.scatter(complexity, performance, s=200, c=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    for i, config in enumerate(['A', 'B', 'C', 'D']):
        ax3.annotate(f'Config {config}', (complexity[i], performance[i]), 
                    xytext=(10, 10), textcoords='offset points')
    ax3.set_xlabel('System Complexity (# of layers)')
    ax3.set_ylabel('Accuracy')
    ax3.set_title('Complexity vs Performance', fontweight='bold')
    ax3.grid(True, alpha=0.3)
    
    # Recommendations priority matrix
    priorities = ['Hyperparameter\nOptimization', 'Full Dataset\nEvaluation', 
                 'Theta Vector\nAnalysis', 'Layer-wise\nAblation', 'Causal Graph\nValidation']
    priority_scores = [3, 3, 2, 2, 1]  # HIGH=3, MEDIUM=2, LOW=1
    impact_scores = [3, 3, 2, 2, 1]
    
    colors = ['red' if p == 3 else 'orange' if p == 2 else 'green' for p in priority_scores]
    scatter = ax4.scatter(priority_scores, impact_scores, s=300, c=colors, alpha=0.7)
    
    for i, rec in enumerate(priorities):
        ax4.annotate(rec, (priority_scores[i], impact_scores[i]), 
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    ax4.set_xlabel('Priority Level')
    ax4.set_ylabel('Expected Impact')
    ax4.set_title('Recommendations Matrix', fontweight='bold')
    ax4.set_xticks([1, 2, 3])
    ax4.set_xticklabels(['Low', 'Medium', 'High'])
    ax4.set_yticks([1, 2, 3])
    ax4.set_yticklabels(['Low', 'Medium', 'High'])
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # Save plot
    plot_file = output_dir / 'phase3a_analysis_visualization.png'
    plt.savefig(plot_file, dpi=300, bbox_inches='tight')
    print(f"   Visualization saved: {plot_file}")
    
    plt.close()
    return str(plot_file)

def main():
    """
    Main analysis function
    """
    print("üéØ PHASE 3-A COMPREHENSIVE ANALYSIS (CORRECTED)")
    print("=" * 60)
    
    # Step 1: Analyze results
    results = analyze_ablation_results()
    
    # Step 2: Diagnose issues
    issues = diagnose_system_issues()
    
    # Step 3: Generate recommendations
    recommendations = generate_recommendations()
    
    # Step 4: Create visualization
    plot_file = create_visualization()
    
    # Step 5: Summary
    print("\n" + "=" * 60)
    print("üèÜ PHASE 3-A ANALYSIS SUMMARY:")
    print("=" * 60)
    
    print("\n‚úÖ COMPLETED SUCCESSFULLY:")
    print("   ‚Ä¢ All 4 configurations executed successfully")
    print("   ‚Ä¢ System integration confirmed operational")
    print("   ‚Ä¢ Performance baseline established (36.36% accuracy)")
    print("   ‚Ä¢ Infrastructure ready for parameter optimization")
    
    print("\n‚ö†Ô∏è  KEY FINDINGS:")
    print("   ‚Ä¢ Current parameters need optimization (0% improvement)")
    print("   ‚Ä¢ Edit ratio underutilized (0.8% vs 2.5% target)")
    print("   ‚Ä¢ All enhanced configurations show identical performance")
    print("   ‚Ä¢ System overhead is minimal (~3.6s inference time)")
    
    print("\nüéØ NEXT STEPS FOR PHASE 3-B:")
    print("   ‚Ä¢ HIGH: Hyperparameter grid search")
    print("   ‚Ä¢ HIGH: Full dataset evaluation")
    print("   ‚Ä¢ MEDIUM: Theta vector quality analysis")
    print("   ‚Ä¢ MEDIUM: Layer-wise editing location optimization")
    
    print(f"\nüìÅ OUTPUTS:")
    print(f"   ‚Ä¢ Analysis report: Complete")
    print(f"   ‚Ä¢ Visualization: {plot_file}")
    print(f"   ‚Ä¢ Recommendations: 5 actionable items identified")
    
    print("\n" + "=" * 60)
    print("‚ú® PHASE 3-A ANALYSIS COMPLETED - READY FOR PHASE 3-B SCALING!")
    print("=" * 60)

if __name__ == "__main__":
    main()