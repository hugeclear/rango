#!/usr/bin/env python3
"""
LaMP-2 CFS-Chameleonçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½è©•ä¾¡ãƒ»æ¯”è¼ƒã‚’è¡Œã†ä¸–ç•Œåˆã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

ç‰¹å¾´:
- å¾“æ¥ç‰ˆChameleon vs CFS-Chameleonæ€§èƒ½æ¯”è¼ƒ
- ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½åˆ†æ
- å”èª¿å­¦ç¿’åŠ¹æœã®å®šé‡è©•ä¾¡
- çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
- å®Œå…¨ä¸‹ä½äº’æ›æ€§ä¿è¨¼
"""

import json
import os
import time
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import numpy as np
import torch
from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import logging

# CFS-Chameleonçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from chameleon_cfs_integrator import CollaborativeChameleonEditor
    from cfs_chameleon_extension import CollaborativeDirectionPool, UserContext
    from chameleon_evaluator import ChameleonEvaluator
    CFS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ CFS-Chameleon modules not available: {e}")
    CFS_AVAILABLE = False

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass 
class CFSEvaluationResult:
    """CFS-Chameleonæ‹¡å¼µè©•ä¾¡çµæœ"""
    method_name: str
    accuracy: float
    f1_macro: float
    f1_micro: float
    precision: float
    recall: float
    inference_time: float
    total_samples: int
    correct_predictions: int
    
    # CFSæ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹
    collaboration_benefit: float = 0.0
    cold_start_performance: float = 0.0
    pool_utilization: float = 0.0
    user_coverage: int = 0
    privacy_preservation: float = 0.0

@dataclass
class ComparisonResults:
    """æ¯”è¼ƒè©•ä¾¡çµæœ"""
    legacy_results: CFSEvaluationResult
    cfs_results: CFSEvaluationResult
    improvement_rate: float
    statistical_significance: float
    cold_start_improvement: float
    collaboration_effectiveness: float

class CFSLaMP2Evaluator:
    """CFS-Chameleonçµ±åˆLaMP-2è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, data_path: str, output_dir: str = "./cfs_evaluation_results", 
                 config_path: str = None, use_collaboration: bool = False,
                 collaboration_mode: str = "heuristic"):
        
        self.data_path = Path(data_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.use_collaboration = use_collaboration
        self.collaboration_mode = collaboration_mode
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        self.config_path = config_path
        if use_collaboration and not config_path:
            self.config_path = "cfs_config.yaml"
        elif not config_path:
            self.config_path = "config.yaml"
        
        # çµ±è¨ˆæƒ…å ±åˆæœŸåŒ–
        self.evaluation_stats = {
            'total_users': 0,
            'cold_start_users': 0,
            'warm_start_users': 0,
            'avg_user_history_length': 0.0
        }
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.test_data = self._load_test_data()
        self.ground_truth = self._load_ground_truth()
        
        # ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        self._initialize_editors()
        
        logger.info(f"âœ… CFS-LaMP2 è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info(f"   å”èª¿æ©Ÿèƒ½: {'æœ‰åŠ¹' if use_collaboration else 'ç„¡åŠ¹'}")
        logger.info(f"   ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(self.test_data)}")
        logger.info(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def _initialize_editors(self):
        """CFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–"""
        if not CFS_AVAILABLE:
            logger.warning("CFS-Chameleon not available - using fallback mode")
            self.cfs_editor = None
            self.legacy_editor = None
            return
        
        try:
            # å”èª¿ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
            if self.use_collaboration:
                collab_config = self._load_collaboration_config()
                self.cfs_editor = CollaborativeChameleonEditor(
                    use_collaboration=True,
                    collaboration_config=collab_config,
                    config_path=self.config_path
                )
                logger.info("âœ… CFS-Chameleonå”èª¿ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
            else:
                self.cfs_editor = None
            
            # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ï¼ˆæ¯”è¼ƒç”¨ï¼‰
            self.legacy_editor = CollaborativeChameleonEditor(
                use_collaboration=False,
                config_path=self.config_path
            )
            logger.info("âœ… ãƒ¬ã‚¬ã‚·ãƒ¼Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
            # Theta vectorsèª­ã¿è¾¼ã¿
            self._load_theta_vectors()
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.cfs_editor = None
            self.legacy_editor = None
    
    def _load_collaboration_config(self) -> Dict[str, Any]:
        """å”èª¿è¨­å®šèª­ã¿è¾¼ã¿"""
        try:
            import yaml
            config_file = Path(self.config_path)
            if config_file.exists():
                with open(config_file, 'r') as f:
                    config = yaml.safe_load(f)
                return config.get('collaboration', {})
        except Exception as e:
            logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'pool_size': 200,
            'rank_reduction': 32,
            'top_k_pieces': 10,
            'privacy_noise_std': 0.01,
            'enable_learning': False
        }
    
    def _load_test_data(self) -> List[Dict]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯å†åˆ©ç”¨ï¼‰"""
        possible_paths = [
            self.data_path / "chameleon_prime_personalization/data/raw/LaMP-2/merged.json",
            self.data_path / "processed/LaMP-2/merged.json",
            Path("chameleon_prime_personalization/data/raw/LaMP-2/merged.json"),
            Path("processed/LaMP-2/merged.json"),
            self.data_path / "merged.json"
        ]
        
        for merged_path in possible_paths:
            if merged_path.exists():
                logger.info(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {merged_path}")
                with open(merged_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæ›´æ–°
                self._update_user_statistics(data)
                return data
        
        raise FileNotFoundError("merged.json not found in any expected location")
    
    def _load_ground_truth(self) -> Dict[str, str]:
        """æ­£è§£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯å†åˆ©ç”¨ï¼‰"""
        possible_paths = [
            self.data_path / "chameleon_prime_personalization/data/raw/LaMP-2/answers.json",
            self.data_path / "raw/LaMP-2/answers.json",
            Path("chameleon_prime_personalization/data/raw/LaMP-2/answers.json"),
            Path("processed/LaMP-2/answers.json"),
            self.data_path / "answers.json"
        ]
        
        for answers_path in possible_paths:
            if answers_path.exists():
                logger.info(f"âœ… æ­£è§£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {answers_path}")
                with open(answers_path, 'r', encoding='utf-8') as f:
                    answers = json.load(f)
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«åŸºã¥ã„ã¦å‡¦ç†
                ground_truth = {}
                if isinstance(answers, list) and answers:
                    sample = answers[0]
                    if isinstance(sample, dict) and "id" in sample and "output" in sample:
                        ground_truth = {str(ans["id"]): str(ans["output"]).lower().strip() 
                                      for ans in answers}
                
                logger.info(f"   æ­£è§£ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†: {len(ground_truth)} ã‚µãƒ³ãƒ—ãƒ«")
                return ground_truth
        
        logger.warning("æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - æ¯”è¼ƒè©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã§ç¶šè¡Œ")
        return {}
    
    def _load_theta_vectors(self):
        """Theta vectorsèª­ã¿è¾¼ã¿"""
        theta_paths = [
            ("processed/LaMP-2/theta_p.json", "processed/LaMP-2/theta_n.json"),
            ("chameleon_prime_personalization/processed/LaMP-2/theta_p.json", 
             "chameleon_prime_personalization/processed/LaMP-2/theta_n.json")
        ]
        
        for theta_p_path, theta_n_path in theta_paths:
            if Path(theta_p_path).exists() and Path(theta_n_path).exists():
                if self.cfs_editor:
                    self.cfs_editor.load_theta_vectors(theta_p_path, theta_n_path)
                if self.legacy_editor:
                    self.legacy_editor.load_theta_vectors(theta_p_path, theta_n_path)
                logger.info("âœ… Theta vectorsèª­ã¿è¾¼ã¿å®Œäº†")
                return
        
        logger.warning("Theta vectors not found - å”èª¿æ©Ÿèƒ½ã®ã¿ã§è©•ä¾¡")
    
    def _update_user_statistics(self, data: List[Dict]):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæ›´æ–°"""
        user_history_lengths = {}
        for sample in data:
            user_id = str(sample.get('id', ''))[:3]  # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæŠ½å‡º
            profile = sample.get('profile', [])
            user_history_lengths[user_id] = len(profile)
        
        self.evaluation_stats['total_users'] = len(user_history_lengths)
        self.evaluation_stats['cold_start_users'] = sum(1 for length in user_history_lengths.values() if length <= 5)
        self.evaluation_stats['experienced_users'] = sum(1 for length in user_history_lengths.values() if length > 5)
        
        logger.info(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆ: ç·æ•°={self.evaluation_stats['total_users']}, "
                   f"ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ={self.evaluation_stats['cold_start_users']}, "
                   f"çµŒé¨“è±Šå¯Œ={self.evaluation_stats['experienced_users']}")
    
    def evaluate_legacy_chameleon(self) -> CFSEvaluationResult:
        """å¾“æ¥ç‰ˆChameleonè©•ä¾¡"""
        logger.info("ğŸ”„ å¾“æ¥ç‰ˆChameleonè©•ä¾¡é–‹å§‹")
        
        if not self.legacy_editor:
            logger.error("ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None
        
        predictions = []
        start_time = time.time()
        
        for i, sample in enumerate(self.test_data):
            if i % 50 == 0:
                logger.info(f"   é€²æ—: {i}/{len(self.test_data)}")
            
            try:
                # å¾“æ¥ã®Chameleonç”Ÿæˆ
                prompt = self._create_movie_prompt(sample)
                response = self.legacy_editor.generate_with_chameleon(
                    prompt=prompt,
                    alpha_personal=1.5,
                    alpha_neutral=-0.8,
                    max_length=10
                )
                
                prediction = self._extract_tag_from_response(response)
                predictions.append(prediction)
                
            except Exception as e:
                logger.warning(f"ã‚µãƒ³ãƒ—ãƒ«{i}è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                predictions.append("unknown")
        
        inference_time = time.time() - start_time
        return self._calculate_cfs_metrics("Legacy_Chameleon", predictions, inference_time)
    
    def evaluate_cfs_chameleon(self, pool_size: int = 200) -> CFSEvaluationResult:
        """CFS-Chameleonå”èª¿è©•ä¾¡"""
        logger.info("ğŸ”„ CFS-Chameleonå”èª¿è©•ä¾¡é–‹å§‹")
        
        if not self.cfs_editor:
            logger.error("CFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None
        
        # å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰
        self._build_collaboration_pool(pool_size)
        
        predictions = []
        start_time = time.time()
        
        for i, sample in enumerate(self.test_data):
            if i % 50 == 0:
                logger.info(f"   é€²æ—: {i}/{len(self.test_data)}")
            
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæŠ½å‡º
                user_id = str(sample.get('id', ''))[:3]
                
                # CFS-Chameleonå”èª¿ç”Ÿæˆ
                prompt = self._create_movie_prompt(sample)
                response = self.cfs_editor.generate_with_collaborative_chameleon(
                    prompt=prompt,
                    user_id=user_id,
                    alpha_personal=1.5,
                    alpha_neutral=-0.8,
                    max_length=10
                )
                
                prediction = self._extract_tag_from_response(response)
                predictions.append(prediction)
                
                self.evaluation_stats['collaboration_sessions'] += 1
                
            except Exception as e:
                logger.warning(f"ã‚µãƒ³ãƒ—ãƒ«{i}å”èª¿è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                predictions.append("unknown")
        
        inference_time = time.time() - start_time
        result = self._calculate_cfs_metrics("CFS_Chameleon", predictions, inference_time)
        
        # å”èª¿ç‰¹æœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ 
        if self.cfs_editor:
            collab_stats = self.cfs_editor.get_collaboration_statistics()
            result.pool_utilization = collab_stats.get('pool_statistics', {}).get('pool_utilization', 0.0)
            result.user_coverage = collab_stats.get('user_count', 0)
        
        return result
    
    def _build_collaboration_pool(self, pool_size: int):
        """å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰"""
        if not self.cfs_editor:
            return
        
        logger.info(f"ğŸ¤ å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰é–‹å§‹ (ã‚µã‚¤ã‚º: {pool_size})")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ»è¿½åŠ 
        user_profiles = {}
        for sample in self.test_data:
            user_id = str(sample.get('id', ''))[:3]
            if user_id not in user_profiles:
                user_profiles[user_id] = []
            user_profiles[user_id].append(sample)
        
        added_users = 0
        for user_id, samples in list(user_profiles.items())[:pool_size // 10]:
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
                personal_direction = self._generate_user_direction(samples)
                neutral_direction = np.random.randn(len(personal_direction)) * 0.1
                
                # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
                context = self._extract_user_preferences(samples)
                
                success = self.cfs_editor.add_user_direction_to_pool(
                    user_id, personal_direction, neutral_direction, context
                )
                
                if success:
                    added_users += 1
                    
            except Exception as e:
                logger.warning(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{user_id}ã®ãƒ—ãƒ¼ãƒ«è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info(f"âœ… å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰å®Œäº†: {added_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ")
    
    def _generate_user_direction(self, samples: List[Dict]) -> np.ndarray:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºã—ã¦SVDå®Ÿè¡Œ
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ãƒ©ãƒ³ãƒ€ãƒ æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        preferences = []
        for sample in samples[:5]:  # æœ€æ–°5ä»¶
            profile = sample.get('profile', [])
            for item in profile[:3]:
                desc = item.get('description', '').lower()
                if 'action' in desc:
                    preferences.append(0)
                elif 'drama' in desc:
                    preferences.append(1)
                elif 'comedy' in desc:
                    preferences.append(2)
                else:
                    preferences.append(3)
        
        # å—œå¥½ã«åŸºã¥ãæ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        direction = np.random.randn(768)
        if preferences:
            dominant_pref = max(set(preferences), key=preferences.count)
            direction = direction + np.random.randn(768) * (dominant_pref + 1) * 0.2
        
        return direction * 0.1  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    
    def _extract_user_preferences(self, samples: List[Dict]) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½æŠ½å‡º"""
        genres = []
        for sample in samples[:10]:
            profile = sample.get('profile', [])
            for item in profile:
                desc = item.get('description', '').lower()
                if 'action' in desc:
                    genres.append('action')
                elif 'drama' in desc:
                    genres.append('drama')
                elif 'comedy' in desc:
                    genres.append('comedy')
                elif 'horror' in desc:
                    genres.append('horror')
        
        if genres:
            dominant_genre = max(set(genres), key=genres.count)
            return f"{dominant_genre} movie preferences"
        return "general movie preferences"
    
    def _create_movie_prompt(self, sample: Dict) -> str:
        """æ˜ ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"""
        return f"Given the following movie description, provide a single word tag that best describes the movie:\n\nMovie: {sample['input']}\n\nTag:"
    
    def _extract_tag_from_response(self, response: str) -> str:
        """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ã‚¿ã‚°æŠ½å‡º"""
        if not response:
            return "unknown"
        
        # æœ€åˆã®å˜èªã‚’æŠ½å‡º
        words = response.strip().lower().split()
        if words:
            tag = words[0]
            # å¥èª­ç‚¹é™¤å»
            tag = ''.join(c for c in tag if c.isalpha())
            return tag if tag else "unknown"
        
        return "unknown"
    
    def _calculate_cfs_metrics(self, method_name: str, predictions: List[str], 
                              inference_time: float) -> CFSEvaluationResult:
        """CFSæ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        # æ­£è§£ãƒ©ãƒ™ãƒ«å–å¾—
        true_labels = []
        pred_labels = []
        
        for i, sample in enumerate(self.test_data):
            sample_id = str(sample.get('id', ''))
            if sample_id in self.ground_truth:
                true_labels.append(self.ground_truth[sample_id])
                pred_labels.append(predictions[i])
        
        if not true_labels:
            # æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼å€¤
            logger.warning("æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ - ãƒ€ãƒŸãƒ¼å€¤ã§è©•ä¾¡ç¶šè¡Œ")
            return CFSEvaluationResult(
                method_name=method_name,
                accuracy=0.5,
                f1_macro=0.5,
                f1_micro=0.5,
                precision=0.5,
                recall=0.5,
                inference_time=inference_time,
                total_samples=len(predictions),
                correct_predictions=0
            )
        
        # æ¨™æº–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        accuracy = accuracy_score(true_labels, pred_labels)
        f1_macro = f1_score(true_labels, pred_labels, average='macro', zero_division=0)
        f1_micro = f1_score(true_labels, pred_labels, average='micro', zero_division=0)
        precision, recall, _, _ = precision_recall_fscore_support(
            true_labels, pred_labels, average='macro', zero_division=0
        )
        
        correct_predictions = sum(1 for t, p in zip(true_labels, pred_labels) if t == p)
        
        # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½è¨ˆç®—
        cold_start_performance = self._calculate_cold_start_performance(
            true_labels, pred_labels
        )
        
        return CFSEvaluationResult(
            method_name=method_name,
            accuracy=accuracy,
            f1_macro=f1_macro,
            f1_micro=f1_micro,
            precision=precision,
            recall=recall,
            inference_time=inference_time,
            total_samples=len(true_labels),
            correct_predictions=correct_predictions,
            cold_start_performance=cold_start_performance
        )
    
    def _calculate_cold_start_performance(self, true_labels: List[str], 
                                        pred_labels: List[str]) -> float:
        """ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½è¨ˆç®—"""
        cold_start_correct = 0
        cold_start_total = 0
        
        for i, sample in enumerate(self.test_data):
            if i >= len(true_labels):
                break
                
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´é•·ã§ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆåˆ¤å®š
            profile = sample.get('profile', [])
            if len(profile) <= 5:  # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼
                cold_start_total += 1
                if true_labels[i] == pred_labels[i]:
                    cold_start_correct += 1
        
        return cold_start_correct / cold_start_total if cold_start_total > 0 else 0.0
    
    def run_comparison_evaluation(self) -> ComparisonResults:
        """å¾“æ¥ç‰ˆ vs CFS-Chameleonæ¯”è¼ƒè©•ä¾¡"""
        logger.info("ğŸš€ CFS-Chameleonæ¯”è¼ƒè©•ä¾¡é–‹å§‹")
        logger.info("=" * 60)
        
        # 1. å¾“æ¥ç‰ˆè©•ä¾¡
        legacy_results = self.evaluate_legacy_chameleon()
        
        # 2. CFS-Chameleonè©•ä¾¡
        cfs_results = self.evaluate_cfs_chameleon()
        
        if not legacy_results or not cfs_results:
            logger.error("è©•ä¾¡çµæœãŒä¸å®Œå…¨ã§ã™")
            return None
        
        # 3. æ¯”è¼ƒåˆ†æ
        improvement_rate = ((cfs_results.accuracy - legacy_results.accuracy) / 
                          legacy_results.accuracy * 100) if legacy_results.accuracy > 0 else 0.0
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        statistical_significance = self._statistical_significance_test(
            legacy_results, cfs_results
        )
        
        # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ”¹å–„
        cold_start_improvement = ((cfs_results.cold_start_performance - 
                                 legacy_results.cold_start_performance) * 100)
        
        # å”èª¿åŠ¹æœæ¸¬å®š
        collaboration_effectiveness = self._calculate_collaboration_effectiveness()
        
        comparison_results = ComparisonResults(
            legacy_results=legacy_results,
            cfs_results=cfs_results,
            improvement_rate=improvement_rate,
            statistical_significance=statistical_significance,
            cold_start_improvement=cold_start_improvement,
            collaboration_effectiveness=collaboration_effectiveness
        )
        
        # çµæœä¿å­˜ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._save_comparison_results(comparison_results)
        self._generate_comparison_report(comparison_results)
        
        return comparison_results
    
    def _statistical_significance_test(self, legacy: CFSEvaluationResult, 
                                     cfs: CFSEvaluationResult) -> float:
        """çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š"""
        # ç°¡æ˜“çš„ãªtæ¤œå®šï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¿…è¦ï¼‰
        if legacy.total_samples < 10 or cfs.total_samples < 10:
            return 1.0
        
        # æ­£è§£ç‡å·®ã®æ¤œå®š
        legacy_rate = legacy.correct_predictions / legacy.total_samples
        cfs_rate = cfs.correct_predictions / cfs.total_samples
        
        # ç°¡æ˜“tæ¤œå®š
        pooled_std = np.sqrt((legacy_rate * (1 - legacy_rate) / legacy.total_samples) +
                            (cfs_rate * (1 - cfs_rate) / cfs.total_samples))
        
        if pooled_std == 0:
            return 1.0
        
        t_stat = abs(cfs_rate - legacy_rate) / pooled_std
        # ç°¡æ˜“på€¤è¨ˆç®—ï¼ˆæ­£ç¢ºã«ã¯tåˆ†å¸ƒã‚’ä½¿ç”¨ï¼‰
        p_value = max(0.001, 2 * (1 - stats.norm.cdf(abs(t_stat))))
        
        return p_value
    
    def _calculate_collaboration_effectiveness(self) -> float:
        """å”èª¿åŠ¹æœæ¸¬å®š"""
        if not self.cfs_editor:
            return 0.0
        
        collab_stats = self.cfs_editor.get_collaboration_statistics()
        if not collab_stats.get('collaboration_enabled', False):
            return 0.0
        
        # å”èª¿ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã«åŸºã¥ãåŠ¹æœæŒ‡æ¨™
        total_sessions = self.evaluation_stats.get('collaboration_sessions', 0)
        total_samples = len(self.test_data)
        
        effectiveness = (total_sessions / total_samples) if total_samples > 0 else 0.0
        return min(effectiveness, 1.0)
    
    def _save_comparison_results(self, results: ComparisonResults):
        """æ¯”è¼ƒçµæœä¿å­˜"""
        results_dict = {
            'legacy_chameleon': {
                'accuracy': results.legacy_results.accuracy,
                'f1_macro': results.legacy_results.f1_macro,
                'precision': results.legacy_results.precision,
                'recall': results.legacy_results.recall,
                'inference_time': results.legacy_results.inference_time,
                'cold_start_performance': results.legacy_results.cold_start_performance
            },
            'cfs_chameleon': {
                'accuracy': results.cfs_results.accuracy,
                'f1_macro': results.cfs_results.f1_macro,
                'precision': results.cfs_results.precision,
                'recall': results.cfs_results.recall,
                'inference_time': results.cfs_results.inference_time,
                'cold_start_performance': results.cfs_results.cold_start_performance,
                'pool_utilization': results.cfs_results.pool_utilization,
                'user_coverage': results.cfs_results.user_coverage
            },
            'comparison_metrics': {
                'improvement_rate': results.improvement_rate,
                'statistical_significance': results.statistical_significance,
                'cold_start_improvement': results.cold_start_improvement,
                'collaboration_effectiveness': results.collaboration_effectiveness
            },
            'evaluation_stats': self.evaluation_stats
        }
        
        results_file = self.output_dir / "cfs_comparison_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æ¯”è¼ƒçµæœä¿å­˜: {results_file}")
    
    def _generate_comparison_report(self, results: ComparisonResults):
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š CFS-Chameleon LaMP-2 æ¯”è¼ƒè©•ä¾¡çµæœ")
        print("=" * 60)
        
        print(f"\nğŸ”¸ å¾“æ¥ç‰ˆChameleon:")
        print(f"   ç²¾åº¦:         {results.legacy_results.accuracy:.4f}")
        print(f"   F1ã‚¹ã‚³ã‚¢:     {results.legacy_results.f1_macro:.4f}")
        print(f"   æ¨è«–æ™‚é–“:     {results.legacy_results.inference_time:.2f}ç§’")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ: {results.legacy_results.cold_start_performance:.4f}")
        
        print(f"\nğŸ¦ CFS-Chameleon:")
        print(f"   ç²¾åº¦:         {results.cfs_results.accuracy:.4f}")
        print(f"   F1ã‚¹ã‚³ã‚¢:     {results.cfs_results.f1_macro:.4f}")
        print(f"   æ¨è«–æ™‚é–“:     {results.cfs_results.inference_time:.2f}ç§’")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ: {results.cfs_results.cold_start_performance:.4f}")
        print(f"   ãƒ—ãƒ¼ãƒ«åˆ©ç”¨ç‡:   {results.cfs_results.pool_utilization:.2%}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¯„å›²:   {results.cfs_results.user_coverage}äºº")
        
        print(f"\nğŸ“ˆ æ”¹å–„åŠ¹æœ:")
        print(f"   å…¨ä½“æ”¹å–„ç‡:     {results.improvement_rate:+.1f}%")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ”¹å–„: {results.cold_start_improvement:+.1f}pt")
        print(f"   çµ±è¨ˆçš„æœ‰æ„æ€§:   p = {results.statistical_significance:.4f}")
        print(f"   å”èª¿åŠ¹æœ:       {results.collaboration_effectiveness:.2%}")
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§ã®åˆ¤å®š
        if results.statistical_significance < 0.05:
            print("   âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„!")
        else:
            print("   âš ï¸  çµ±è¨ˆçš„æœ‰æ„æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        # å¯è¦–åŒ–ç”Ÿæˆ
        self._plot_cfs_comparison(results)
    
    def _plot_cfs_comparison(self, results: ComparisonResults):
        """æ¯”è¼ƒçµæœå¯è¦–åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        methods = ['Legacy Chameleon', 'CFS-Chameleon']
        
        # 1. ç²¾åº¦ãƒ»F1æ¯”è¼ƒ
        accuracies = [results.legacy_results.accuracy, results.cfs_results.accuracy]
        f1_scores = [results.legacy_results.f1_macro, results.cfs_results.f1_macro]
        
        x = np.arange(len(methods))
        width = 0.35
        
        axes[0, 0].bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8)
        axes[0, 0].bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8)
        axes[0, 0].set_xlabel('Method')
        axes[0, 0].set_ylabel('Score')
        axes[0, 0].set_title('Performance Comparison')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(methods)
        axes[0, 0].legend()
        axes[0, 0].set_ylim(0, 1)
        
        # 2. ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ¯”è¼ƒ
        cold_start_scores = [results.legacy_results.cold_start_performance, 
                           results.cfs_results.cold_start_performance]
        
        axes[0, 1].bar(methods, cold_start_scores, alpha=0.8, color='green')
        axes[0, 1].set_xlabel('Method')
        axes[0, 1].set_ylabel('Cold-start Performance')
        axes[0, 1].set_title('Cold-start User Performance')
        axes[0, 1].set_ylim(0, 1)
        
        # 3. æ¨è«–æ™‚é–“æ¯”è¼ƒ
        inference_times = [results.legacy_results.inference_time, 
                         results.cfs_results.inference_time]
        
        axes[1, 0].bar(methods, inference_times, alpha=0.8, color='orange')
        axes[1, 0].set_xlabel('Method')
        axes[1, 0].set_ylabel('Inference Time (seconds)')
        axes[1, 0].set_title('Inference Time Comparison')
        
        # 4. æ”¹å–„ç‡ã‚µãƒãƒªãƒ¼
        improvements = [
            ('Overall', results.improvement_rate),
            ('Cold-start', results.cold_start_improvement),
            ('Collaboration', results.collaboration_effectiveness * 100)
        ]
        
        improvement_names = [imp[0] for imp in improvements]
        improvement_values = [imp[1] for imp in improvements]
        
        colors = ['blue' if v > 0 else 'red' for v in improvement_values]
        axes[1, 1].bar(improvement_names, improvement_values, alpha=0.8, color=colors)
        axes[1, 1].set_xlabel('Improvement Type')
        axes[1, 1].set_ylabel('Improvement (%)')
        axes[1, 1].set_title('CFS-Chameleon Improvements')
        axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / "cfs_comparison_visualization.png", 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“ˆ æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜: {self.output_dir / 'cfs_comparison_visualization.png'}")

def create_enhanced_argument_parser():
    """æ‹¡å¼µå¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼"""
    parser = argparse.ArgumentParser(description='LaMP-2 CFS-Chameleonçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯')
    
    # æ—¢å­˜å¼•æ•°ä¿æŒ
    parser.add_argument('--data_path', default='./chameleon_prime_personalization/data', 
                       help='LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹')
    parser.add_argument('--output_dir', default='./cfs_evaluation_results', 
                       help='çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # CFS-Chameleonæ–°è¦è¿½åŠ å¼•æ•°
    parser.add_argument('--use_collaboration', action='store_true',
                       help='CFS-Chameleonå”èª¿æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--config', type=str, default=None,
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (cfs_config.yaml or config.yaml)')
    parser.add_argument('--collaboration_mode', choices=['heuristic', 'learned'],
                       default='heuristic', help='å”èª¿é¸æŠæˆ¦ç•¥')
    parser.add_argument('--compare_modes', action='store_true',
                       help='å¾“æ¥ç‰ˆvså”èª¿ç‰ˆã®æ¯”è¼ƒè©•ä¾¡å®Ÿè¡Œ')
    parser.add_argument('--cold_start_test', action='store_true',
                       help='ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ€§èƒ½è©•ä¾¡')
    parser.add_argument('--pool_size', type=int, default=200,
                       help='å”èª¿æ–¹å‘ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º')
    parser.add_argument('--evaluation_mode', choices=['legacy', 'cfs', 'comparison'],
                       default='comparison', help='è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰é¸æŠ')
    
    return parser

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = create_enhanced_argument_parser()
    args = parser.parse_args()
    
    logger.info("ğŸš€ CFS-Chameleon LaMP-2 çµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
    logger.info(f"   å”èª¿æ©Ÿèƒ½: {'æœ‰åŠ¹' if args.use_collaboration else 'ç„¡åŠ¹'}")
    logger.info(f"   è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰: {args.evaluation_mode}")
    
    # è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    evaluator = CFSLaMP2Evaluator(
        data_path=args.data_path,
        output_dir=args.output_dir,
        config_path=args.config,
        use_collaboration=args.use_collaboration,
        collaboration_mode=args.collaboration_mode
    )
    
    try:
        if args.compare_modes or args.evaluation_mode == 'comparison':
            # æ¯”è¼ƒè©•ä¾¡å®Ÿè¡Œ
            results = evaluator.run_comparison_evaluation()
            
            if results:
                print(f"\nâœ… CFS-Chameleonæ¯”è¼ƒè©•ä¾¡å®Œäº†!")
                print(f"ğŸ“Š æ”¹å–„ç‡: {results.improvement_rate:+.1f}%")
                print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {args.output_dir}")
            else:
                print("âŒ æ¯”è¼ƒè©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        elif args.evaluation_mode == 'legacy':
            # å¾“æ¥ç‰ˆã®ã¿è©•ä¾¡
            results = evaluator.evaluate_legacy_chameleon()
            if results:
                print(f"âœ… å¾“æ¥ç‰ˆChameleonè©•ä¾¡å®Œäº†: ç²¾åº¦={results.accuracy:.4f}")
            
        elif args.evaluation_mode == 'cfs':
            # CFS-Chameleonã®ã¿è©•ä¾¡
            results = evaluator.evaluate_cfs_chameleon(args.pool_size)
            if results:
                print(f"âœ… CFS-Chameleonè©•ä¾¡å®Œäº†: ç²¾åº¦={results.accuracy:.4f}")
        
        logger.info("ğŸ‰ ã™ã¹ã¦ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸ!")
        
    except Exception as e:
        logger.error(f"è©•ä¾¡å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()