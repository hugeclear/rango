#!/usr/bin/env python3
"""
LaMP-2 CFS-Chameleonçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ 
å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½è©•ä¾¡ãƒ»æ¯”è¼ƒã‚’è¡Œã†ä¸–ç•Œåˆã®è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

ç‰¹å¾´:
- å¾“æ¥ç‰ˆChameleon vs CFS-Chameleonæ€§èƒ½æ¯”è¼ƒ
- ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½åˆ†æ
- å”èª¿å­¦ç¿’åŠ¹æœã®å®šé‡è©•ä¾¡
- çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
- å®Œå…¨ä¸‹ä½äº’æ›æ€§ä¿è¨¼
"""

import json
import os
import time
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import numpy as np
import torch
from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
import logging

# CFS-Chameleonçµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from chameleon_cfs_integrator import CollaborativeChameleonEditor
    from cfs_chameleon_extension import CollaborativeDirectionPool, UserContext
    from chameleon_evaluator import ChameleonEvaluator
    CFS_AVAILABLE = True
except ImportError as e:
    print(f"âš ï¸ CFS-Chameleon modules not available: {e}")
    CFS_AVAILABLE = False

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass 
class CFSEvaluationResult:
    """CFS-Chameleonæ‹¡å¼µè©•ä¾¡çµæœ"""
    method_name: str
    accuracy: float
    f1_macro: float
    f1_micro: float
    precision: float
    recall: float
    inference_time: float
    total_samples: int
    correct_predictions: int
    
    # CFSæ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹
    collaboration_benefit: float = 0.0
    cold_start_performance: float = 0.0
    pool_utilization: float = 0.0
    user_coverage: int = 0
    privacy_preservation: float = 0.0

@dataclass
class ComparisonResults:
    """æ¯”è¼ƒè©•ä¾¡çµæœ"""
    legacy_results: CFSEvaluationResult
    cfs_results: CFSEvaluationResult
    improvement_rate: float
    statistical_significance: float
    cold_start_improvement: float
    collaboration_effectiveness: float

class CFSLaMP2Evaluator:
    """CFS-Chameleonçµ±åˆLaMP-2è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, data_path: str, output_dir: str = "./cfs_evaluation_results", 
                 config_path: str = None, use_collaboration: bool = False,
                 collaboration_mode: str = "heuristic", sample_limit: int = None,
                 alpha_p_override: float = None, alpha_n_override: float = None,
                 max_length_override: int = None, debug_mode: bool = False):
        
        self.data_path = Path(data_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.use_collaboration = use_collaboration
        self.collaboration_mode = collaboration_mode
        self.sample_limit = sample_limit
        
        # ğŸš€ Chameleonãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ï¼‰
        self.alpha_p_override = alpha_p_override
        self.alpha_n_override = alpha_n_override  
        self.max_length_override = max_length_override
        self.debug_mode = debug_mode
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        self.config_path = config_path
        if use_collaboration and not config_path:
            self.config_path = "cfs_config.yaml"
        elif not config_path:
            self.config_path = "config.yaml"
        
        # çµ±è¨ˆæƒ…å ±åˆæœŸåŒ–
        self.evaluation_stats = {
            'total_users': 0,
            'cold_start_users': 0,
            'warm_start_users': 0,
            'avg_user_history_length': 0.0,
            'collaboration_sessions': 0  # ğŸ”§ PRODUCTION FIX: Missing key causing KeyError
        }
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.test_data = self._load_test_data()
        self.ground_truth = self._load_ground_truth()
        
        # ğŸ”§ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œå…¨å»ƒæ­¢ã®ãŸã‚ï¼‰
        self._validate_data_integrity()
        
        # ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        self._initialize_editors()
        
        logger.info(f"âœ… CFS-LaMP2 è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info(f"   å”èª¿æ©Ÿèƒ½: {'æœ‰åŠ¹' if use_collaboration else 'ç„¡åŠ¹'}")
        logger.info(f"   ãƒ†ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«æ•°: {len(self.test_data)}")
        logger.info(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def _initialize_editors(self):
        """CFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–"""
        if not CFS_AVAILABLE:
            logger.warning("CFS-Chameleon not available - using fallback mode")
            self.cfs_editor = None
            self.legacy_editor = None
            return
        
        try:
            # å”èª¿ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
            if self.use_collaboration:
                collab_config = self._load_collaboration_config()
                self.cfs_editor = CollaborativeChameleonEditor(
                    use_collaboration=True,
                    collaboration_config=collab_config,
                    config_path=self.config_path
                )
                logger.info("âœ… CFS-Chameleonå”èª¿ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
            else:
                self.cfs_editor = None
            
            # ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ï¼ˆæ¯”è¼ƒç”¨ï¼‰
            self.legacy_editor = CollaborativeChameleonEditor(
                use_collaboration=False,
                config_path=self.config_path
            )
            logger.info("âœ… ãƒ¬ã‚¬ã‚·ãƒ¼Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
            # Theta vectorsèª­ã¿è¾¼ã¿
            self._load_theta_vectors()
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.cfs_editor = None
            self.legacy_editor = None
    
    def _load_collaboration_config(self) -> Dict[str, Any]:
        """å”èª¿è¨­å®šèª­ã¿è¾¼ã¿"""
        try:
            import yaml
            config_file = Path(self.config_path)
            if config_file.exists():
                with open(config_file, 'r') as f:
                    config = yaml.safe_load(f)
                return config.get('collaboration', {})
        except Exception as e:
            logger.warning(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'pool_size': 200,
            'rank_reduction': 32,
            'top_k_pieces': 10,
            'privacy_noise_std': 0.01,
            'enable_learning': False
        }
    
    def _load_test_data(self) -> List[Dict]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯å†åˆ©ç”¨ï¼‰"""
        possible_paths = [
            self.data_path / "chameleon_prime_personalization/data/raw/LaMP-2/merged.json",
            self.data_path / "processed/LaMP-2/merged.json",
            Path("chameleon_prime_personalization/data/raw/LaMP-2/merged.json"),
            Path("processed/LaMP-2/merged.json"),
            self.data_path / "merged.json"
        ]
        
        for merged_path in possible_paths:
            if merged_path.exists():
                logger.info(f"âœ… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {merged_path}")
                with open(merged_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                # ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™é©ç”¨
                if self.sample_limit:
                    data = data[:self.sample_limit]
                    logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«åˆ¶é™é©ç”¨: {len(data)} samples (limit: {self.sample_limit})")
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæ›´æ–°
                self._update_user_statistics(data)
                return data
        
        raise FileNotFoundError("merged.json not found in any expected location")
    
    def _load_ground_truth(self) -> Dict[str, str]:
        """æ­£è§£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯å†åˆ©ç”¨ï¼‰"""
        possible_paths = [
            self.data_path / "chameleon_prime_personalization/data/raw/LaMP-2/answers.json",
            self.data_path / "raw/LaMP-2/answers.json",
            Path("chameleon_prime_personalization/data/raw/LaMP-2/answers.json"),
            Path("processed/LaMP-2/answers.json"),
            self.data_path / "answers.json"
        ]
        
        for answers_path in possible_paths:
            if answers_path.exists():
                logger.info(f"âœ… æ­£è§£ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {answers_path}")
                with open(answers_path, 'r', encoding='utf-8') as f:
                    answers = json.load(f)
                
                # ğŸ”§ LaMP-2å…¬å¼ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¯¾å¿œ: {"task":"LaMP_2", "golds":[...]}
                ground_truth = {}
                if isinstance(answers, dict) and "golds" in answers:
                    # å…¬å¼LaMP-2å½¢å¼
                    golds = answers["golds"]
                    if isinstance(golds, list) and golds:
                        ground_truth = {str(ans["id"]): str(ans["output"]).lower().strip() 
                                      for ans in golds if "id" in ans and "output" in ans}
                elif isinstance(answers, list) and answers:
                    # å¾“æ¥å½¢å¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    sample = answers[0]
                    if isinstance(sample, dict) and "id" in sample and "output" in sample:
                        ground_truth = {str(ans["id"]): str(ans["output"]).lower().strip() 
                                      for ans in answers}
                
                logger.info(f"   æ­£è§£ãƒ‡ãƒ¼ã‚¿å¤‰æ›å®Œäº†: {len(ground_truth)} ã‚µãƒ³ãƒ—ãƒ«")
                return ground_truth
        
        # ğŸš¨ CRITICAL: LaMP-2å…¬å¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã®ã¯ç•°å¸¸
        error_msg = "âŒ CRITICAL: æ­£è§£ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ - LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä¸å®Œå…¨ã§ã™"
        logger.error(error_msg)
        raise FileNotFoundError(f"{error_msg}. ç¢ºèªã—ã¦ãã ã•ã„: answers.json ãŒæ­£ã—ã„å ´æ‰€ã«å­˜åœ¨ã™ã‚‹ã‹")
    
    def _load_theta_vectors(self):
        """Theta vectorsèª­ã¿è¾¼ã¿"""
        theta_paths = [
            ("processed/LaMP-2/theta_p.json", "processed/LaMP-2/theta_n.json"),
            ("chameleon_prime_personalization/processed/LaMP-2/theta_p.json", 
             "chameleon_prime_personalization/processed/LaMP-2/theta_n.json")
        ]
        
        for theta_p_path, theta_n_path in theta_paths:
            if Path(theta_p_path).exists() and Path(theta_n_path).exists():
                if self.cfs_editor:
                    self.cfs_editor.load_theta_vectors(theta_p_path, theta_n_path)
                if self.legacy_editor:
                    self.legacy_editor.load_theta_vectors(theta_p_path, theta_n_path)
                logger.info("âœ… Theta vectorsèª­ã¿è¾¼ã¿å®Œäº†")
                return
        
        logger.warning("Theta vectors not found - å”èª¿æ©Ÿèƒ½ã®ã¿ã§è©•ä¾¡")
    
    def _validate_data_integrity(self):
        """
        ğŸš¨ CRITICAL: LaMP-2ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
        
        ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Œå…¨å»ƒæ­¢ã®ãŸã‚ã€è©•ä¾¡å‰ã«å¿…ãšãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ç¢ºèªã€‚
        ä¸æ•´åˆãŒã‚ã‚Œã°å³åº§ã«ä¾‹å¤–ã‚’æŠ•ã’ã¦ã‚·ã‚¹ãƒ†ãƒ ã‚’åœæ­¢ã™ã‚‹ã€‚
        """
        logger.info("ğŸ”§ LaMP-2ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯é–‹å§‹")
        
        if not self.test_data:
            error_msg = "âŒ CRITICAL: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™"
            logger.error(error_msg)
            raise RuntimeError(f"{error_msg} - ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¦ã„ã¾ã™")
        
        if not self.ground_truth:
            error_msg = "âŒ CRITICAL: æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™"
            logger.error(error_msg)
            raise RuntimeError(f"{error_msg} - LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒä¸å®Œå…¨ã§ã™")
        
        # ã‚µãƒ³ãƒ—ãƒ«IDã¨æ­£è§£ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
        missing_answers = []
        sample_ids = []
        
        for sample in self.test_data:
            sample_id = str(sample.get('id', ''))
            sample_ids.append(sample_id)
            
            if sample_id not in self.ground_truth:
                missing_answers.append(sample_id)
        
        # æ¬ æãƒã‚§ãƒƒã‚¯
        if missing_answers:
            error_msg = (f"âŒ CRITICAL: æ¬¡ã®{len(missing_answers)}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ã«æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“: "
                        f"{missing_answers[:10]}{'...' if len(missing_answers) > 10 else ''}")
            logger.error(error_msg)
            logger.error(f"   ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(sample_ids)}")
            logger.error(f"   æ­£è§£ãƒ‡ãƒ¼ã‚¿æ•°: {len(self.ground_truth)}")
            logger.error(f"   æ¬ æã‚µãƒ³ãƒ—ãƒ«æ•°: {len(missing_answers)}")
            raise RuntimeError(f"{error_msg} - LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•´åˆæ€§ã‚¨ãƒ©ãƒ¼")
        
        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        success_msg = (f"âœ… LaMP-2ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Œäº†: "
                      f"ã‚µãƒ³ãƒ—ãƒ«{len(self.test_data)}ä»¶ã€æ­£è§£{len(self.ground_truth)}ä»¶ã€100%ä¸€è‡´")
        logger.info(success_msg)
        print(success_msg)
    
    def _update_user_statistics(self, data: List[Dict]):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆæ›´æ–°"""
        user_history_lengths = {}
        for sample in data:
            user_id = str(sample.get('id', ''))[:3]  # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæŠ½å‡º
            profile = sample.get('profile', [])
            user_history_lengths[user_id] = len(profile)
        
        self.evaluation_stats['total_users'] = len(user_history_lengths)
        self.evaluation_stats['cold_start_users'] = sum(1 for length in user_history_lengths.values() if length <= 5)
        self.evaluation_stats['experienced_users'] = sum(1 for length in user_history_lengths.values() if length > 5)
        
        logger.info(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼çµ±è¨ˆ: ç·æ•°={self.evaluation_stats['total_users']}, "
                   f"ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ={self.evaluation_stats['cold_start_users']}, "
                   f"çµŒé¨“è±Šå¯Œ={self.evaluation_stats['experienced_users']}")
    
    def evaluate_legacy_chameleon(self) -> CFSEvaluationResult:
        """å¾“æ¥ç‰ˆChameleonè©•ä¾¡"""
        logger.info("ğŸ”„ å¾“æ¥ç‰ˆChameleonè©•ä¾¡é–‹å§‹")
        
        if not self.legacy_editor:
            logger.error("ãƒ¬ã‚¬ã‚·ãƒ¼ã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None
        
        predictions = []
        start_time = time.time()
        
        for i, sample in enumerate(self.test_data):
            if i % 50 == 0:
                logger.info(f"   é€²æ—: {i}/{len(self.test_data)}")
            
            try:
                # ğŸš€ ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šï¼‰
                alpha_p = self.alpha_p_override if self.alpha_p_override is not None else 1.5
                alpha_n = self.alpha_n_override if self.alpha_n_override is not None else -0.8
                max_len = self.max_length_override if self.max_length_override is not None else 10
                
                # å¾“æ¥ã®Chameleonç”Ÿæˆ
                prompt = self._create_movie_prompt(sample)
                response = self.legacy_editor.generate_with_chameleon(
                    prompt=prompt,
                    alpha_personal=alpha_p,
                    alpha_neutral=alpha_n,
                    max_length=max_len
                )
                
                prediction = self._extract_tag_from_response(response)
                predictions.append(prediction)
                
                # ğŸš€ ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºï¼ˆã‚¹ã‚³ã‚¢åˆ†æã®ãŸã‚ï¼‰
                if hasattr(self, 'debug_mode') and getattr(self, 'debug_mode', False):
                    sample_id = str(sample.get('id', ''))
                    actual_answer = self.ground_truth.get(sample_id, 'unknown')
                    logger.info(f"   [Legacy] Sample {sample_id}: Predicted='{prediction}', Actual='{actual_answer}', Response='{response[:100]}...'")
                    if prediction == actual_answer:
                        logger.info(f"   âœ… MATCH!")
                    else:
                        logger.info(f"   âŒ MISMATCH")
                
            except Exception as e:
                logger.warning(f"ã‚µãƒ³ãƒ—ãƒ«{i}è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                predictions.append("unknown")
        
        inference_time = time.time() - start_time
        return self._calculate_cfs_metrics("Legacy_Chameleon", predictions, inference_time)
    
    def evaluate_cfs_chameleon(self, pool_size: int = 200) -> CFSEvaluationResult:
        """CFS-Chameleonå”èª¿è©•ä¾¡"""
        logger.info("ğŸ”„ CFS-Chameleonå”èª¿è©•ä¾¡é–‹å§‹")
        
        if not self.cfs_editor:
            logger.error("CFS-Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return None
        
        # å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰
        self._build_collaboration_pool(pool_size)
        
        predictions = []
        start_time = time.time()
        
        for i, sample in enumerate(self.test_data):
            if i % 50 == 0:
                logger.info(f"   é€²æ—: {i}/{len(self.test_data)}")
            
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDæŠ½å‡º
                user_id = str(sample.get('id', ''))[:3]
                
                # ğŸš€ ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šï¼‰
                alpha_p = self.alpha_p_override if self.alpha_p_override is not None else 1.5
                alpha_n = self.alpha_n_override if self.alpha_n_override is not None else -0.8
                max_len = self.max_length_override if self.max_length_override is not None else 10
                
                # CFS-Chameleonå”èª¿ç”Ÿæˆ
                prompt = self._create_movie_prompt(sample)
                response = self.cfs_editor.generate_with_collaborative_chameleon(
                    prompt=prompt,
                    user_id=user_id,
                    alpha_personal=alpha_p,
                    alpha_neutral=alpha_n,
                    max_length=max_len
                )
                
                prediction = self._extract_tag_from_response(response)
                predictions.append(prediction)
                
                # ğŸš€ ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¡¨ç¤ºï¼ˆã‚¹ã‚³ã‚¢åˆ†æã®ãŸã‚ï¼‰
                if hasattr(self, 'debug_mode') and getattr(self, 'debug_mode', False):
                    sample_id = str(sample.get('id', ''))
                    actual_answer = self.ground_truth.get(sample_id, 'unknown')
                    logger.info(f"   [CFS] Sample {sample_id}: Predicted='{prediction}', Actual='{actual_answer}', Response='{response[:100]}...'")
                    if prediction == actual_answer:
                        logger.info(f"   âœ… MATCH!")
                    else:
                        logger.info(f"   âŒ MISMATCH")
                
                self.evaluation_stats['collaboration_sessions'] += 1
                
            except Exception as e:
                logger.warning(f"ã‚µãƒ³ãƒ—ãƒ«{i}å”èª¿è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
                predictions.append("unknown")
        
        inference_time = time.time() - start_time
        result = self._calculate_cfs_metrics("CFS_Chameleon", predictions, inference_time)
        
        # å”èª¿ç‰¹æœ‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¿½åŠ 
        if self.cfs_editor:
            collab_stats = self.cfs_editor.get_collaboration_statistics()
            result.pool_utilization = collab_stats.get('pool_statistics', {}).get('pool_utilization', 0.0)
            result.user_coverage = collab_stats.get('user_count', 0)
        
        return result
    
    def _build_collaboration_pool(self, pool_size: int):
        """å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰"""
        if not self.cfs_editor:
            return
        
        logger.info(f"ğŸ¤ å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰é–‹å§‹ (ã‚µã‚¤ã‚º: {pool_size})")
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆãƒ»è¿½åŠ 
        user_profiles = {}
        for sample in self.test_data:
            user_id = str(sample.get('id', ''))[:3]
            if user_id not in user_profiles:
                user_profiles[user_id] = []
            user_profiles[user_id].append(sample)
        
        added_users = 0
        for user_id, samples in list(user_profiles.items())[:pool_size // 10]:
            try:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰
                personal_direction = self._generate_user_direction(samples)
                neutral_direction = np.random.randn(len(personal_direction)) * 0.1
                
                # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
                context = self._extract_user_preferences(samples)
                
                success = self.cfs_editor.add_user_direction_to_pool(
                    user_id, personal_direction, neutral_direction, context
                )
                
                if success:
                    added_users += 1
                    
            except Exception as e:
                logger.warning(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼{user_id}ã®ãƒ—ãƒ¼ãƒ«è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info(f"âœ… å”èª¿ãƒ—ãƒ¼ãƒ«æ§‹ç¯‰å®Œäº†: {added_users}ãƒ¦ãƒ¼ã‚¶ãƒ¼è¿½åŠ ")
    
    def _generate_user_direction(self, samples: List[Dict]) -> np.ndarray:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡ºã—ã¦SVDå®Ÿè¡Œ
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ãƒ©ãƒ³ãƒ€ãƒ æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        preferences = []
        for sample in samples[:5]:  # æœ€æ–°5ä»¶
            profile = sample.get('profile', [])
            for item in profile[:3]:
                desc = item.get('description', '').lower()
                if 'action' in desc:
                    preferences.append(0)
                elif 'drama' in desc:
                    preferences.append(1)
                elif 'comedy' in desc:
                    preferences.append(2)
                else:
                    preferences.append(3)
        
        # å—œå¥½ã«åŸºã¥ãæ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        direction = np.random.randn(768)
        if preferences:
            dominant_pref = max(set(preferences), key=preferences.count)
            direction = direction + np.random.randn(768) * (dominant_pref + 1) * 0.2
        
        return direction * 0.1  # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
    
    def _extract_user_preferences(self, samples: List[Dict]) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å—œå¥½æŠ½å‡º"""
        genres = []
        for sample in samples[:10]:
            profile = sample.get('profile', [])
            for item in profile:
                desc = item.get('description', '').lower()
                if 'action' in desc:
                    genres.append('action')
                elif 'drama' in desc:
                    genres.append('drama')
                elif 'comedy' in desc:
                    genres.append('comedy')
                elif 'horror' in desc:
                    genres.append('horror')
        
        if genres:
            dominant_genre = max(set(genres), key=genres.count)
            return f"{dominant_genre} movie preferences"
        return "general movie preferences"
    
    def _create_movie_prompt(self, sample: Dict) -> str:
        """ğŸš€ æ”¹è‰¯ç‰ˆæ˜ ç”»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ï¼‰"""
        # ã‚ˆã‚Šå…·ä½“çš„ã§å³å¯†ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        genre_examples = "action, comedy, drama, horror, romance, sci-fi, fantasy, thriller, crime, classic, violence, dark comedy, twist ending, true story, based on a book, thought-provoking, social commentary, psychology, dystopia"
        
        return f"""Classify the following movie into ONE specific genre tag. Choose the most accurate tag from these options: {genre_examples}

Movie Description: {sample['input']}

Most accurate genre tag:"""
    
    def _extract_tag_from_response(self, response: str) -> str:
        """ğŸš€ æ”¹è‰¯ç‰ˆã‚¿ã‚°æŠ½å‡ºï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ï¼‰"""
        if not response:
            return "unknown"
        
        # ã‚ˆã‚Šå³å¯†ãªã‚¿ã‚°æŠ½å‡ºã¨ãƒãƒƒãƒ”ãƒ³ã‚°
        response = response.strip().lower()
        
        # ä¸€èˆ¬çš„ãªæ˜ ç”»ã‚¸ãƒ£ãƒ³ãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        genre_keywords = {
            'action': ['action', 'fight', 'war', 'battle', 'adventure'],
            'comedy': ['comedy', 'funny', 'humor', 'laugh', 'comic'],
            'drama': ['drama', 'dramatic', 'emotional'],
            'horror': ['horror', 'scary', 'fear', 'terror'],
            'romance': ['romance', 'love', 'romantic'],
            'sci-fi': ['sci-fi', 'science', 'future', 'space', 'robot'],
            'fantasy': ['fantasy', 'magic', 'wizard', 'supernatural'],
            'thriller': ['thriller', 'suspense', 'mystery'],
            'crime': ['crime', 'criminal', 'police', 'detective'],
            'classic': ['classic', 'old', 'vintage', 'traditional'],
            'violence': ['violence', 'violent', 'brutal', 'killing'],
            'dark comedy': ['dark comedy', 'black comedy', 'dark humor'],
            'twist ending': ['twist', 'surprise', 'unexpected'],
            'true story': ['true story', 'based on', 'real', 'biography'],
            'based on a book': ['book', 'novel', 'adaptation'],
            'thought-provoking': ['thought-provoking', 'deep', 'philosophical'],
            'social commentary': ['social', 'society', 'political', 'commentary'],
            'psychology': ['psychology', 'psychological', 'mind', 'mental'],
            'dystopia': ['dystopia', 'dystopian', 'future society']
        }
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        for genre, keywords in genre_keywords.items():
            for keyword in keywords:
                if keyword in response:
                    return genre
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æœ€åˆã®å˜èªã‚’æŠ½å‡º
        words = response.split()
        if words:
            tag = words[0]
            # å¥èª­ç‚¹é™¤å»
            tag = ''.join(c for c in tag if c.isalpha())
            return tag if tag else "unknown"
        
        return "unknown"
    
    def _calculate_cfs_metrics(self, method_name: str, predictions: List[str], 
                              inference_time: float) -> CFSEvaluationResult:
        """CFSæ‹¡å¼µãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—"""
        # æ­£è§£ãƒ©ãƒ™ãƒ«å–å¾—
        true_labels = []
        pred_labels = []
        
        for i, sample in enumerate(self.test_data):
            sample_id = str(sample.get('id', ''))
            if sample_id in self.ground_truth:
                true_labels.append(self.ground_truth[sample_id])
                pred_labels.append(predictions[i])
        
        if not true_labels:
            # ğŸš¨ CRITICAL: LaMP-2ã§æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒãªã„ã®ã¯çµ¶å¯¾ã«ã‚ã‚Šãˆãªã„
            error_msg = (f"âŒ CRITICAL: ã‚µãƒ³ãƒ—ãƒ«{len(predictions)}ä»¶ä¸­ã€æ­£è§£ãƒ‡ãƒ¼ã‚¿ãŒ0ä»¶ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚"
                        f"LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            logger.error(error_msg)
            raise RuntimeError(f"{error_msg} ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¾ãŸã¯ã‚µãƒ³ãƒ—ãƒ«é¸æŠã«ãƒã‚°ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # æ¨™æº–ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        accuracy = accuracy_score(true_labels, pred_labels)
        f1_macro = f1_score(true_labels, pred_labels, average='macro', zero_division=0)
        f1_micro = f1_score(true_labels, pred_labels, average='micro', zero_division=0)
        precision, recall, _, _ = precision_recall_fscore_support(
            true_labels, pred_labels, average='macro', zero_division=0
        )
        
        correct_predictions = sum(1 for t, p in zip(true_labels, pred_labels) if t == p)
        
        # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½è¨ˆç®—
        cold_start_performance = self._calculate_cold_start_performance(
            true_labels, pred_labels
        )
        
        return CFSEvaluationResult(
            method_name=method_name,
            accuracy=accuracy,
            f1_macro=f1_macro,
            f1_micro=f1_micro,
            precision=precision,
            recall=recall,
            inference_time=inference_time,
            total_samples=len(true_labels),
            correct_predictions=correct_predictions,
            cold_start_performance=cold_start_performance
        )
    
    def _calculate_cold_start_performance(self, true_labels: List[str], 
                                        pred_labels: List[str]) -> float:
        """ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ€§èƒ½è¨ˆç®—"""
        cold_start_correct = 0
        cold_start_total = 0
        
        for i, sample in enumerate(self.test_data):
            if i >= len(true_labels):
                break
                
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å±¥æ­´é•·ã§ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆåˆ¤å®š
            profile = sample.get('profile', [])
            if len(profile) <= 5:  # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼
                cold_start_total += 1
                if true_labels[i] == pred_labels[i]:
                    cold_start_correct += 1
        
        return cold_start_correct / cold_start_total if cold_start_total > 0 else 0.0
    
    def run_comparison_evaluation(self) -> ComparisonResults:
        """å¾“æ¥ç‰ˆ vs CFS-Chameleonæ¯”è¼ƒè©•ä¾¡"""
        logger.info("ğŸš€ CFS-Chameleonæ¯”è¼ƒè©•ä¾¡é–‹å§‹")
        logger.info("=" * 60)
        
        # 1. å¾“æ¥ç‰ˆè©•ä¾¡
        legacy_results = self.evaluate_legacy_chameleon()
        
        # 2. CFS-Chameleonè©•ä¾¡
        cfs_results = self.evaluate_cfs_chameleon()
        
        if not legacy_results or not cfs_results:
            logger.error("è©•ä¾¡çµæœãŒä¸å®Œå…¨ã§ã™")
            return None
        
        # 3. æ¯”è¼ƒåˆ†æ
        improvement_rate = ((cfs_results.accuracy - legacy_results.accuracy) / 
                          legacy_results.accuracy * 100) if legacy_results.accuracy > 0 else 0.0
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š
        statistical_significance = self._statistical_significance_test(
            legacy_results, cfs_results
        )
        
        # ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ”¹å–„
        cold_start_improvement = ((cfs_results.cold_start_performance - 
                                 legacy_results.cold_start_performance) * 100)
        
        # å”èª¿åŠ¹æœæ¸¬å®š
        collaboration_effectiveness = self._calculate_collaboration_effectiveness()
        
        comparison_results = ComparisonResults(
            legacy_results=legacy_results,
            cfs_results=cfs_results,
            improvement_rate=improvement_rate,
            statistical_significance=statistical_significance,
            cold_start_improvement=cold_start_improvement,
            collaboration_effectiveness=collaboration_effectiveness
        )
        
        # çµæœä¿å­˜ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._save_comparison_results(comparison_results)
        self._generate_comparison_report(comparison_results)
        
        return comparison_results
    
    def _statistical_significance_test(self, legacy: CFSEvaluationResult, 
                                     cfs: CFSEvaluationResult) -> float:
        """çµ±è¨ˆçš„æœ‰æ„æ€§æ¤œå®š"""
        # ç°¡æ˜“çš„ãªtæ¤œå®šï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šè©³ç´°ãªåˆ†æãŒå¿…è¦ï¼‰
        if legacy.total_samples < 10 or cfs.total_samples < 10:
            return 1.0
        
        # æ­£è§£ç‡å·®ã®æ¤œå®š
        legacy_rate = legacy.correct_predictions / legacy.total_samples
        cfs_rate = cfs.correct_predictions / cfs.total_samples
        
        # ç°¡æ˜“tæ¤œå®š
        pooled_std = np.sqrt((legacy_rate * (1 - legacy_rate) / legacy.total_samples) +
                            (cfs_rate * (1 - cfs_rate) / cfs.total_samples))
        
        if pooled_std == 0:
            return 1.0
        
        t_stat = abs(cfs_rate - legacy_rate) / pooled_std
        # ç°¡æ˜“på€¤è¨ˆç®—ï¼ˆæ­£ç¢ºã«ã¯tåˆ†å¸ƒã‚’ä½¿ç”¨ï¼‰
        p_value = max(0.001, 2 * (1 - stats.norm.cdf(abs(t_stat))))
        
        return p_value
    
    def _calculate_collaboration_effectiveness(self) -> float:
        """å”èª¿åŠ¹æœæ¸¬å®š"""
        if not self.cfs_editor:
            return 0.0
        
        collab_stats = self.cfs_editor.get_collaboration_statistics()
        if not collab_stats.get('collaboration_enabled', False):
            return 0.0
        
        # å”èª¿ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã«åŸºã¥ãåŠ¹æœæŒ‡æ¨™
        total_sessions = self.evaluation_stats.get('collaboration_sessions', 0)
        total_samples = len(self.test_data)
        
        effectiveness = (total_sessions / total_samples) if total_samples > 0 else 0.0
        return min(effectiveness, 1.0)
    
    def _save_comparison_results(self, results: ComparisonResults):
        """æ¯”è¼ƒçµæœä¿å­˜"""
        results_dict = {
            'legacy_chameleon': {
                'accuracy': results.legacy_results.accuracy,
                'f1_macro': results.legacy_results.f1_macro,
                'precision': results.legacy_results.precision,
                'recall': results.legacy_results.recall,
                'inference_time': results.legacy_results.inference_time,
                'cold_start_performance': results.legacy_results.cold_start_performance
            },
            'cfs_chameleon': {
                'accuracy': results.cfs_results.accuracy,
                'f1_macro': results.cfs_results.f1_macro,
                'precision': results.cfs_results.precision,
                'recall': results.cfs_results.recall,
                'inference_time': results.cfs_results.inference_time,
                'cold_start_performance': results.cfs_results.cold_start_performance,
                'pool_utilization': results.cfs_results.pool_utilization,
                'user_coverage': results.cfs_results.user_coverage
            },
            'comparison_metrics': {
                'improvement_rate': results.improvement_rate,
                'statistical_significance': results.statistical_significance,
                'cold_start_improvement': results.cold_start_improvement,
                'collaboration_effectiveness': results.collaboration_effectiveness
            },
            'evaluation_stats': self.evaluation_stats
        }
        
        results_file = self.output_dir / "cfs_comparison_results.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_dict, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ’¾ æ¯”è¼ƒçµæœä¿å­˜: {results_file}")
    
    def _generate_comparison_report(self, results: ComparisonResults):
        """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "=" * 60)
        print("ğŸ“Š CFS-Chameleon LaMP-2 æ¯”è¼ƒè©•ä¾¡çµæœ")
        print("=" * 60)
        
        print(f"\nğŸ”¸ å¾“æ¥ç‰ˆChameleon:")
        print(f"   ç²¾åº¦:         {results.legacy_results.accuracy:.4f}")
        print(f"   F1ã‚¹ã‚³ã‚¢:     {results.legacy_results.f1_macro:.4f}")
        print(f"   æ¨è«–æ™‚é–“:     {results.legacy_results.inference_time:.2f}ç§’")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ: {results.legacy_results.cold_start_performance:.4f}")
        
        print(f"\nğŸ¦ CFS-Chameleon:")
        print(f"   ç²¾åº¦:         {results.cfs_results.accuracy:.4f}")
        print(f"   F1ã‚¹ã‚³ã‚¢:     {results.cfs_results.f1_macro:.4f}")
        print(f"   æ¨è«–æ™‚é–“:     {results.cfs_results.inference_time:.2f}ç§’")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆ: {results.cfs_results.cold_start_performance:.4f}")
        print(f"   ãƒ—ãƒ¼ãƒ«åˆ©ç”¨ç‡:   {results.cfs_results.pool_utilization:.2%}")
        print(f"   ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¯„å›²:   {results.cfs_results.user_coverage}äºº")
        
        print(f"\nğŸ“ˆ æ”¹å–„åŠ¹æœ:")
        print(f"   å…¨ä½“æ”¹å–„ç‡:     {results.improvement_rate:+.1f}%")
        print(f"   ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ”¹å–„: {results.cold_start_improvement:+.1f}pt")
        print(f"   çµ±è¨ˆçš„æœ‰æ„æ€§:   p = {results.statistical_significance:.4f}")
        print(f"   å”èª¿åŠ¹æœ:       {results.collaboration_effectiveness:.2%}")
        
        # çµ±è¨ˆçš„æœ‰æ„æ€§ã®åˆ¤å®š
        if results.statistical_significance < 0.05:
            print("   âœ… çµ±è¨ˆçš„ã«æœ‰æ„ãªæ”¹å–„!")
        else:
            print("   âš ï¸  çµ±è¨ˆçš„æœ‰æ„æ€§ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        # å¯è¦–åŒ–ç”Ÿæˆ
        self._plot_cfs_comparison(results)
    
    def _plot_cfs_comparison(self, results: ComparisonResults):
        """æ¯”è¼ƒçµæœå¯è¦–åŒ–"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        methods = ['Legacy Chameleon', 'CFS-Chameleon']
        
        # 1. ç²¾åº¦ãƒ»F1æ¯”è¼ƒ
        accuracies = [results.legacy_results.accuracy, results.cfs_results.accuracy]
        f1_scores = [results.legacy_results.f1_macro, results.cfs_results.f1_macro]
        
        x = np.arange(len(methods))
        width = 0.35
        
        axes[0, 0].bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8)
        axes[0, 0].bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8)
        axes[0, 0].set_xlabel('Method')
        axes[0, 0].set_ylabel('Score')
        axes[0, 0].set_title('Performance Comparison')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(methods)
        axes[0, 0].legend()
        axes[0, 0].set_ylim(0, 1)
        
        # 2. ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆæ¯”è¼ƒ
        cold_start_scores = [results.legacy_results.cold_start_performance, 
                           results.cfs_results.cold_start_performance]
        
        axes[0, 1].bar(methods, cold_start_scores, alpha=0.8, color='green')
        axes[0, 1].set_xlabel('Method')
        axes[0, 1].set_ylabel('Cold-start Performance')
        axes[0, 1].set_title('Cold-start User Performance')
        axes[0, 1].set_ylim(0, 1)
        
        # 3. æ¨è«–æ™‚é–“æ¯”è¼ƒ
        inference_times = [results.legacy_results.inference_time, 
                         results.cfs_results.inference_time]
        
        axes[1, 0].bar(methods, inference_times, alpha=0.8, color='orange')
        axes[1, 0].set_xlabel('Method')
        axes[1, 0].set_ylabel('Inference Time (seconds)')
        axes[1, 0].set_title('Inference Time Comparison')
        
        # 4. æ”¹å–„ç‡ã‚µãƒãƒªãƒ¼
        improvements = [
            ('Overall', results.improvement_rate),
            ('Cold-start', results.cold_start_improvement),
            ('Collaboration', results.collaboration_effectiveness * 100)
        ]
        
        improvement_names = [imp[0] for imp in improvements]
        improvement_values = [imp[1] for imp in improvements]
        
        colors = ['blue' if v > 0 else 'red' for v in improvement_values]
        axes[1, 1].bar(improvement_names, improvement_values, alpha=0.8, color=colors)
        axes[1, 1].set_xlabel('Improvement Type')
        axes[1, 1].set_ylabel('Improvement (%)')
        axes[1, 1].set_title('CFS-Chameleon Improvements')
        axes[1, 1].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / "cfs_comparison_visualization.png", 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ğŸ“ˆ æ¯”è¼ƒå¯è¦–åŒ–ä¿å­˜: {self.output_dir / 'cfs_comparison_visualization.png'}")

def create_enhanced_argument_parser():
    """æ‹¡å¼µå¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼"""
    parser = argparse.ArgumentParser(description='LaMP-2 CFS-Chameleonçµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯')
    
    # æ—¢å­˜å¼•æ•°ä¿æŒ
    parser.add_argument('--data_path', default='./chameleon_prime_personalization/data', 
                       help='LaMP-2ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‘ã‚¹')
    parser.add_argument('--output_dir', default='./cfs_evaluation_results', 
                       help='çµæœå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª')
    
    # CFS-Chameleonæ–°è¦è¿½åŠ å¼•æ•°
    parser.add_argument('--use_collaboration', action='store_true',
                       help='CFS-Chameleonå”èª¿æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–')
    parser.add_argument('--config', type=str, default=None,
                       help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (cfs_config.yaml or config.yaml)')
    parser.add_argument('--collaboration_mode', choices=['heuristic', 'learned'],
                       default='heuristic', help='å”èª¿é¸æŠæˆ¦ç•¥')
    parser.add_argument('--compare_modes', action='store_true',
                       help='å¾“æ¥ç‰ˆvså”èª¿ç‰ˆã®æ¯”è¼ƒè©•ä¾¡å®Ÿè¡Œ')
    parser.add_argument('--cold_start_test', action='store_true',
                       help='ã‚³ãƒ¼ãƒ«ãƒ‰ã‚¹ã‚¿ãƒ¼ãƒˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ€§èƒ½è©•ä¾¡')
    parser.add_argument('--pool_size', type=int, default=200,
                       help='å”èª¿æ–¹å‘ãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚º')
    parser.add_argument('--evaluation_mode', choices=['legacy', 'cfs', 'comparison'],
                       default='comparison', help='è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰é¸æŠ')
    parser.add_argument('--sample_limit', type=int, default=None,
                       help='è©•ä¾¡ã‚µãƒ³ãƒ—ãƒ«æ•°åˆ¶é™ï¼ˆé«˜é€Ÿãƒ†ã‚¹ãƒˆç”¨ï¼‰')
    parser.add_argument('--include_baseline', action='store_true',
                       help='ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ï¼ˆç·¨é›†ãªã—ï¼‰ã‚‚è©•ä¾¡ã«å«ã‚ã‚‹')
    parser.add_argument('--debug_mode', action='store_true',
                       help='ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è©³ç´°å‡ºåŠ›')
    
    # ğŸš€ Chameleon ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´å¼•æ•°ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šã®ãŸã‚ï¼‰
    parser.add_argument('--alpha_p', type=float, default=None,
                       help='ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: configã‹ã‚‰èª­ã¿è¾¼ã¿)')
    parser.add_argument('--alpha_n', type=float, default=None, 
                       help='ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: configã‹ã‚‰èª­ã¿è¾¼ã¿)')
    parser.add_argument('--max_length', type=int, default=None,
                       help='ç”Ÿæˆæœ€å¤§é•· (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: configã‹ã‚‰èª­ã¿è¾¼ã¿)')
    
    return parser

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = create_enhanced_argument_parser()
    args = parser.parse_args()
    
    logger.info("ğŸš€ CFS-Chameleon LaMP-2 çµ±åˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
    logger.info(f"   å”èª¿æ©Ÿèƒ½: {'æœ‰åŠ¹' if args.use_collaboration else 'ç„¡åŠ¹'}")
    logger.info(f"   è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰: {args.evaluation_mode}")
    
    # è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    evaluator = CFSLaMP2Evaluator(
        data_path=args.data_path,
        output_dir=args.output_dir,
        config_path=args.config,
        use_collaboration=args.use_collaboration,
        collaboration_mode=args.collaboration_mode,
        sample_limit=args.sample_limit,
        # ğŸš€ Chameleonãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ï¼ˆã‚¹ã‚³ã‚¢å‘ä¸Šï¼‰
        alpha_p_override=args.alpha_p,
        alpha_n_override=args.alpha_n,
        max_length_override=args.max_length,
        debug_mode=args.debug_mode
    )
    
    try:
        if args.compare_modes or args.evaluation_mode == 'comparison':
            # æ¯”è¼ƒè©•ä¾¡å®Ÿè¡Œ
            results = evaluator.run_comparison_evaluation()
            
            if results:
                print(f"\nâœ… CFS-Chameleonæ¯”è¼ƒè©•ä¾¡å®Œäº†!")
                print(f"ğŸ“Š æ”¹å–„ç‡: {results.improvement_rate:+.1f}%")
                print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {args.output_dir}")
            else:
                print("âŒ æ¯”è¼ƒè©•ä¾¡ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        elif args.evaluation_mode == 'legacy':
            # å¾“æ¥ç‰ˆã®ã¿è©•ä¾¡
            results = evaluator.evaluate_legacy_chameleon()
            if results:
                print(f"âœ… å¾“æ¥ç‰ˆChameleonè©•ä¾¡å®Œäº†: ç²¾åº¦={results.accuracy:.4f}")
            
        elif args.evaluation_mode == 'cfs':
            # CFS-Chameleonã®ã¿è©•ä¾¡
            results = evaluator.evaluate_cfs_chameleon(args.pool_size)
            if results:
                print(f"âœ… CFS-Chameleonè©•ä¾¡å®Œäº†: ç²¾åº¦={results.accuracy:.4f}")
        
        logger.info("ğŸ‰ ã™ã¹ã¦ã®è©•ä¾¡ãŒå®Œäº†ã—ã¾ã—ãŸ!")
        
    except Exception as e:
        logger.error(f"è©•ä¾¡å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()