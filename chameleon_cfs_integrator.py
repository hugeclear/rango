#!/usr/bin/env python3
"""
Chameleon-CFSçµ±åˆå™¨: æ—¢å­˜Chameleonã‚³ãƒ¼ãƒ‰ã®æˆ¦ç•¥çš„æ”¹å¤‰
å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®æ®µéšçš„æ‹¡å¼µ

ç‰¹å¾´:
- æ—¢å­˜ChameleonEditorã®å®Œå…¨æ‹¡å¼µ
- ä¸‹ä½äº’æ›æ€§ä¿è¨¼ï¼ˆuse_collaboration=Falseï¼‰
- ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å”èª¿å­¦ç¿’
- è»½é‡å­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆ
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Any, Optional, Union
import logging
from pathlib import Path
import json
import time

from cfs_chameleon_extension import (
    CollaborativeDirectionPool, DirectionPiece, UserContext, 
    LightweightGateNetwork
)

# æ—¢å­˜ã®ChameleonEditorã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã¾ãŸã¯ç¶™æ‰¿ç”¨ã«å‚ç…§ï¼‰
try:
    from chameleon_evaluator import ChameleonEditor as BaseChameleonEditor
    BASE_EDITOR_AVAILABLE = True
except ImportError:
    # åŸºæœ¬ã‚¯ãƒ©ã‚¹ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    class BaseChameleonEditor:
        def __init__(self, *args, **kwargs):
            pass
    BASE_EDITOR_AVAILABLE = False

logger = logging.getLogger(__name__)

class CollaborativeChameleonEditor(BaseChameleonEditor):
    """
    å”èª¿çš„Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
    
    æ—¢å­˜ã®ChameleonEditorã‚’æ‹¡å¼µã—ã€å”èª¿çš„æ©Ÿèƒ½ã‚’è¿½åŠ 
    use_collaborationãƒ•ãƒ©ã‚°ã§æ—¢å­˜æ©Ÿèƒ½ã¨ã®å®Œå…¨äº’æ›æ€§ã‚’ä¿æŒ
    """
    
    def __init__(self, model_name: str = "meta-llama/Llama-3.2-3B-Instruct", 
                 device: str = "auto", torch_dtype: str = "float32",
                 use_collaboration: bool = False, 
                 collaboration_config: Dict[str, Any] = None,
                 config_path: str = None):
        """
        å”èª¿çš„Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            device: ãƒ‡ãƒã‚¤ã‚¹
            torch_dtype: ãƒ‡ãƒ¼ã‚¿å‹
            use_collaboration: å”èª¿æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
            collaboration_config: å”èª¿æ©Ÿèƒ½è¨­å®š
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        self.config_data = None
        self.theta_p_path = None
        self.theta_n_path = None
        self.direction_p_path = None
        self.direction_n_path = None
        
        if config_path:
            import yaml
            try:
                with open(config_path, 'r') as f:
                    self.config_data = yaml.safe_load(f)
                    model_config = self.config_data.get('model', {})
                    model_name = model_config.get('name', model_name)
                    device = model_config.get('device', device)
                    torch_dtype = model_config.get('torch_dtype', torch_dtype)
                    
                    # Theta vectorã¨Direction vectorãƒ‘ã‚¹èª­ã¿è¾¼ã¿
                    chameleon_config = self.config_data.get('chameleon', {})
                    self.theta_p_path = chameleon_config.get('theta_p_path')
                    self.theta_n_path = chameleon_config.get('theta_n_path')
                    self.direction_p_path = chameleon_config.get('direction_p_path')
                    self.direction_n_path = chameleon_config.get('direction_n_path')
                    
            except Exception as e:
                logger.warning(f"Config file reading error: {e}, using defaults")
        
        # åŸºåº•ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        if BASE_EDITOR_AVAILABLE:
            super().__init__(model_name, device, torch_dtype)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰target_layersã‚’ä¸Šæ›¸ãé©ç”¨
            if self.config_data and 'chameleon' in self.config_data:
                chameleon_config = self.config_data['chameleon']
                if 'target_layers' in chameleon_config:
                    logger.info(f"Overriding target_layers from config: {chameleon_config['target_layers']}")
                    # åŸºåº•ã‚¯ãƒ©ã‚¹ã«ç›´æ¥é©ç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¾Œã§åˆ©ç”¨ï¼‰
                    self._config_target_layers = chameleon_config['target_layers']
                if 'alpha_personal' in chameleon_config:
                    self._config_alpha_personal = chameleon_config['alpha_personal'] 
                if 'alpha_general' in chameleon_config:
                    self._config_alpha_general = chameleon_config['alpha_general']
        
        # å”èª¿æ©Ÿèƒ½ã®è¨­å®š
        self.use_collaboration = use_collaboration
        self.collaboration_config = collaboration_config or self._default_collaboration_config()
        
        # Theta vectorsèª­ã¿è¾¼ã¿
        self._load_theta_vectors()
        
        # Direction vectorsèª­ã¿è¾¼ã¿
        self._load_direction_vectors()
        
        # å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        if self.use_collaboration:
            self._initialize_collaboration_components()
        
        # ãƒ•ãƒƒã‚¯ç®¡ç†åˆæœŸåŒ–
        self.direction_hooks = []
        
        logger.info(f"CollaborativeChameleonEditor initialized (collaboration: {use_collaboration})")
    
    def _load_theta_vectors(self):
        """Theta vectorsèª­ã¿è¾¼ã¿"""
        try:
            import numpy as np
            from pathlib import Path
            
            if self.theta_p_path and self.theta_n_path:
                # ãƒ‘ã‚¹å­˜åœ¨ç¢ºèª
                theta_p_path = Path(self.theta_p_path)
                theta_n_path = Path(self.theta_n_path)
                
                if theta_p_path.exists() and theta_n_path.exists():
                    # Theta vectorsèª­ã¿è¾¼ã¿
                    self.theta_personal = np.load(theta_p_path)
                    self.theta_neutral = np.load(theta_n_path)
                    logger.info(f"âœ… Theta vectors loaded: P={self.theta_personal.shape}, N={self.theta_neutral.shape}")
                else:
                    logger.warning(f"âš ï¸ Theta vector files not found: {theta_p_path}, {theta_n_path}")
                    self.theta_personal = None
                    self.theta_neutral = None
            else:
                logger.warning("âš ï¸ Theta vector paths not specified in config")
                self.theta_personal = None
                self.theta_neutral = None
                
        except Exception as e:
            logger.warning(f"âš ï¸ Theta vector loading error: {e}")
            self.theta_personal = None
            self.theta_neutral = None
    
    def _load_direction_vectors(self):
        """Direction vectorsèª­ã¿è¾¼ã¿"""
        try:
            import numpy as np
            from pathlib import Path
            
            if self.direction_p_path and self.direction_n_path:
                # ãƒ‘ã‚¹å­˜åœ¨ç¢ºèª
                direction_p_path = Path(self.direction_p_path)
                direction_n_path = Path(self.direction_n_path)
                
                if direction_p_path.exists() and direction_n_path.exists():
                    # Direction vectorsèª­ã¿è¾¼ã¿
                    self.direction_personal = np.load(direction_p_path)
                    self.direction_neutral = np.load(direction_n_path)
                    logger.info(f"âœ… Direction vectors loaded: P={self.direction_personal.shape}, N={self.direction_neutral.shape}")
                else:
                    logger.warning(f"âš ï¸ Direction vector files not found: {direction_p_path}, {direction_n_path}")
                    self.direction_personal = None
                    self.direction_neutral = None
            else:
                logger.warning("âš ï¸ Direction vector paths not specified in config")
                self.direction_personal = None
                self.direction_neutral = None
                
        except Exception as e:
            logger.warning(f"âš ï¸ Direction vector loading error: {e}")
            self.direction_personal = None
            self.direction_neutral = None
    
    def generate_with_chameleon(self, prompt: str, alpha_personal: float = None, alpha_neutral: float = None, 
                               target_layers: List[str] = None, max_length: int = 50) -> str:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸChameleonç·¨é›†ç”Ÿæˆ
        """
        # Direction vectorså„ªå…ˆã§å­˜åœ¨ç¢ºèªï¼ˆChameleonç·¨é›†ã«å¿…è¦ï¼‰
        if self.direction_personal is None or self.direction_neutral is None:
            logger.warning("Direction vectors not loaded, cannot perform Chameleon editing")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            return self._fallback_generation(prompt, max_length)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆå¼•æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
        if alpha_personal is None and hasattr(self, '_config_alpha_personal'):
            alpha_personal = self._config_alpha_personal
        if alpha_neutral is None and hasattr(self, '_config_alpha_general'):
            alpha_neutral = self._config_alpha_general
        if target_layers is None and hasattr(self, '_config_target_layers'):
            target_layers = self._config_target_layers
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
        if alpha_personal is None:
            alpha_personal = 0.1
        if alpha_neutral is None:
            alpha_neutral = -0.05
        if target_layers is None:
            target_layers = ["model.layers.16.mlp"]
        
        try:
            # Chameleonç·¨é›†å®Ÿè¡Œ
            return self._execute_chameleon_generation(prompt, alpha_personal, alpha_neutral, target_layers, max_length)
        except Exception as e:
            logger.warning(f"Chameleon generation error: {e}")
            return self._fallback_generation(prompt, max_length)
    
    def _execute_chameleon_generation(self, prompt: str, alpha_personal: float, alpha_neutral: float, 
                                     target_layers: List[str], max_length: int) -> str:
        """Chameleonç·¨é›†å®Ÿè¡Œï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ©ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            if BASE_EDITOR_AVAILABLE and hasattr(self.__class__.__bases__[0], 'generate_with_chameleon'):
                return super().generate_with_chameleon(prompt, alpha_personal, alpha_neutral, target_layers, max_length)
        except:
            pass  # åŸºåº•ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ç‹¬è‡ªå®Ÿè£…ã‚’ä½¿ç”¨
        
        # Direction vectors ã‚’ä½¿ç”¨ã—ãŸç‹¬è‡ªå®Ÿè£…
        if not hasattr(self, 'model') or not hasattr(self, 'tokenizer'):
            logger.warning("Model or tokenizer not available for Chameleon generation")
            return self._fallback_generation(prompt, max_length)
        
        try:
            # ãƒ•ãƒƒã‚¯ç™»éŒ²
            self._register_direction_hooks(target_layers, alpha_personal, alpha_neutral)
            
            # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=max_length)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.generate(**inputs, max_length=max_length, do_sample=False)
                generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                result = generated[len(prompt):].strip()
            
            # ãƒ•ãƒƒã‚¯å‰Šé™¤
            self._remove_direction_hooks()
            
            return result if result else self._fallback_generation(prompt, max_length)
            
        except Exception as e:
            logger.warning(f"Chameleon generation failed: {e}")
            self._remove_direction_hooks()  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ãƒƒã‚¯å‰Šé™¤
            return self._fallback_generation(prompt, max_length)
    
    def _fallback_generation(self, prompt: str, max_length: int) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ"""
        try:
            # ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯åŸºæœ¬ç”Ÿæˆ
            if hasattr(self, 'model') and hasattr(self, 'tokenizer'):
                inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=max_length)
                inputs = {k: v.to(self.device) for k, v in inputs.items()}
                
                with torch.no_grad():
                    outputs = self.model.generate(**inputs, max_length=max_length, do_sample=False)
                    generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                    return generated[len(prompt):].strip()
            else:
                # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãã®ã¾ã¾è¿”ã™
                return f"Generated response for: {prompt}"
        except Exception as e:
            logger.warning(f"Fallback generation error: {e}")
            return f"Error in generation for: {prompt}"
    
    def _register_direction_hooks(self, target_layers: List[str], alpha_personal: float, alpha_neutral: float):
        """Direction vectorç·¨é›†ãƒ•ãƒƒã‚¯ã®ç™»éŒ²"""
        def direction_editing_hook(module, input, output):
            """Direction vectorã‚’ä½¿ç”¨ã—ãŸç·¨é›†ãƒ•ãƒƒã‚¯"""
            try:
                if isinstance(output, tuple):
                    output_tensor = output[0]
                    additional_outputs = output[1:]
                else:
                    output_tensor = output
                    additional_outputs = ()
                
                # Direction vectorã‚’ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚’é©ç”¨
                edited_output = self._apply_direction_editing(
                    output_tensor, alpha_personal, alpha_neutral
                )
                
                if additional_outputs:
                    return (edited_output,) + additional_outputs
                else:
                    return edited_output
                    
            except Exception as e:
                logger.warning(f"Direction hook error: {e}")
                return output
        
        # ãƒ•ãƒƒã‚¯ç™»éŒ²
        for layer_name in target_layers:
            try:
                layer = self._get_layer_by_name(layer_name)
                if layer is not None:
                    hook = layer.register_forward_hook(direction_editing_hook)
                    self.direction_hooks.append(hook)
                    logger.info(f"Registered direction hook on {layer_name}")
            except Exception as e:
                logger.warning(f"Failed to register direction hook on {layer_name}: {e}")
    
    def _remove_direction_hooks(self):
        """Direction vectorãƒ•ãƒƒã‚¯ã®å‰Šé™¤"""
        for hook in self.direction_hooks:
            hook.remove()
        self.direction_hooks = []
    
    def _get_layer_by_name(self, layer_name: str):
        """ãƒ¬ã‚¤ãƒ¤ãƒ¼åã‹ã‚‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—"""
        try:
            parts = layer_name.split('.')
            layer = self.model
            for part in parts:
                if part.isdigit():
                    layer = layer[int(part)]
                else:
                    layer = getattr(layer, part)
            return layer
        except:
            logger.warning(f"Layer {layer_name} not found")
            return None
    
    def _apply_direction_editing(self, output_tensor: torch.Tensor, alpha_personal: float, alpha_neutral: float) -> torch.Tensor:
        """Direction vectorã‚’ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ç·¨é›†é©ç”¨"""
        try:
            # æ¬¡å…ƒå–å¾—
            if len(output_tensor.shape) == 3:
                hidden_dim = output_tensor.shape[-1]
            elif len(output_tensor.shape) == 2:
                hidden_dim = output_tensor.shape[-1]
            else:
                return output_tensor
            
            # Direction vectorsã‚’é©åˆ‡ãªé•·ã•ã«èª¿æ•´
            personal_vec = torch.tensor(
                self.direction_personal[:hidden_dim],
                dtype=output_tensor.dtype,
                device=output_tensor.device
            )
            neutral_vec = torch.tensor(
                self.direction_neutral[:hidden_dim],
                dtype=output_tensor.dtype,
                device=output_tensor.device
            )
            
            # ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—
            edit_vector = alpha_personal * personal_vec + alpha_neutral * neutral_vec
            
            # å½¢çŠ¶èª¿æ•´
            if len(output_tensor.shape) == 3:
                edit_vector = edit_vector.view(1, 1, -1)
            elif len(output_tensor.shape) == 2:
                edit_vector = edit_vector.view(1, -1)
            
            return output_tensor + edit_vector
            
        except Exception as e:
            logger.warning(f"Direction editing application failed: {e}")
            return output_tensor
    
    def _default_collaboration_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå”èª¿è¨­å®š"""
        return {
            'pool_size': 1000,
            'rank_reduction': 32,
            'top_k_pieces': 10,
            'fusion_strategy': 'analytical',
            'selection_strategy': 'analytical',
            'privacy_noise_std': 0.01,
            'enable_learning': False,
            'auto_dimension_detection': True,  # è‡ªå‹•æ¬¡å…ƒæ¤œå‡º
            'adaptive_vector_sizing': True,   # é©å¿œçš„ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚ºèª¿æ•´
            'gate_network_config': {
                'embedding_dim': 768,
                'num_directions': 200,
                'hidden_dim': 256
            }
        }
    
    def _initialize_collaboration_components(self):
        """å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        config = self.collaboration_config
        
        # å”èª¿æ–¹å‘ãƒ—ãƒ¼ãƒ«
        self.direction_pool = CollaborativeDirectionPool(
            pool_size=config.get('pool_size', 1000),
            rank_reduction=config.get('rank_reduction', 32)
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
        self.user_contexts: Dict[str, UserContext] = {}
        
        # è»½é‡å­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        enable_learning = config.get('enable_learning', False)
        if enable_learning:
            gate_config = config.get('gate_network_config', {
                'embedding_dim': 768,
                'num_directions': 200,
                'hidden_dim': 256
            })
            self.gate_network = LightweightGateNetwork(
                embedding_dim=gate_config.get('embedding_dim', 768),
                num_directions=gate_config.get('num_directions', 200),
                hidden_dim=gate_config.get('hidden_dim', 256)
            )
            self.gate_optimizer = torch.optim.Adam(self.gate_network.parameters(), lr=1e-3)
        else:
            self.gate_network = None
            self.gate_optimizer = None
        
        # å”èª¿çµ±è¨ˆ
        self.collaboration_stats = {
            'total_collaborations': 0,
            'cache_hits': 0,
            'avg_improvement': 0.0,
            'privacy_applications': 0
        }
        
        logger.info("Collaboration components initialized")
    
    def add_user_direction_to_pool(self, user_id: str, personal_direction: np.ndarray, 
                                 neutral_direction: np.ndarray, semantic_context: str = "") -> bool:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’å”èª¿ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            personal_direction: å€‹äººæ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
            neutral_direction: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
            semantic_context: æ„å‘³çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            è¿½åŠ æˆåŠŸã‹ã©ã†ã‹
        """
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - direction not added to pool")
            return False
        
        try:
            # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ãƒã‚¤ã‚ºè¿½åŠ 
            noise_std = self.collaboration_config.get('privacy_noise_std', 0.01)
            if noise_std > 0:
                noise = np.random.normal(0, noise_std, personal_direction.shape)
                personal_direction = personal_direction + noise
                self.collaboration_stats['privacy_applications'] += 1
            
            # æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
            pieces = self.direction_pool.add_direction_vector(
                personal_direction, user_id, semantic_context
            )
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ/æ›´æ–°
            if user_id not in self.user_contexts:
                self.user_contexts[user_id] = UserContext(
                    user_id=user_id,
                    preference_vector=personal_direction[:min(len(personal_direction), 768)],
                    history_embedding=np.mean([personal_direction, neutral_direction], axis=0),
                    activity_level=1.0,
                    similarity_cache={}
                )
            else:
                # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¬ãƒ™ãƒ«æ›´æ–°
                self.user_contexts[user_id].activity_level += 0.1
            
            logger.info(f"Added {len(pieces)} direction pieces for user {user_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to add user direction to pool: {e}")
            return False
    
    def collaborative_edit_embedding(self, base_embedding: torch.Tensor, user_id: str,
                                   query_context: str = "", alpha_personal: float = 1.5, 
                                   alpha_neutral: float = -0.8) -> torch.Tensor:
        """
        å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã®å®Ÿè£…ï¼ˆæ¬¡å…ƒä¸æ•´åˆä¿®æ­£ç‰ˆï¼‰
        
        Args:
            base_embedding: åŸºæœ¬åŸ‹ã‚è¾¼ã¿
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID  
            query_context: ã‚¯ã‚¨ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            alpha_personal: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦
            alpha_neutral: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦
            
        Returns:
            ç·¨é›†ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿
        """
        # å”èª¿æ©Ÿèƒ½ãŒç„¡åŠ¹ã®å ´åˆã¯æ—¢å­˜ã®æ–¹æ³•ã‚’ä½¿ç”¨
        if not self.use_collaboration:
            return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
        
        try:
            # 1. å‹•çš„æ¬¡å…ƒæ¤œå‡º
            actual_hidden_dim = self._detect_actual_hidden_dimension(base_embedding)
            
            # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯å‹•çš„ä½œæˆï¼‰
            if user_id not in self.user_contexts:
                logger.info(f"Creating new user context for {user_id}")
                self._create_dynamic_user_context(user_id, actual_hidden_dim)
            
            user_context = self.user_contexts[user_id]
            
            # 3. ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆé©å¿œçš„ã‚µã‚¤ã‚ºï¼‰
            query_embedding = self._generate_adaptive_query_embedding(query_context, actual_hidden_dim)
            
            # 4. å”èª¿çš„ãƒ”ãƒ¼ã‚¹é¸æŠ
            selected_pieces = self.direction_pool.select_collaborative_pieces(
                user_context=user_context,
                query_embedding=query_embedding,
                top_k=self.collaboration_config.get('top_k_pieces', 10),
                strategy=self.collaboration_config.get('selection_strategy', 'analytical')
            )
            
            if not selected_pieces:
                logger.debug("No collaborative pieces available - using legacy editing")
                return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
            
            # 5. æ–¹å‘çµ±åˆï¼ˆé©å¿œçš„ã‚µã‚¤ã‚ºï¼‰
            collaborative_direction = self.direction_pool.fuse_selected_directions(
                selected_pieces, 
                fusion_strategy=self.collaboration_config.get('fusion_strategy', 'analytical')
            )
            
            # 6. æ¬¡å…ƒæ•´åˆæ€§ç¢ºä¿
            collaborative_direction = self._ensure_dimension_compatibility(
                collaborative_direction, actual_hidden_dim
            )
            
            # 7. å”èª¿æ–¹å‘ã®é©ç”¨
            collaborative_direction_tensor = torch.tensor(
                collaborative_direction, 
                dtype=base_embedding.dtype, 
                device=base_embedding.device
            )
            
            # 8. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
            edit_vector = self._create_hybrid_edit_vector(
                collaborative_direction_tensor, alpha_personal, alpha_neutral, actual_hidden_dim
            )
            
            # 9. å½¢çŠ¶èª¿æ•´ã¨ç·¨é›†é©ç”¨
            edit_vector = self._adjust_vector_shape(edit_vector, base_embedding.shape)
            edited_embedding = base_embedding + edit_vector
            
            # 10. çµ±è¨ˆæ›´æ–°
            self.collaboration_stats['total_collaborations'] += 1
            
            logger.debug(f"Applied collaborative editing for user {user_id} (dim={actual_hidden_dim}, pieces={len(selected_pieces)})")
            return edited_embedding
            
        except Exception as e:
            logger.warning(f"Collaborative editing failed: {e} - falling back to legacy")
            return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
    
    def _legacy_edit_embedding(self, base_embedding: torch.Tensor, 
                             alpha_personal: float, alpha_neutral: float) -> torch.Tensor:
        """æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ç·¨é›†ï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        # Direction vectorså„ªå…ˆã§ä½¿ç”¨
        if self.direction_personal is not None and self.direction_neutral is not None:
            personal_direction = torch.tensor(self.direction_personal, dtype=base_embedding.dtype, device=base_embedding.device)
            neutral_direction = torch.tensor(self.direction_neutral, dtype=base_embedding.dtype, device=base_embedding.device)
        elif hasattr(self, 'personal_direction') and hasattr(self, 'neutral_direction') and \
             self.personal_direction is not None and self.neutral_direction is not None:
            personal_direction = self.personal_direction
            neutral_direction = self.neutral_direction
        else:
            logger.warning("No direction vectors available for editing")
            return base_embedding
        
        # æ—¢å­˜ã®Chameleonç·¨é›†ãƒ­ã‚¸ãƒƒã‚¯
        device = base_embedding.device
        dtype = base_embedding.dtype
        
        # é©åˆ‡ãªæ¬¡å…ƒã‚’å–å¾—
        if len(base_embedding.shape) == 3:
            hidden_dim = base_embedding.shape[-1]
        elif len(base_embedding.shape) == 2:
            hidden_dim = base_embedding.shape[-1]
        else:
            return base_embedding
        
        # Direction vectorsã‚’é©åˆ‡ãªé•·ã•ã«èª¿æ•´
        personal_vec = personal_direction[:hidden_dim]
        neutral_vec = neutral_direction[:hidden_dim]
        
        # Tensorã‚’GPUã«ç§»å‹•
        if not isinstance(personal_vec, torch.Tensor):
            personal_vec = torch.tensor(personal_vec, dtype=dtype, device=device)
        if not isinstance(neutral_vec, torch.Tensor):
            neutral_vec = torch.tensor(neutral_vec, dtype=dtype, device=device)
        
        # ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—
        edit_vector = alpha_personal * personal_vec + alpha_neutral * neutral_vec
        
        # å½¢çŠ¶èª¿æ•´
        if len(base_embedding.shape) == 3:
            edit_vector = edit_vector.view(1, 1, -1)
        elif len(base_embedding.shape) == 2:
            edit_vector = edit_vector.view(1, -1)
        
        return base_embedding + edit_vector
    
    def _detect_actual_hidden_dimension(self, embedding: torch.Tensor) -> int:
        """å®Ÿéš›ã®éš ã‚Œæ¬¡å…ƒã‚’å‹•çš„æ¤œå‡º"""
        if len(embedding.shape) == 3:
            return embedding.shape[-1]  # (batch, seq, hidden)
        elif len(embedding.shape) == 2:
            return embedding.shape[-1]  # (batch, hidden)
        else:
            return 768  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _create_dynamic_user_context(self, user_id: str, hidden_dim: int):
        """å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ"""
        from cfs_chameleon_extension import UserContext
        
        preference_vector = np.random.randn(min(hidden_dim, 768)) * 0.1
        history_embedding = np.random.randn(min(hidden_dim, 768)) * 0.05
        
        self.user_contexts[user_id] = UserContext(
            user_id=user_id,
            preference_vector=preference_vector,
            history_embedding=history_embedding,
            activity_level=1.0,
            similarity_cache={}
        )
    
    def _generate_adaptive_query_embedding(self, query_context: str, hidden_dim: int) -> np.ndarray:
        """é©å¿œçš„ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        if not query_context:
            return np.zeros(min(hidden_dim, 768))
        
        try:
            context_hash = hash(query_context) % 1000000
            embedding_size = min(hidden_dim, 768)
            context_embedding = np.random.RandomState(context_hash).randn(embedding_size)
            return context_embedding
        except:
            return np.zeros(min(hidden_dim, 768))
    
    def _ensure_dimension_compatibility(self, direction: np.ndarray, target_dim: int) -> np.ndarray:
        """æ¬¡å…ƒæ•´åˆæ€§ã‚’ç¢ºä¿"""
        if len(direction) == target_dim:
            return direction
        elif len(direction) > target_dim:
            # ãƒˆãƒªãƒŸãƒ³ã‚°
            return direction[:target_dim]
        else:
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            padded = np.zeros(target_dim)
            padded[:len(direction)] = direction
            return padded
    
    def _create_hybrid_edit_vector(self, collaborative_direction: torch.Tensor, 
                                 alpha_personal: float, alpha_neutral: float, 
                                 hidden_dim: int) -> torch.Tensor:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        try:
            # Direction vectorså„ªå…ˆã§ä½¿ç”¨
            if self.direction_personal is not None and len(self.direction_personal) >= hidden_dim:
                personal_direction = torch.tensor(
                    self.direction_personal[:hidden_dim],
                    device=collaborative_direction.device, 
                    dtype=collaborative_direction.dtype
                )
                # å€‹äººæ–¹å‘ã¨å”èª¿æ–¹å‘ã®çµåˆ
                personal_component = alpha_personal * personal_direction
                collaborative_component = 0.3 * collaborative_direction  # å”èª¿æˆåˆ†ã®é‡ã¿ã‚’èª¿æ•´
                return personal_component + collaborative_component
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å”èª¿æ–¹å‘ã®ã¿ä½¿ç”¨
            elif hasattr(self, 'personal_direction') and self.personal_direction is not None and len(self.personal_direction) >= hidden_dim:
                personal_component = alpha_personal * self.personal_direction[:hidden_dim].to(
                    device=collaborative_direction.device, dtype=collaborative_direction.dtype
                )
                collaborative_component = 0.3 * collaborative_direction
                return personal_component + collaborative_component
            
            else:
                # å”èª¿æ–¹å‘ã®ã¿ä½¿ç”¨
                return alpha_personal * collaborative_direction
            
        except Exception as e:
            logger.warning(f"Hybrid vector creation failed: {e} - using collaborative only")
            return alpha_personal * collaborative_direction
    
    def _adjust_vector_shape(self, edit_vector: torch.Tensor, target_shape: torch.Size) -> torch.Tensor:
        """ãƒ™ã‚¯ãƒˆãƒ«å½¢çŠ¶èª¿æ•´"""
        if len(target_shape) == 3:
            # (batch, seq, hidden)ã®å ´åˆ
            return edit_vector.view(1, 1, -1)
        elif len(target_shape) == 2:
            # (batch, hidden)ã®å ´åˆ  
            return edit_vector.view(1, -1)
        else:
            return edit_vector
    
    def _generate_query_embedding(self, query_context: str, base_embedding: torch.Tensor) -> np.ndarray:
        """ã‚¯ã‚¨ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ"""
        if not query_context:
            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒãªã„å ´åˆã¯åŸºæœ¬åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨
            return base_embedding.detach().cpu().numpy().flatten()[:768]
        
        try:
            # ç°¡å˜ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ã‚ˆã‚Šé«˜åº¦ãªæ‰‹æ³•ã‚’ä½¿ç”¨
            context_hash = hash(query_context) % 1000000
            context_embedding = np.random.RandomState(context_hash).randn(768)
            return context_embedding
        except:
            return np.zeros(768)
    
    def generate_with_collaborative_chameleon(self, prompt: str, user_id: str,
                                            alpha_personal: float = 1.5, alpha_neutral: float = -0.8,
                                            target_layers: List[str] = None, max_length: int = 50) -> str:
        """
        å”èª¿çš„Chameleonç·¨é›†ã‚’é©ç”¨ã—ãŸç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            alpha_personal: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦
            alpha_neutral: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦
            target_layers: ç·¨é›†å¯¾è±¡ãƒ¬ã‚¤ãƒ¤ãƒ¼
            max_length: æœ€å¤§ç”Ÿæˆé•·
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        if target_layers is None:
            target_layers = ["model.layers.20"]
        
        # å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
        self._register_collaborative_hooks(target_layers, user_id, alpha_personal, alpha_neutral)
        
        try:
            # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ç”Ÿæˆæ©Ÿèƒ½ã‚’ä½¿ç”¨
            if BASE_EDITOR_AVAILABLE and hasattr(super(), 'generate_with_chameleon'):
                # æ—¢å­˜ã®ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ãŒã‚ã‚‹å ´åˆ
                return super().generate_with_chameleon(
                    prompt, alpha_personal, alpha_neutral, target_layers, max_length
                )
            else:
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
                return self._fallback_generation(prompt, max_length)
                
        finally:
            # ãƒ•ãƒƒã‚¯ã‚’å‰Šé™¤
            self.remove_editing_hooks()
    
    def _register_collaborative_hooks(self, target_layers: List[str], user_id: str,
                                    alpha_personal: float, alpha_neutral: float):
        """å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯ã®ç™»éŒ²"""
        def collaborative_editing_hook(module, input, output):
            """å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯"""
            try:
                if isinstance(output, tuple):
                    output_tensor = output[0]
                    additional_outputs = output[1:]
                else:
                    output_tensor = output
                    additional_outputs = ()
                
                # å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚’é©ç”¨
                edited_output = self.collaborative_edit_embedding(
                    output_tensor, user_id, "", alpha_personal, alpha_neutral
                )
                
                if additional_outputs:
                    return (edited_output,) + additional_outputs
                else:
                    return edited_output
                    
            except Exception as e:
                logger.warning(f"Collaborative hook error: {e}")
                return output
        
        # ãƒ•ãƒƒã‚¯ç™»éŒ²
        if hasattr(self, 'editing_hooks'):
            for layer_name in target_layers:
                try:
                    if hasattr(self, '_get_layer_by_name'):
                        layer = self._get_layer_by_name(layer_name)
                        hook = layer.register_forward_hook(collaborative_editing_hook)
                        self.editing_hooks.append(hook)
                        logger.info(f"Registered collaborative hook on {layer_name}")
                except:
                    logger.warning(f"Failed to register collaborative hook on {layer_name}")
    
    def _fallback_generation(self, prompt: str, max_length: int) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆå®Ÿè£…"""
        logger.warning("Using fallback generation - limited functionality")
        return f"[Generated response for: {prompt[:50]}...]"
    
    def train_collaboration_components(self, training_data: List[Dict[str, Any]], 
                                     epochs: int = 10) -> Dict[str, float]:
        """
        å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è»½é‡å­¦ç¿’
        
        Args:
            training_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (user_id, context, effective_directions)
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            
        Returns:
            å­¦ç¿’çµ±è¨ˆ
        """
        if not self.use_collaboration or self.gate_network is None:
            logger.warning("Learning components not available")
            return {}
        
        logger.info(f"Starting collaboration training ({epochs} epochs, {len(training_data)} samples)")
        
        training_stats = {'losses': [], 'accuracies': []}
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            correct_predictions = 0
            total_predictions = 0
            
            for batch_data in training_data:
                user_id = batch_data['user_id']
                context = batch_data['context']
                effective_directions = batch_data['effective_directions']  # ãƒã‚¤ãƒŠãƒªãƒ©ãƒ™ãƒ«
                
                if user_id not in self.user_contexts:
                    continue
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸ‹ã‚è¾¼ã¿å–å¾—
                user_embedding = torch.tensor(
                    self.user_contexts[user_id].preference_vector,
                    dtype=torch.float32
                ).unsqueeze(0)
                
                # ã‚²ãƒ¼ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯äºˆæ¸¬
                predicted_gates = self.gate_network(user_embedding)
                
                # æå¤±è¨ˆç®—
                target_gates = torch.tensor(effective_directions, dtype=torch.float32).unsqueeze(0)
                loss = nn.BCELoss()(predicted_gates, target_gates)
                
                # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
                self.gate_optimizer.zero_grad()
                loss.backward()
                self.gate_optimizer.step()
                
                # çµ±è¨ˆæ›´æ–°
                epoch_loss += loss.item()
                predictions = (predicted_gates > 0.5).float()
                correct_predictions += (predictions == target_gates).sum().item()
                total_predictions += target_gates.numel()
            
            # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆ
            avg_loss = epoch_loss / len(training_data)
            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
            
            training_stats['losses'].append(avg_loss)
            training_stats['accuracies'].append(accuracy)
            
            if (epoch + 1) % 5 == 0:
                logger.info(f"Epoch {epoch+1}/{epochs}: Loss={avg_loss:.4f}, Acc={accuracy:.4f}")
        
        logger.info("Collaboration training completed")
        return {
            'final_loss': training_stats['losses'][-1],
            'final_accuracy': training_stats['accuracies'][-1],
            'improvement': training_stats['accuracies'][-1] - training_stats['accuracies'][0]
        }
    
    def get_collaboration_statistics(self) -> Dict[str, Any]:
        """å”èª¿æ©Ÿèƒ½ã®çµ±è¨ˆæƒ…å ±å–å¾—"""
        if not self.use_collaboration:
            return {'collaboration_enabled': False}
        
        pool_stats = self.direction_pool.get_statistics()
        
        return {
            'collaboration_enabled': True,
            'pool_statistics': pool_stats,
            'collaboration_stats': self.collaboration_stats,
            'user_count': len(self.user_contexts),
            'learning_enabled': self.gate_network is not None
        }
    
    def save_collaboration_state(self, filepath: str):
        """å”èª¿çŠ¶æ…‹ã®ä¿å­˜"""
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - nothing to save")
            return
        
        # ãƒ—ãƒ¼ãƒ«çŠ¶æ…‹ä¿å­˜
        pool_path = filepath.replace('.json', '_pool.json')
        self.direction_pool.save_pool(pool_path)
        
        # å…¨ä½“çŠ¶æ…‹ä¿å­˜
        state_data = {
            'config': self.collaboration_config,
            'stats': self.collaboration_stats,
            'user_contexts_count': len(self.user_contexts),
            'timestamp': time.time()
        }
        
        with open(filepath, 'w') as f:
            json.dump(state_data, f, indent=2)
        
        logger.info(f"Collaboration state saved to {filepath}")
    
    def load_collaboration_state(self, filepath: str):
        """å”èª¿çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿"""
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - cannot load state")
            return
        
        try:
            # ãƒ—ãƒ¼ãƒ«çŠ¶æ…‹èª­ã¿è¾¼ã¿
            pool_path = filepath.replace('.json', '_pool.json')
            if Path(pool_path).exists():
                self.direction_pool.load_pool(pool_path)
            
            # å…¨ä½“çŠ¶æ…‹èª­ã¿è¾¼ã¿
            with open(filepath, 'r') as f:
                state_data = json.load(f)
            
            self.collaboration_stats = state_data.get('stats', {})
            
            logger.info(f"Collaboration state loaded from {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to load collaboration state: {e}")

# ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
ChameleonCFS = CollaborativeChameleonEditor

if __name__ == "__main__":
    # çµ±åˆãƒ†ã‚¹ãƒˆ
    print("ğŸ¦ Chameleon-CFS Integration Test")
    
    # å”èª¿æ©Ÿèƒ½ç„¡åŠ¹ï¼ˆæ—¢å­˜äº’æ›ï¼‰
    editor_legacy = CollaborativeChameleonEditor(use_collaboration=False)
    print(f"Legacy mode: {not editor_legacy.use_collaboration}")
    
    # å”èª¿æ©Ÿèƒ½æœ‰åŠ¹
    editor_collaborative = CollaborativeChameleonEditor(
        use_collaboration=True,
        collaboration_config={'enable_learning': True}
    )
    print(f"Collaborative mode: {editor_collaborative.use_collaboration}")
    
    # çµ±è¨ˆç¢ºèª
    stats = editor_collaborative.get_collaboration_statistics()
    print(f"Collaboration stats: {stats['collaboration_enabled']}")
    
    print("âœ… Chameleon-CFS integration test completed")