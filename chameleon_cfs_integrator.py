#!/usr/bin/env python3
"""
Chameleon-CFSçµ±åˆå™¨: æ—¢å­˜Chameleonã‚³ãƒ¼ãƒ‰ã®æˆ¦ç•¥çš„æ”¹å¤‰
å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚·ã‚¹ãƒ†ãƒ ã¸ã®æ®µéšçš„æ‹¡å¼µ

ç‰¹å¾´:
- æ—¢å­˜ChameleonEditorã®å®Œå…¨æ‹¡å¼µ
- ä¸‹ä½äº’æ›æ€§ä¿è¨¼ï¼ˆuse_collaboration=Falseï¼‰
- ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·å”èª¿å­¦ç¿’
- è»½é‡å­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçµ±åˆ
"""

import torch
import torch.nn as nn
import numpy as np
from typing import Dict, List, Tuple, Any, Optional, Union
import logging
from pathlib import Path
import json
import time

from cfs_chameleon_extension import (
    CollaborativeDirectionPool, DirectionPiece, UserContext, 
    LightweightGateNetwork
)

# æ—¢å­˜ã®ChameleonEditorã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã¾ãŸã¯ç¶™æ‰¿ç”¨ã«å‚ç…§ï¼‰
try:
    from chameleon_evaluator import ChameleonEditor as BaseChameleonEditor
    BASE_EDITOR_AVAILABLE = True
except ImportError:
    # åŸºæœ¬ã‚¯ãƒ©ã‚¹ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    class BaseChameleonEditor:
        def __init__(self, *args, **kwargs):
            pass
    BASE_EDITOR_AVAILABLE = False

logger = logging.getLogger(__name__)

class CollaborativeChameleonEditor(BaseChameleonEditor):
    """
    å”èª¿çš„Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼
    
    æ—¢å­˜ã®ChameleonEditorã‚’æ‹¡å¼µã—ã€å”èª¿çš„æ©Ÿèƒ½ã‚’è¿½åŠ 
    use_collaborationãƒ•ãƒ©ã‚°ã§æ—¢å­˜æ©Ÿèƒ½ã¨ã®å®Œå…¨äº’æ›æ€§ã‚’ä¿æŒ
    """
    
    def __init__(self, model_name: str = "meta-llama/Llama-3.2-3B-Instruct", 
                 device: str = "auto", torch_dtype: str = "float32",
                 use_collaboration: bool = False, 
                 collaboration_config: Dict[str, Any] = None,
                 config_path: str = None):
        """
        å”èª¿çš„Chameleonã‚¨ãƒ‡ã‚£ã‚¿ãƒ¼åˆæœŸåŒ–
        
        Args:
            model_name: ãƒ¢ãƒ‡ãƒ«å
            device: ãƒ‡ãƒã‚¤ã‚¹
            torch_dtype: ãƒ‡ãƒ¼ã‚¿å‹
            use_collaboration: å”èª¿æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
            collaboration_config: å”èª¿æ©Ÿèƒ½è¨­å®š
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        self.config_data = None
        self.theta_p_path = None
        self.theta_n_path = None
        self.direction_p_path = None
        self.direction_n_path = None
        
        if config_path:
            import yaml
            try:
                with open(config_path, 'r') as f:
                    self.config_data = yaml.safe_load(f)
                    model_config = self.config_data.get('model', {})
                    model_name = model_config.get('name', model_name)
                    device = model_config.get('device', device)
                    torch_dtype = model_config.get('torch_dtype', torch_dtype)
                    
                    # Theta vectorã¨Direction vectorãƒ‘ã‚¹èª­ã¿è¾¼ã¿
                    chameleon_config = self.config_data.get('chameleon', {})
                    self.theta_p_path = chameleon_config.get('theta_p_path')
                    self.theta_n_path = chameleon_config.get('theta_n_path')
                    self.direction_p_path = chameleon_config.get('direction_p_path')
                    self.direction_n_path = chameleon_config.get('direction_n_path')
                    
            except Exception as e:
                logger.warning(f"Config file reading error: {e}, using defaults")
        
        # åŸºåº•ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–
        if BASE_EDITOR_AVAILABLE:
            super().__init__(model_name, device, torch_dtype)
            
            # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰target_layersã‚’ä¸Šæ›¸ãé©ç”¨
            if self.config_data and 'chameleon' in self.config_data:
                chameleon_config = self.config_data['chameleon']
                if 'target_layers' in chameleon_config:
                    logger.info(f"Overriding target_layers from config: {chameleon_config['target_layers']}")
                    # åŸºåº•ã‚¯ãƒ©ã‚¹ã«ç›´æ¥é©ç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦å¾Œã§åˆ©ç”¨ï¼‰
                    self._config_target_layers = chameleon_config['target_layers']
                if 'alpha_personal' in chameleon_config:
                    self._config_alpha_personal = chameleon_config['alpha_personal'] 
                if 'alpha_general' in chameleon_config:
                    self._config_alpha_general = chameleon_config['alpha_general']
        
        # å”èª¿æ©Ÿèƒ½ã®è¨­å®š
        self.use_collaboration = use_collaboration
        self.collaboration_config = collaboration_config or self._default_collaboration_config()
        
        # Theta vectorsèª­ã¿è¾¼ã¿
        self._load_theta_vectors()
        
        # Direction vectorsèª­ã¿è¾¼ã¿
        self._load_direction_vectors()
        
        # å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        if self.use_collaboration:
            self._initialize_collaboration_components()
        
        # ãƒ•ãƒƒã‚¯ç®¡ç†åˆæœŸåŒ–
        self.direction_hooks = []
        
        logger.info(f"CollaborativeChameleonEditor initialized (collaboration: {use_collaboration})")
    
    def _load_theta_vectors(self):
        """Theta vectorsèª­ã¿è¾¼ã¿ï¼ˆå¼·åŒ–ç‰ˆ - ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼‰"""
        try:
            import numpy as np
            from pathlib import Path
            
            if not self.theta_p_path or not self.theta_n_path:
                error_msg = "âŒ CRITICAL: Theta vector paths not specified in config"
                logger.error(error_msg)
                print(error_msg)
                self.theta_personal = None
                self.theta_neutral = None
                return False
            
            # ãƒ‘ã‚¹å­˜åœ¨ç¢ºèª
            theta_p_path = Path(self.theta_p_path)
            theta_n_path = Path(self.theta_n_path)
            
            if not theta_p_path.exists():
                error_msg = f"âŒ CRITICAL: Theta personal file not found: {theta_p_path.absolute()}"
                logger.error(error_msg)
                print(error_msg)
                self.theta_personal = None
                self.theta_neutral = None
                return False
                
            if not theta_n_path.exists():
                error_msg = f"âŒ CRITICAL: Theta neutral file not found: {theta_n_path.absolute()}"
                logger.error(error_msg)
                print(error_msg)
                self.theta_personal = None
                self.theta_neutral = None
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
            self.theta_personal = np.load(theta_p_path)
            self.theta_neutral = np.load(theta_n_path)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if self.theta_personal.size == 0:
                error_msg = f"âŒ CRITICAL: Theta personal vector is empty"
                logger.error(error_msg)
                print(error_msg)
                return False
                
            if self.theta_neutral.size == 0:
                error_msg = f"âŒ CRITICAL: Theta neutral vector is empty"
                logger.error(error_msg)
                print(error_msg)
                return False
                
            if self.theta_personal.shape != self.theta_neutral.shape:
                error_msg = f"âŒ CRITICAL: Theta vector shape mismatch: P={self.theta_personal.shape}, N={self.theta_neutral.shape}"
                logger.error(error_msg)
                print(error_msg)
                return False
            
            success_msg = f"âœ… Theta vectors loaded and validated: P={self.theta_personal.shape}, N={self.theta_neutral.shape}"
            logger.info(success_msg)
            print(success_msg)
            return True
                
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Theta vector loading error: {e}"
            logger.error(error_msg)
            print(error_msg)
            self.theta_personal = None
            self.theta_neutral = None
            return False
    
    def _load_direction_vectors(self):
        """Direction vectorsèª­ã¿è¾¼ã¿ï¼ˆå¼·åŒ–ç‰ˆ - ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼‰"""
        try:
            import numpy as np
            from pathlib import Path
            
            if not self.direction_p_path or not self.direction_n_path:
                error_msg = "âŒ CRITICAL: Direction vector paths not specified in config"
                logger.error(error_msg)
                print(error_msg)
                self.direction_personal = None
                self.direction_neutral = None
                return False
            
            # ãƒ‘ã‚¹å­˜åœ¨ç¢ºèª
            direction_p_path = Path(self.direction_p_path)
            direction_n_path = Path(self.direction_n_path)
            
            if not direction_p_path.exists():
                error_msg = f"âŒ CRITICAL: Direction personal file not found: {direction_p_path.absolute()}"
                logger.error(error_msg)
                print(error_msg)
                self.direction_personal = None
                self.direction_neutral = None
                return False
                
            if not direction_n_path.exists():
                error_msg = f"âŒ CRITICAL: Direction neutral file not found: {direction_n_path.absolute()}"
                logger.error(error_msg)
                print(error_msg)
                self.direction_personal = None
                self.direction_neutral = None
                return False
            
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨æ¤œè¨¼
            self.direction_personal = np.load(direction_p_path)
            self.direction_neutral = np.load(direction_n_path)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if self.direction_personal.size == 0:
                error_msg = f"âŒ CRITICAL: Direction personal vector is empty"
                logger.error(error_msg)
                print(error_msg)
                return False
                
            if self.direction_neutral.size == 0:
                error_msg = f"âŒ CRITICAL: Direction neutral vector is empty"
                logger.error(error_msg)
                print(error_msg)
                return False
                
            if self.direction_personal.shape != self.direction_neutral.shape:
                error_msg = f"âŒ CRITICAL: Direction vector shape mismatch: P={self.direction_personal.shape}, N={self.direction_neutral.shape}"
                logger.error(error_msg)
                print(error_msg)
                return False
            
            success_msg = f"âœ… Direction vectors loaded and validated: P={self.direction_personal.shape}, N={self.direction_neutral.shape}"
            logger.info(success_msg)
            print(success_msg)
            return True
                
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Direction vector loading error: {e}"
            logger.error(error_msg)
            print(error_msg)
            self.direction_personal = None
            self.direction_neutral = None
            return False
    
    def generate_with_chameleon(self, prompt: str, alpha_personal: float = None, alpha_neutral: float = None, 
                               target_layers: List[str] = None, max_length: int = 128) -> str:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸChameleonç·¨é›†ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç„¡åŠ¹åŒ–ç‰ˆï¼‰
        """
        # Direction vectorså„ªå…ˆã§å­˜åœ¨ç¢ºèªï¼ˆChameleonç·¨é›†ã«å¿…è¦ï¼‰
        if self.direction_personal is None or self.direction_neutral is None:
            error_msg = "âŒ ABORT: Direction vectors not loaded, Chameleon editing cannot proceed"
            logger.error(error_msg)
            print(error_msg)
            print("ğŸ”§ Fix required: Check direction vector file paths in config:")
            print(f"   - direction_p_path: {self.direction_p_path}")
            print(f"   - direction_n_path: {self.direction_n_path}")
            raise ValueError("Direction vectors not available - fix configuration and retry")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆå¼•æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰
        if alpha_personal is None and hasattr(self, '_config_alpha_personal'):
            alpha_personal = self._config_alpha_personal
        if alpha_neutral is None and hasattr(self, '_config_alpha_general'):
            alpha_neutral = self._config_alpha_general
        if target_layers is None and hasattr(self, '_config_target_layers'):
            target_layers = self._config_target_layers
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®šï¼ˆconfigæœªå®šç¾©ã®å ´åˆï¼‰
        if alpha_personal is None:
            alpha_personal = 0.3
        if alpha_neutral is None:
            alpha_neutral = -0.05
        if target_layers is None:
            target_layers = ["model.layers.14.mlp"]
            
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ¤œè¨¼ã¨ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        debug_msg = f"ğŸ¯ Chameleon parameters: Î±_p={alpha_personal}, Î±_n={alpha_neutral}, max_length={max_length}, layers={target_layers}"
        logger.info(debug_msg)
        print(debug_msg)
        
        try:
            # Chameleonç·¨é›†å®Ÿè¡Œï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç„¡ã—ï¼‰
            result = self._execute_chameleon_generation(prompt, alpha_personal, alpha_neutral, target_layers, max_length)
            success_msg = f"âœ… Chameleon editing completed successfully: {len(result)} chars generated"
            logger.info(success_msg)
            print(success_msg)
            return result
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Chameleon generation failed: {e}"
            logger.error(error_msg)
            print(error_msg)
            print("ğŸ”§ Debug information:")
            print(f"   - Model available: {hasattr(self, 'model')}")
            print(f"   - Tokenizer available: {hasattr(self, 'tokenizer')}")
            print(f"   - Direction vectors loaded: {self.direction_personal is not None and self.direction_neutral is not None}")
            raise e  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç¦æ­¢ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’æ˜ç¤ºçš„ã«ä¼ æ’­
    
    def _execute_chameleon_generation(self, prompt: str, alpha_personal: float, alpha_neutral: float, 
                                     target_layers: List[str], max_length: int) -> str:
        """Chameleonç·¨é›†å®Ÿè¡Œï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        # åŸºåº•ã‚¯ãƒ©ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’åˆ©ç”¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
        try:
            if BASE_EDITOR_AVAILABLE and hasattr(self.__class__.__bases__[0], 'generate_with_chameleon'):
                return super().generate_with_chameleon(prompt, alpha_personal, alpha_neutral, target_layers, max_length)
        except:
            pass  # åŸºåº•ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ç‹¬è‡ªå®Ÿè£…ã‚’ä½¿ç”¨
        
        # Direction vectors ã‚’ä½¿ç”¨ã—ãŸç‹¬è‡ªå®Ÿè£…
        if not hasattr(self, 'model') or not hasattr(self, 'tokenizer'):
            error_msg = "âŒ CRITICAL: Model or tokenizer not available for Chameleon generation"
            logger.error(error_msg)
            print(error_msg)
            raise AttributeError("Model/tokenizer not initialized - cannot perform generation")
        
        try:
            # ãƒ•ãƒƒã‚¯ç™»éŒ²
            self._register_direction_hooks(target_layers, alpha_personal, alpha_neutral)
            
            # ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=max_length)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            with torch.no_grad():
                outputs = self.model.generate(**inputs, max_length=max_length, do_sample=False)
                generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
                result = generated[len(prompt):].strip()
            
            # ãƒ•ãƒƒã‚¯å‰Šé™¤
            self._remove_direction_hooks()
            
            if not result or len(result.strip()) == 0:
                error_msg = "âŒ CRITICAL: Chameleon generation produced empty result"
                logger.error(error_msg)
                print(error_msg)
                raise ValueError("Generation failed - empty result")
            
            return result
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Chameleon generation internal error: {e}"
            logger.error(error_msg)
            print(error_msg)
            self._remove_direction_hooks()  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒ•ãƒƒã‚¯å‰Šé™¤
            print("ğŸ”§ Hook removal completed after error")
            raise e  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ç¦æ­¢ã—ã€ã‚¨ãƒ©ãƒ¼ã‚’ä¼ æ’­
    
    def _fallback_generation(self, prompt: str, max_length: int) -> str:
        """âŒ DEPRECATED: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã¯å»ƒæ­¢ - RuntimeError ã‚’æŠ•ã’ã‚‹"""
        error_msg = "âŒ CRITICAL: Fallback generation attempted - this indicates a system failure"
        logger.error(error_msg)
        raise RuntimeError(error_msg + f" (prompt: '{prompt[:50]}...', max_length: {max_length})")
    
    def _register_direction_hooks(self, target_layers: List[str], alpha_personal: float, alpha_neutral: float):
        """Direction vectorç·¨é›†ãƒ•ãƒƒã‚¯ã®ç™»éŒ²"""
        def direction_editing_hook(module, input, output):
            """Direction vectorã‚’ä½¿ç”¨ã—ãŸç·¨é›†ãƒ•ãƒƒã‚¯"""
            try:
                if isinstance(output, tuple):
                    output_tensor = output[0]
                    additional_outputs = output[1:]
                else:
                    output_tensor = output
                    additional_outputs = ()
                
                # Direction vectorã‚’ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚’é©ç”¨
                edited_output = self._apply_direction_editing(
                    output_tensor, alpha_personal, alpha_neutral
                )
                
                if additional_outputs:
                    return (edited_output,) + additional_outputs
                else:
                    return edited_output
                    
            except Exception as e:
                logger.warning(f"Direction hook error: {e}")
                return output
        
        # ãƒ•ãƒƒã‚¯ç™»éŒ²
        for layer_name in target_layers:
            try:
                layer = self._get_layer_by_name(layer_name)
                if layer is not None:
                    hook = layer.register_forward_hook(direction_editing_hook)
                    self.direction_hooks.append(hook)
                    logger.info(f"Registered direction hook on {layer_name}")
            except Exception as e:
                logger.warning(f"Failed to register direction hook on {layer_name}: {e}")
    
    def _remove_direction_hooks(self):
        """Direction vectorãƒ•ãƒƒã‚¯ã®å‰Šé™¤"""
        for hook in self.direction_hooks:
            hook.remove()
        self.direction_hooks = []
    
    def _get_layer_by_name(self, layer_name: str):
        """ãƒ¬ã‚¤ãƒ¤ãƒ¼åã‹ã‚‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—"""
        try:
            parts = layer_name.split('.')
            layer = self.model
            for part in parts:
                if part.isdigit():
                    layer = layer[int(part)]
                else:
                    layer = getattr(layer, part)
            return layer
        except:
            logger.warning(f"Layer {layer_name} not found")
            return None
    
    def _apply_direction_editing(self, output_tensor: torch.Tensor, alpha_personal: float, alpha_neutral: float) -> torch.Tensor:
        """Direction vectorã‚’ä½¿ç”¨ã—ãŸåŸ‹ã‚è¾¼ã¿ç·¨é›†é©ç”¨"""
        try:
            # æ¬¡å…ƒå–å¾—
            if len(output_tensor.shape) == 3:
                hidden_dim = output_tensor.shape[-1]
            elif len(output_tensor.shape) == 2:
                hidden_dim = output_tensor.shape[-1]
            else:
                return output_tensor
            
            # Direction vectorsã‚’é©åˆ‡ãªé•·ã•ã«èª¿æ•´
            personal_vec = torch.tensor(
                self.direction_personal[:hidden_dim],
                dtype=output_tensor.dtype,
                device=output_tensor.device
            )
            neutral_vec = torch.tensor(
                self.direction_neutral[:hidden_dim],
                dtype=output_tensor.dtype,
                device=output_tensor.device
            )
            
            # ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—
            edit_vector = alpha_personal * personal_vec + alpha_neutral * neutral_vec
            
            # å½¢çŠ¶èª¿æ•´
            if len(output_tensor.shape) == 3:
                edit_vector = edit_vector.view(1, 1, -1)
            elif len(output_tensor.shape) == 2:
                edit_vector = edit_vector.view(1, -1)
            
            return output_tensor + edit_vector
            
        except Exception as e:
            logger.warning(f"Direction editing application failed: {e}")
            return output_tensor
    
    def _default_collaboration_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå”èª¿è¨­å®š"""
        return {
            'pool_size': 1000,
            'rank_reduction': 32,
            'top_k_pieces': 10,
            'fusion_strategy': 'analytical',
            'selection_strategy': 'analytical',
            'privacy_noise_std': 0.01,
            'enable_learning': False,
            'auto_dimension_detection': True,  # è‡ªå‹•æ¬¡å…ƒæ¤œå‡º
            'adaptive_vector_sizing': True,   # é©å¿œçš„ãƒ™ã‚¯ãƒˆãƒ«ã‚µã‚¤ã‚ºèª¿æ•´
            'gate_network_config': {
                'embedding_dim': 768,
                'num_directions': 200,
                'hidden_dim': 256
            }
        }
    
    def _initialize_collaboration_components(self):
        """å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        config = self.collaboration_config
        
        # å”èª¿æ–¹å‘ãƒ—ãƒ¼ãƒ«
        self.direction_pool = CollaborativeDirectionPool(
            pool_size=config.get('pool_size', 1000),
            rank_reduction=config.get('rank_reduction', 32)
        )
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆè¾æ›¸
        self.user_contexts: Dict[str, UserContext] = {}
        
        # è»½é‡å­¦ç¿’ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        enable_learning = config.get('enable_learning', False)
        if enable_learning:
            gate_config = config.get('gate_network_config', {
                'embedding_dim': 768,
                'num_directions': 200,
                'hidden_dim': 256
            })
            self.gate_network = LightweightGateNetwork(
                embedding_dim=gate_config.get('embedding_dim', 768),
                num_directions=gate_config.get('num_directions', 200),
                hidden_dim=gate_config.get('hidden_dim', 256)
            )
            self.gate_optimizer = torch.optim.Adam(self.gate_network.parameters(), lr=1e-3)
        else:
            self.gate_network = None
            self.gate_optimizer = None
        
        # å”èª¿çµ±è¨ˆ
        self.collaboration_stats = {
            'total_collaborations': 0,
            'cache_hits': 0,
            'avg_improvement': 0.0,
            'privacy_applications': 0,
            'collaborative_directions_generated': 0
        }
        
        logger.info("Collaboration components initialized")
    
    def add_user_direction_to_pool(self, user_id: str, personal_direction: np.ndarray, 
                                 neutral_direction: np.ndarray, semantic_context: str = "") -> bool:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’å”èª¿ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            personal_direction: å€‹äººæ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
            neutral_direction: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«
            semantic_context: æ„å‘³çš„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            
        Returns:
            è¿½åŠ æˆåŠŸã‹ã©ã†ã‹
        """
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - direction not added to pool")
            return False
        
        try:
            # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ãƒã‚¤ã‚ºè¿½åŠ 
            noise_std = self.collaboration_config.get('privacy_noise_std', 0.01)
            if noise_std > 0:
                noise = np.random.normal(0, noise_std, personal_direction.shape)
                personal_direction = personal_direction + noise
                self.collaboration_stats['privacy_applications'] += 1
            
            # æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’ãƒ—ãƒ¼ãƒ«ã«è¿½åŠ 
            pieces = self.direction_pool.add_direction_vector(
                personal_direction, user_id, semantic_context
            )
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ/æ›´æ–°
            if user_id not in self.user_contexts:
                self.user_contexts[user_id] = UserContext(
                    user_id=user_id,
                    preference_vector=personal_direction[:min(len(personal_direction), 768)],
                    history_embedding=np.mean([personal_direction, neutral_direction], axis=0),
                    activity_level=1.0,
                    similarity_cache={}
                )
            else:
                # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ãƒ¬ãƒ™ãƒ«æ›´æ–°
                self.user_contexts[user_id].activity_level += 0.1
            
            logger.info(f"Added {len(pieces)} direction pieces for user {user_id}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to add user direction to pool: {e}")
            return False
    
    def collaborative_edit_embedding(self, base_embedding: torch.Tensor, user_id: str,
                                   query_context: str = "", alpha_personal: float = 1.5, 
                                   alpha_neutral: float = -0.8) -> torch.Tensor:
        """
        å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã®å®Ÿè£…ï¼ˆæ¬¡å…ƒä¸æ•´åˆä¿®æ­£ç‰ˆï¼‰
        
        Args:
            base_embedding: åŸºæœ¬åŸ‹ã‚è¾¼ã¿
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID  
            query_context: ã‚¯ã‚¨ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
            alpha_personal: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦
            alpha_neutral: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦
            
        Returns:
            ç·¨é›†ã•ã‚ŒãŸåŸ‹ã‚è¾¼ã¿
        """
        # å”èª¿æ©Ÿèƒ½ãŒç„¡åŠ¹ã®å ´åˆã¯æ—¢å­˜ã®æ–¹æ³•ã‚’ä½¿ç”¨
        if not self.use_collaboration:
            return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
        
        try:
            # 1. å‹•çš„æ¬¡å…ƒæ¤œå‡º
            actual_hidden_dim = self._detect_actual_hidden_dimension(base_embedding)
            
            # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå–å¾—ï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯å‹•çš„ä½œæˆï¼‰
            if user_id not in self.user_contexts:
                logger.info(f"Creating new user context for {user_id}")
                self._create_dynamic_user_context(user_id, actual_hidden_dim)
            
            user_context = self.user_contexts[user_id]
            
            # 3. ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆï¼ˆé©å¿œçš„ã‚µã‚¤ã‚ºï¼‰
            query_embedding = self._generate_adaptive_query_embedding(query_context, actual_hidden_dim)
            
            # 4. å”èª¿çš„ãƒ”ãƒ¼ã‚¹é¸æŠ
            selected_pieces = self.direction_pool.select_collaborative_pieces(
                user_context=user_context,
                query_embedding=query_embedding,
                top_k=self.collaboration_config.get('top_k_pieces', 10),
                strategy=self.collaboration_config.get('selection_strategy', 'analytical')
            )
            
            if not selected_pieces:
                logger.debug("No collaborative pieces available - using legacy editing")
                return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
            
            # 5. æ–¹å‘çµ±åˆï¼ˆé©å¿œçš„ã‚µã‚¤ã‚ºï¼‰
            collaborative_direction = self.direction_pool.fuse_selected_directions(
                selected_pieces, 
                fusion_strategy=self.collaboration_config.get('fusion_strategy', 'analytical')
            )
            
            # 6. æ¬¡å…ƒæ•´åˆæ€§ç¢ºä¿
            collaborative_direction = self._ensure_dimension_compatibility(
                collaborative_direction, actual_hidden_dim
            )
            
            # 7. å”èª¿æ–¹å‘ã®é©ç”¨
            collaborative_direction_tensor = torch.tensor(
                collaborative_direction, 
                dtype=base_embedding.dtype, 
                device=base_embedding.device
            )
            
            # 8. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
            edit_vector = self._create_hybrid_edit_vector(
                collaborative_direction_tensor, alpha_personal, alpha_neutral, actual_hidden_dim
            )
            
            # 9. å½¢çŠ¶èª¿æ•´ã¨ç·¨é›†é©ç”¨
            edit_vector = self._adjust_vector_shape(edit_vector, base_embedding.shape)
            edited_embedding = base_embedding + edit_vector
            
            # 10. çµ±è¨ˆæ›´æ–°
            self.collaboration_stats['total_collaborations'] += 1
            
            logger.debug(f"Applied collaborative editing for user {user_id} (dim={actual_hidden_dim}, pieces={len(selected_pieces)})")
            return edited_embedding
            
        except Exception as e:
            logger.warning(f"Collaborative editing failed: {e} - falling back to legacy")
            return self._legacy_edit_embedding(base_embedding, alpha_personal, alpha_neutral)
    
    def _legacy_edit_embedding(self, base_embedding: torch.Tensor, 
                             alpha_personal: float, alpha_neutral: float) -> torch.Tensor:
        """æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ç·¨é›†ï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        # Direction vectorså„ªå…ˆã§ä½¿ç”¨
        if self.direction_personal is not None and self.direction_neutral is not None:
            personal_direction = torch.tensor(self.direction_personal, dtype=base_embedding.dtype, device=base_embedding.device)
            neutral_direction = torch.tensor(self.direction_neutral, dtype=base_embedding.dtype, device=base_embedding.device)
        elif hasattr(self, 'personal_direction') and hasattr(self, 'neutral_direction') and \
             self.personal_direction is not None and self.neutral_direction is not None:
            personal_direction = self.personal_direction
            neutral_direction = self.neutral_direction
        else:
            logger.warning("No direction vectors available for editing")
            return base_embedding
        
        # æ—¢å­˜ã®Chameleonç·¨é›†ãƒ­ã‚¸ãƒƒã‚¯
        device = base_embedding.device
        dtype = base_embedding.dtype
        
        # é©åˆ‡ãªæ¬¡å…ƒã‚’å–å¾—
        if len(base_embedding.shape) == 3:
            hidden_dim = base_embedding.shape[-1]
        elif len(base_embedding.shape) == 2:
            hidden_dim = base_embedding.shape[-1]
        else:
            return base_embedding
        
        # Direction vectorsã‚’é©åˆ‡ãªé•·ã•ã«èª¿æ•´
        personal_vec = personal_direction[:hidden_dim]
        neutral_vec = neutral_direction[:hidden_dim]
        
        # Tensorã‚’GPUã«ç§»å‹•
        if not isinstance(personal_vec, torch.Tensor):
            personal_vec = torch.tensor(personal_vec, dtype=dtype, device=device)
        if not isinstance(neutral_vec, torch.Tensor):
            neutral_vec = torch.tensor(neutral_vec, dtype=dtype, device=device)
        
        # ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«è¨ˆç®—
        edit_vector = alpha_personal * personal_vec + alpha_neutral * neutral_vec
        
        # å½¢çŠ¶èª¿æ•´
        if len(base_embedding.shape) == 3:
            edit_vector = edit_vector.view(1, 1, -1)
        elif len(base_embedding.shape) == 2:
            edit_vector = edit_vector.view(1, -1)
        
        return base_embedding + edit_vector
    
    def _detect_actual_hidden_dimension(self, embedding: torch.Tensor) -> int:
        """å®Ÿéš›ã®éš ã‚Œæ¬¡å…ƒã‚’å‹•çš„æ¤œå‡º"""
        if len(embedding.shape) == 3:
            return embedding.shape[-1]  # (batch, seq, hidden)
        elif len(embedding.shape) == 2:
            return embedding.shape[-1]  # (batch, hidden)
        else:
            return 768  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    def _create_dynamic_user_context(self, user_id: str, hidden_dim: int):
        """å‹•çš„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ"""
        from cfs_chameleon_extension import UserContext
        
        preference_vector = np.random.randn(min(hidden_dim, 768)) * 0.1
        history_embedding = np.random.randn(min(hidden_dim, 768)) * 0.05
        
        self.user_contexts[user_id] = UserContext(
            user_id=user_id,
            preference_vector=preference_vector,
            history_embedding=history_embedding,
            activity_level=1.0,
            similarity_cache={}
        )
    
    def _generate_adaptive_query_embedding(self, query_context: str, hidden_dim: int) -> np.ndarray:
        """é©å¿œçš„ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ"""
        if not query_context:
            return np.zeros(min(hidden_dim, 768))
        
        try:
            context_hash = hash(query_context) % 1000000
            embedding_size = min(hidden_dim, 768)
            context_embedding = np.random.RandomState(context_hash).randn(embedding_size)
            return context_embedding
        except:
            return np.zeros(min(hidden_dim, 768))
    
    def _ensure_dimension_compatibility(self, direction: np.ndarray, target_dim: int) -> np.ndarray:
        """æ¬¡å…ƒæ•´åˆæ€§ã‚’ç¢ºä¿"""
        if len(direction) == target_dim:
            return direction
        elif len(direction) > target_dim:
            # ãƒˆãƒªãƒŸãƒ³ã‚°
            return direction[:target_dim]
        else:
            # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
            padded = np.zeros(target_dim)
            padded[:len(direction)] = direction
            return padded
    
    def _create_hybrid_edit_vector(self, collaborative_direction: torch.Tensor, 
                                 alpha_personal: float, alpha_neutral: float, 
                                 hidden_dim: int) -> torch.Tensor:
        """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ç·¨é›†ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆï¼ˆDirection vectorsä½¿ç”¨ï¼‰"""
        try:
            # Direction vectorså„ªå…ˆã§ä½¿ç”¨
            if self.direction_personal is not None and len(self.direction_personal) >= hidden_dim:
                personal_direction = torch.tensor(
                    self.direction_personal[:hidden_dim],
                    device=collaborative_direction.device, 
                    dtype=collaborative_direction.dtype
                )
                # å€‹äººæ–¹å‘ã¨å”èª¿æ–¹å‘ã®çµåˆ
                personal_component = alpha_personal * personal_direction
                collaborative_component = 0.3 * collaborative_direction  # å”èª¿æˆåˆ†ã®é‡ã¿ã‚’èª¿æ•´
                return personal_component + collaborative_component
            
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å”èª¿æ–¹å‘ã®ã¿ä½¿ç”¨
            elif hasattr(self, 'personal_direction') and self.personal_direction is not None and len(self.personal_direction) >= hidden_dim:
                personal_component = alpha_personal * self.personal_direction[:hidden_dim].to(
                    device=collaborative_direction.device, dtype=collaborative_direction.dtype
                )
                collaborative_component = 0.3 * collaborative_direction
                return personal_component + collaborative_component
            
            else:
                # å”èª¿æ–¹å‘ã®ã¿ä½¿ç”¨
                return alpha_personal * collaborative_direction
            
        except Exception as e:
            logger.warning(f"Hybrid vector creation failed: {e} - using collaborative only")
            return alpha_personal * collaborative_direction
    
    def _adjust_vector_shape(self, edit_vector: torch.Tensor, target_shape: torch.Size) -> torch.Tensor:
        """ãƒ™ã‚¯ãƒˆãƒ«å½¢çŠ¶èª¿æ•´"""
        if len(target_shape) == 3:
            # (batch, seq, hidden)ã®å ´åˆ
            return edit_vector.view(1, 1, -1)
        elif len(target_shape) == 2:
            # (batch, hidden)ã®å ´åˆ  
            return edit_vector.view(1, -1)
        else:
            return edit_vector
    
    def _extract_context_embedding(self, prompt: str) -> np.ndarray:
        """
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‚„å±¥æ­´ã‹ã‚‰ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆ
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            ã‚¯ã‚¨ãƒªåŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ« (768æ¬¡å…ƒ)
        """
        try:
            if not prompt:
                logger.warning("Empty prompt provided for context embedding")
                return np.zeros(768)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å‰å‡¦ç†
            clean_prompt = prompt.strip()[:200]  # æœ€åˆã®200æ–‡å­—ã‚’ä½¿ç”¨
            
            if hasattr(self, 'model') and hasattr(self, 'tokenizer'):
                # ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸå®Ÿéš›ã®åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
                try:
                    inputs = self.tokenizer(clean_prompt, return_tensors='pt', truncation=True, max_length=128)
                    inputs = {k: v.to(self.device) for k, v in inputs.items()}
                    
                    with torch.no_grad():
                        # æœ€å¾Œã®éš ã‚Œå±¤ã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’æŠ½å‡º
                        outputs = self.model(**inputs, output_hidden_states=True)
                        last_hidden_state = outputs.hidden_states[-1]  # æœ€å¾Œã®å±¤
                        # å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°
                        embedding = last_hidden_state.mean(dim=1).squeeze().cpu().numpy()
                        
                    # 768æ¬¡å…ƒã«èª¿æ•´ï¼ˆå¿…è¦ã«å¿œã˜ã¦åˆ‡ã‚Šè©°ã‚ã¾ãŸã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰
                    if embedding.shape[0] > 768:
                        embedding = embedding[:768]
                    elif embedding.shape[0] < 768:
                        padded = np.zeros(768)
                        padded[:embedding.shape[0]] = embedding
                        embedding = padded
                    
                    logger.debug(f"Generated model-based embedding: shape={embedding.shape}")
                    return embedding
                    
                except Exception as e:
                    error_msg = f"âŒ CRITICAL: Model-based embedding failed: {e}"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg + f" (prompt: '{clean_prompt[:50]}...')")
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãŒåˆ©ç”¨ã§ããªã„å ´åˆã‚‚RuntimeError
            error_msg = "âŒ CRITICAL: Model or tokenizer not available for context embedding extraction"
            logger.error(error_msg)
            raise RuntimeError(error_msg + f" (prompt: '{clean_prompt[:50]}...')")
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Context embedding generation failed: {e}"
            logger.error(error_msg)
            raise RuntimeError(error_msg + f" (prompt: '{clean_prompt[:50]}...')")
    
    def _generate_query_embedding(self, query_context: str, base_embedding: torch.Tensor) -> np.ndarray:
        """ã‚¯ã‚¨ãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ç¶­æŒï¼‰"""
        logger.warning("_generate_query_embedding is deprecated, use _extract_context_embedding instead")
        return self._extract_context_embedding(query_context)
    
    def _generate_collaborative_directions(self, user_id: str, prompt: str) -> Dict[str, torch.Tensor]:
        """
        å”èª¿çš„æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
        
        Args:
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            
        Returns:
            å”èª¿çš„æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã®è¾æ›¸
        """
        try:
            if not self.use_collaboration:
                error_msg = "âŒ CRITICAL: Collaboration not enabled, cannot generate collaborative directions"
                logger.error(error_msg)
                raise RuntimeError(error_msg + f" (user_id: {user_id})")
            
            if not hasattr(self, 'direction_pool') or self.direction_pool is None:
                error_msg = "âŒ CRITICAL: Direction pool not initialized"
                logger.error(error_msg)
                raise RuntimeError(error_msg + f" (user_id: {user_id})")
            
            # Direction vectorsã®åŸºæœ¬æ¤œè¨¼
            if self.direction_personal is None or self.direction_neutral is None:
                error_msg = "âŒ CRITICAL: Base direction vectors not loaded"
                logger.error(error_msg)
                raise RuntimeError(error_msg + f" (user_id: {user_id})")
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆåŸ‹ã‚è¾¼ã¿ã‚’å¿…ãšç”Ÿæˆï¼ˆå”èª¿æ©Ÿèƒ½ã®å‰æï¼‰
            prompt_embedding = self._extract_context_embedding(prompt)
            
            # å”èª¿æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
            if user_id not in self.user_contexts:
                # æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼šãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ–¹å‘ã‚’ä½¿ç”¨
                logger.info(f"New user {user_id}, using default directions")
                collaborative_directions = {
                    'personal': torch.tensor(self.direction_personal, dtype=torch.float32),
                    'neutral': torch.tensor(self.direction_neutral, dtype=torch.float32)
                }
            else:
                # æ—¢å­˜ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼šå”èª¿ãƒ—ãƒ¼ãƒ«ã‹ã‚‰æ–¹å‘ã‚’å–å¾—
                user_context = self.user_contexts[user_id]
                
                # Direction poolã®å”èª¿æ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯
                if not hasattr(self.direction_pool, 'get_collaborative_directions'):
                    error_msg = "âŒ CRITICAL: Direction pool does not support collaborative directions generation"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg + f" (user_id: {user_id})")
                
                try:
                    pool_directions = self.direction_pool.get_collaborative_directions(
                        user_context, prompt_embedding
                    )
                    
                    # ãƒ—ãƒ¼ãƒ«çµæœã®æ¤œè¨¼
                    if not isinstance(pool_directions, dict) or 'personal' not in pool_directions or 'neutral' not in pool_directions:
                        error_msg = "âŒ CRITICAL: Invalid collaborative directions from pool"
                        logger.error(error_msg)
                        raise RuntimeError(error_msg + f" (user_id: {user_id}, pool_result: {type(pool_directions)})")
                    
                    collaborative_directions = {
                        'personal': torch.tensor(pool_directions['personal'], dtype=torch.float32),
                        'neutral': torch.tensor(pool_directions['neutral'], dtype=torch.float32)
                    }
                    
                except Exception as e:
                    error_msg = f"âŒ CRITICAL: Failed to get collaborative directions from pool: {e}"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg + f" (user_id: {user_id})")
            
            # ç”Ÿæˆã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã®æ¤œè¨¼
            for key, vector in collaborative_directions.items():
                if not isinstance(vector, torch.Tensor):
                    error_msg = f"âŒ CRITICAL: {key} direction is not a torch.Tensor: {type(vector)}"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg + f" (user_id: {user_id})")
                
                if vector.shape[0] == 0:
                    error_msg = f"âŒ CRITICAL: {key} direction has zero length"
                    logger.error(error_msg)
                    raise RuntimeError(error_msg + f" (user_id: {user_id})")
            
            # çµ±è¨ˆæ›´æ–°
            self.collaboration_stats['collaborative_directions_generated'] += 1
            
            debug_msg = f"ğŸ¤ Generated collaborative directions for user {user_id}: P={collaborative_directions['personal'].shape}, N={collaborative_directions['neutral'].shape}"
            logger.info(debug_msg)
            print(debug_msg)
            
            return collaborative_directions
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Collaborative direction generation failed: {e}"
            logger.error(error_msg)
            print(error_msg)
            raise e
    
    def generate_with_collaborative_chameleon(self, prompt: str, user_id: str,
                                            alpha_personal: float = None, alpha_neutral: float = None,
                                            target_layers: List[str] = None, max_length: int = 128) -> str:
        """
        å”èª¿çš„Chameleonç·¨é›†ã‚’é©ç”¨ã—ãŸç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç„¡åŠ¹åŒ–ç‰ˆï¼‰
        
        Args:
            prompt: å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            user_id: ãƒ¦ãƒ¼ã‚¶ãƒ¼ID
            alpha_personal: ãƒ‘ãƒ¼ã‚½ãƒŠãƒ«æ–¹å‘å¼·åº¦ (Noneã§configã‹ã‚‰èª­ã¿è¾¼ã¿)
            alpha_neutral: ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«æ–¹å‘å¼·åº¦ (Noneã§configã‹ã‚‰èª­ã¿è¾¼ã¿)
            target_layers: ç·¨é›†å¯¾è±¡ãƒ¬ã‚¤ãƒ¤ãƒ¼ (Noneã§configã‹ã‚‰èª­ã¿è¾¼ã¿)
            max_length: æœ€å¤§ç”Ÿæˆé•·
            
        Returns:
            ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        
        Raises:
            ValueError: å”èª¿æ©Ÿèƒ½ãŒåˆæœŸåŒ–ã§ããªã„å ´åˆ
        """
        # å”èª¿æ©Ÿèƒ½åˆæœŸåŒ–ç¢ºèª
        if not self.use_collaboration:
            error_msg = "âŒ CRITICAL: Collaborative Chameleon requested but collaboration disabled"
            logger.error(error_msg)
            print(error_msg)
            print("ğŸ”§ Enable collaboration: set use_collaboration=True in constructor")
            raise ValueError("Collaboration not enabled - cannot perform collaborative editing")
        
        # CFSã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç¢ºèª
        if not hasattr(self, 'direction_pool') or self.direction_pool is None:
            error_msg = "âŒ CRITICAL: Collaborative direction pool not initialized"
            logger.error(error_msg)
            print(error_msg)
            print("ğŸ”§ Ensure collaboration components were initialized correctly")
            raise ValueError("Direction pool not available - collaboration system not ready")
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if alpha_personal is None and hasattr(self, '_config_alpha_personal'):
            alpha_personal = self._config_alpha_personal
        if alpha_neutral is None and hasattr(self, '_config_alpha_general'):
            alpha_neutral = self._config_alpha_general
        if target_layers is None and hasattr(self, '_config_target_layers'):
            target_layers = self._config_target_layers
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
        if alpha_personal is None:
            alpha_personal = 0.3
        if alpha_neutral is None:
            alpha_neutral = -0.05
        if target_layers is None:
            target_layers = ["model.layers.14.mlp"]
            
        debug_msg = f"ğŸ¤ CFS-Chameleon parameters: user={user_id}, Î±_p={alpha_personal}, Î±_n={alpha_neutral}, max_length={max_length}, layers={target_layers}"
        logger.info(debug_msg)
        print(debug_msg)
        
        try:
            # å”èª¿çš„æ–¹å‘ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
            collaborative_directions = self._generate_collaborative_directions(user_id, prompt)
            
            # å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯ã‚’ç™»éŒ²
            self._register_collaborative_hooks(target_layers, collaborative_directions, alpha_personal, alpha_neutral, user_id)
            
            # ç”Ÿæˆå®Ÿè¡Œ
            result = self._execute_chameleon_generation(prompt, alpha_personal, alpha_neutral, target_layers, max_length)
            
            success_msg = f"âœ… Collaborative Chameleon editing completed: {len(result)} chars generated"
            logger.info(success_msg)
            print(success_msg)
            return result
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Collaborative Chameleon generation failed: {e}"
            logger.error(error_msg)
            print(error_msg)
            print("ğŸ”§ Debug information:")
            print(f"   - Collaboration enabled: {self.use_collaboration}")
            print(f"   - Direction pool available: {hasattr(self, 'direction_pool') and self.direction_pool is not None}")
            print(f"   - User ID provided: {user_id}")
            raise e
                
        finally:
            # ãƒ•ãƒƒã‚¯ã‚’å‰Šé™¤
            self._remove_direction_hooks()
    
    def _register_collaborative_hooks(self, target_layers: List[str], collaborative_directions: Dict[str, torch.Tensor],
                                    alpha_personal: float, alpha_neutral: float, user_id: str):
        """å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯ã®ç™»éŒ²"""
        def collaborative_editing_hook(module, input, output):
            """å”èª¿çš„ç·¨é›†ãƒ•ãƒƒã‚¯"""
            try:
                if isinstance(output, tuple):
                    output_tensor = output[0]
                    additional_outputs = output[1:]
                else:
                    output_tensor = output
                    additional_outputs = ()
                
                # å”èª¿çš„åŸ‹ã‚è¾¼ã¿ç·¨é›†ã‚’é©ç”¨
                edited_output = self.collaborative_edit_embedding(
                    output_tensor, user_id, "", alpha_personal, alpha_neutral
                )
                
                if additional_outputs:
                    return (edited_output,) + additional_outputs
                else:
                    return edited_output
                    
            except Exception as e:
                logger.warning(f"Collaborative hook error: {e}")
                return output
        
        # ãƒ•ãƒƒã‚¯ç™»éŒ²
        if hasattr(self, 'editing_hooks'):
            for layer_name in target_layers:
                try:
                    if hasattr(self, '_get_layer_by_name'):
                        layer = self._get_layer_by_name(layer_name)
                        hook = layer.register_forward_hook(collaborative_editing_hook)
                        self.editing_hooks.append(hook)
                        logger.info(f"Registered collaborative hook on {layer_name}")
                except:
                    logger.warning(f"Failed to register collaborative hook on {layer_name}")
    
    def _fallback_generation(self, prompt: str, max_length: int) -> str:
        """âŒ DEPRECATED: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆã¯å»ƒæ­¢ - RuntimeError ã‚’æŠ•ã’ã‚‹"""
        error_msg = "âŒ CRITICAL: Fallback generation attempted - this indicates a system failure"
        logger.error(error_msg)
        raise RuntimeError(error_msg + f" (prompt: '{prompt[:50]}...', max_length: {max_length})")
    
    def train_collaboration_components(self, training_data: List[Dict[str, Any]], 
                                     epochs: int = 10) -> Dict[str, float]:
        """
        å”èª¿ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®è»½é‡å­¦ç¿’
        
        Args:
            training_data: å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ (user_id, context, effective_directions)
            epochs: ã‚¨ãƒãƒƒã‚¯æ•°
            
        Returns:
            å­¦ç¿’çµ±è¨ˆ
        """
        if not self.use_collaboration or self.gate_network is None:
            logger.warning("Learning components not available")
            return {}
        
        logger.info(f"Starting collaboration training ({epochs} epochs, {len(training_data)} samples)")
        
        training_stats = {'losses': [], 'accuracies': []}
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            correct_predictions = 0
            total_predictions = 0
            
            for batch_data in training_data:
                user_id = batch_data['user_id']
                context = batch_data['context']
                effective_directions = batch_data['effective_directions']  # ãƒã‚¤ãƒŠãƒªãƒ©ãƒ™ãƒ«
                
                if user_id not in self.user_contexts:
                    continue
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼åŸ‹ã‚è¾¼ã¿å–å¾—
                user_embedding = torch.tensor(
                    self.user_contexts[user_id].preference_vector,
                    dtype=torch.float32
                ).unsqueeze(0)
                
                # ã‚²ãƒ¼ãƒˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯äºˆæ¸¬
                predicted_gates = self.gate_network(user_embedding)
                
                # æå¤±è¨ˆç®—
                target_gates = torch.tensor(effective_directions, dtype=torch.float32).unsqueeze(0)
                loss = nn.BCELoss()(predicted_gates, target_gates)
                
                # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
                self.gate_optimizer.zero_grad()
                loss.backward()
                self.gate_optimizer.step()
                
                # çµ±è¨ˆæ›´æ–°
                epoch_loss += loss.item()
                predictions = (predicted_gates > 0.5).float()
                correct_predictions += (predictions == target_gates).sum().item()
                total_predictions += target_gates.numel()
            
            # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆ
            avg_loss = epoch_loss / len(training_data)
            accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0.0
            
            training_stats['losses'].append(avg_loss)
            training_stats['accuracies'].append(accuracy)
            
            if (epoch + 1) % 5 == 0:
                logger.info(f"Epoch {epoch+1}/{epochs}: Loss={avg_loss:.4f}, Acc={accuracy:.4f}")
        
        logger.info("Collaboration training completed")
        return {
            'final_loss': training_stats['losses'][-1],
            'final_accuracy': training_stats['accuracies'][-1],
            'improvement': training_stats['accuracies'][-1] - training_stats['accuracies'][0]
        }
    
    def get_collaboration_statistics(self) -> Dict[str, Any]:
        """å”èª¿æ©Ÿèƒ½ã®çµ±è¨ˆæƒ…å ±å–å¾—"""
        if not self.use_collaboration:
            return {'collaboration_enabled': False}
        
        pool_stats = self.direction_pool.get_statistics()
        
        return {
            'collaboration_enabled': True,
            'pool_statistics': pool_stats,
            'collaboration_stats': self.collaboration_stats,
            'user_count': len(self.user_contexts),
            'learning_enabled': self.gate_network is not None
        }
    
    def save_collaboration_state(self, filepath: str):
        """å”èª¿çŠ¶æ…‹ã®ä¿å­˜"""
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - nothing to save")
            return
        
        # ãƒ—ãƒ¼ãƒ«çŠ¶æ…‹ä¿å­˜
        pool_path = filepath.replace('.json', '_pool.json')
        self.direction_pool.save_pool(pool_path)
        
        # å…¨ä½“çŠ¶æ…‹ä¿å­˜
        state_data = {
            'config': self.collaboration_config,
            'stats': self.collaboration_stats,
            'user_contexts_count': len(self.user_contexts),
            'timestamp': time.time()
        }
        
        with open(filepath, 'w') as f:
            json.dump(state_data, f, indent=2)
        
        logger.info(f"Collaboration state saved to {filepath}")
    
    def load_collaboration_state(self, filepath: str):
        """å”èª¿çŠ¶æ…‹ã®èª­ã¿è¾¼ã¿"""
        if not self.use_collaboration:
            logger.warning("Collaboration disabled - cannot load state")
            return
        
        try:
            # ãƒ—ãƒ¼ãƒ«çŠ¶æ…‹èª­ã¿è¾¼ã¿
            pool_path = filepath.replace('.json', '_pool.json')
            if Path(pool_path).exists():
                self.direction_pool.load_pool(pool_path)
            
            # å…¨ä½“çŠ¶æ…‹èª­ã¿è¾¼ã¿
            with open(filepath, 'r') as f:
                state_data = json.load(f)
            
            self.collaboration_stats = state_data.get('stats', {})
            
            logger.info(f"Collaboration state loaded from {filepath}")
            
        except Exception as e:
            logger.error(f"Failed to load collaboration state: {e}")

# ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
ChameleonCFS = CollaborativeChameleonEditor

if __name__ == "__main__":
    # çµ±åˆãƒ†ã‚¹ãƒˆ
    print("ğŸ¦ Chameleon-CFS Integration Test")
    
    # å”èª¿æ©Ÿèƒ½ç„¡åŠ¹ï¼ˆæ—¢å­˜äº’æ›ï¼‰
    editor_legacy = CollaborativeChameleonEditor(use_collaboration=False)
    print(f"Legacy mode: {not editor_legacy.use_collaboration}")
    
    # å”èª¿æ©Ÿèƒ½æœ‰åŠ¹
    editor_collaborative = CollaborativeChameleonEditor(
        use_collaboration=True,
        collaboration_config={'enable_learning': True}
    )
    print(f"Collaborative mode: {editor_collaborative.use_collaboration}")
    
    # çµ±è¨ˆç¢ºèª
    stats = editor_collaborative.get_collaboration_statistics()
    print(f"Collaboration stats: {stats['collaboration_enabled']}")
    
    print("âœ… Chameleon-CFS integration test completed")