#!/usr/bin/env python3
"""
CFS-Chameleon End-to-End ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3ãƒ¦ãƒ¼ã‚¶ãƒ¼Ã—å„3ã‚µãƒ³ãƒ—ãƒ«ã§å®Œå…¨å‹•ä½œæ¤œè¨¼
ä¾‹å¤–ç™ºç”Ÿæ™‚ã¯å¿…ãšãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆ
"""

import sys
import os
import time
import json
import logging
from pathlib import Path
from typing import List, Dict, Any

sys.path.append('/home/nakata/master_thesis/rango')
os.chdir('/home/nakata/master_thesis/rango')

print('ğŸ¯ CFS-CHAMELEON END-TO-END DEMO')
print('='*80)
print('ğŸ”§ ãƒ‡ãƒ¢è¨­è¨ˆ:')
print('   â€¢ 3ãƒ¦ãƒ¼ã‚¶ãƒ¼ Ã— å„3ã‚µãƒ³ãƒ—ãƒ« = 9å›ã®ç”Ÿæˆãƒ†ã‚¹ãƒˆ')
print('   â€¢ å…¨ä¾‹å¤–ã§ãƒ†ã‚¹ãƒˆå¤±æ•— (Silent failureç¦æ­¢)')
print('   â€¢ å”èª¿æ©Ÿèƒ½ãƒ»çµ±è¨ˆãƒ»å“è³ªã™ã¹ã¦æ¤œè¨¼')
print('   â€¢ CFS vs Legacy vs Baseline 3ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒ')
print('='*80)

from chameleon_cfs_integrator import CollaborativeChameleonEditor

class E2EDemoRunner:
    """End-to-End ãƒ‡ãƒ¢å®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.test_users = ["user_101", "user_202", "user_303"]
        self.samples_per_user = 3
        self.total_samples = len(self.test_users) * self.samples_per_user
        self.results = {}
        self.start_time = time.time()
    
    def load_test_data(self) -> List[Dict[str, Any]]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        try:
            data_path = Path("chameleon_prime_personalization/data/raw/LaMP-2/merged.json")
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # 9ã‚µãƒ³ãƒ—ãƒ«å–å¾—
            test_samples = data[:self.total_samples]
            
            if len(test_samples) < self.total_samples:
                raise RuntimeError(f"âŒ CRITICAL: Not enough test data: {len(test_samples)} < {self.total_samples}")
            
            print(f"âœ… Test data loaded: {len(test_samples)} samples")
            return test_samples
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: Failed to load test data: {e}"
            print(error_msg)
            raise RuntimeError(error_msg)
    
    def test_cfs_chameleon_system(self, test_samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """CFS-Chameleonã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ¦ Testing CFS-Chameleon System...")
        
        try:
            # CFS-ChameleonåˆæœŸåŒ–
            editor = CollaborativeChameleonEditor(
                use_collaboration=True,
                config_path='cfs_config.yaml'
            )
            
            print("âœ… CFS-Chameleon initialized successfully")
            
            results = []
            user_idx = 0
            sample_idx = 0
            
            for i, sample in enumerate(test_samples):
                current_user = self.test_users[user_idx]
                user_sample_idx = sample_idx + 1
                
                print(f"\n   ğŸ”„ Sample {i+1}/{self.total_samples} - User: {current_user} (Sample {user_sample_idx}/3)")
                
                input_text = sample.get('input', '')[:150]  # é©åº¦ãªé•·ã•ã«åˆ¶é™
                expected = sample.get('output', 'N/A')
                
                sample_start = time.time()
                
                try:
                    # CFS-Chameleonç”Ÿæˆå®Ÿè¡Œ
                    generated = editor.generate_with_collaborative_chameleon(
                        prompt=input_text,
                        user_id=current_user,
                        alpha_personal=0.15,  # æ§ãˆã‚ãªç·¨é›†å¼·åº¦
                        alpha_neutral=-0.03,
                        max_length=120
                    )
                    
                    generation_time = time.time() - sample_start
                    
                    # ç”Ÿæˆå“è³ªæ¤œè¨¼
                    if not generated or len(generated.strip()) == 0:
                        raise RuntimeError(f"âŒ CRITICAL: Empty generation for user {current_user}")
                    
                    if len(generated) < 10:
                        raise RuntimeError(f"âŒ CRITICAL: Too short generation ({len(generated)} chars) for user {current_user}")
                    
                    results.append({
                        'sample_id': i + 1,
                        'user_id': current_user,
                        'user_sample': user_sample_idx,
                        'input': input_text[:80] + "..." if len(input_text) > 80 else input_text,
                        'expected': expected,
                        'generated': generated[:100] + "..." if len(generated) > 100 else generated,
                        'full_generated_length': len(generated),
                        'generation_time': generation_time,
                        'status': 'success'
                    })
                    
                    print(f"     âœ… SUCCESS: {len(generated)} chars in {generation_time:.2f}s")
                    print(f"     ğŸ“ Output: \"{generated[:60]}...\"")
                    
                except Exception as e:
                    # ä¾‹å¤–ç™ºç”Ÿ = E2Eãƒ†ã‚¹ãƒˆå¤±æ•—
                    error_msg = f"âŒ CRITICAL E2E FAILURE: Sample {i+1} (User {current_user}): {e}"
                    print(f"     {error_msg}")
                    raise RuntimeError(error_msg)
                
                # æ¬¡ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ã‚µãƒ³ãƒ—ãƒ«ã«é€²ã‚€
                sample_idx += 1
                if sample_idx >= self.samples_per_user:
                    sample_idx = 0
                    user_idx += 1
            
            # å”èª¿æ©Ÿèƒ½çµ±è¨ˆç¢ºèª
            try:
                stats = editor.get_collaboration_statistics()
                collab_stats = stats.get('collaboration_stats', {})
                
                directions_generated = collab_stats.get('collaborative_directions_generated', 0)
                if directions_generated == 0:
                    raise RuntimeError("âŒ CRITICAL: No collaborative directions were generated")
                
                print(f"\nğŸ“Š CFS-Chameleon Statistics:")
                print(f"   â€¢ Collaborative Directions Generated: {directions_generated}")
                print(f"   â€¢ Total Collaborations: {collab_stats.get('total_collaborations', 0)}")
                print(f"   â€¢ Privacy Applications: {collab_stats.get('privacy_applications', 0)}")
                
            except Exception as e:
                error_msg = f"âŒ CRITICAL: Failed to get collaboration statistics: {e}"
                print(error_msg)
                raise RuntimeError(error_msg)
            
            return {
                'system_name': 'CFS-Chameleon',
                'results': results,
                'status': 'completed',
                'collaboration_stats': collab_stats
            }
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: CFS-Chameleon system test failed: {e}"
            print(error_msg)
            raise RuntimeError(error_msg)
    
    def test_baseline_comparison(self, test_samples: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚·ã‚¹ãƒ†ãƒ æ¯”è¼ƒãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ“Š Testing Baseline System for Comparison...")
        
        try:
            from chameleon_evaluator import ChameleonEvaluator
            evaluator = ChameleonEvaluator('config.yaml')
            
            baseline_results = []
            
            # 3ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§ã‚¯ã‚¤ãƒƒã‚¯æ¯”è¼ƒ
            for i, sample in enumerate(test_samples[:3]):
                input_text = sample.get('input', '')[:150]
                expected = sample.get('output', 'N/A')
                
                sample_start = time.time()
                
                try:
                    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ç”Ÿæˆï¼ˆç·¨é›†ãªã—ï¼‰
                    inputs = evaluator.tokenizer(input_text, return_tensors='pt', truncation=True, max_length=100)
                    inputs = {k: v.to(evaluator.device) for k, v in inputs.items()}
                    
                    with evaluator.model.torch.no_grad():
                        outputs = evaluator.model.generate(
                            **inputs,
                            max_length=inputs['input_ids'].shape[1] + 60,
                            do_sample=True,
                            temperature=0.7,
                            top_p=0.9,
                            pad_token_id=evaluator.tokenizer.eos_token_id
                        )
                    
                    generated = evaluator.tokenizer.decode(outputs[0], skip_special_tokens=True)
                    generated = generated[len(input_text):].strip()  # å…¥åŠ›éƒ¨åˆ†ã‚’é™¤å»
                    
                    generation_time = time.time() - sample_start
                    
                    baseline_results.append({
                        'sample_id': i + 1,
                        'input': input_text[:80] + "..." if len(input_text) > 80 else input_text,
                        'generated': generated[:100] + "..." if len(generated) > 100 else generated,
                        'generation_time': generation_time,
                        'status': 'success'
                    })
                    
                    print(f"     âœ… Baseline Sample {i+1}: {len(generated)} chars in {generation_time:.2f}s")
                    
                except Exception as e:
                    print(f"     âš ï¸ Baseline Sample {i+1} failed: {e}")
                    baseline_results.append({
                        'sample_id': i + 1,
                        'status': 'failed',
                        'error': str(e)
                    })
            
            return {
                'system_name': 'Baseline',
                'results': baseline_results,
                'status': 'completed'
            }
            
        except Exception as e:
            print(f"     âš ï¸ Baseline system test failed: {e}")
            return {
                'system_name': 'Baseline',
                'results': [],
                'status': 'failed',
                'error': str(e)
            }
    
    def analyze_e2e_results(self, cfs_results: Dict[str, Any], baseline_results: Dict[str, Any]):
        """E2Eçµæœåˆ†æ"""
        print("\n" + "="*80)
        print("ğŸ“Š END-TO-END DEMO ANALYSIS")
        print("="*80)
        
        # CFS-Chameleonçµæœåˆ†æ
        print(f"\nğŸ¦ CFS-CHAMELEON PERFORMANCE:")
        if cfs_results['status'] == 'completed':
            cfs_samples = cfs_results['results']
            cfs_success = len([r for r in cfs_samples if r['status'] == 'success'])
            cfs_success_rate = (cfs_success / len(cfs_samples) * 100) if cfs_samples else 0
            
            if cfs_success > 0:
                avg_time = sum(r['generation_time'] for r in cfs_samples if r['status'] == 'success') / cfs_success
                avg_length = sum(r['full_generated_length'] for r in cfs_samples if r['status'] == 'success') / cfs_success
            else:
                avg_time = 0
                avg_length = 0
            
            print(f"   â€¢ Success Rate: {cfs_success_rate:.1f}% ({cfs_success}/{len(cfs_samples)})")
            print(f"   â€¢ Average Generation Time: {avg_time:.2f}s")
            print(f"   â€¢ Average Output Length: {avg_length:.0f} chars")
            
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ¥åˆ†æ
            user_stats = {}
            for result in cfs_samples:
                if result['status'] == 'success':
                    user = result['user_id']
                    if user not in user_stats:
                        user_stats[user] = []
                    user_stats[user].append(result)
            
            print(f"   â€¢ User Coverage: {len(user_stats)}/{len(self.test_users)} users tested")
            for user, samples in user_stats.items():
                print(f"     - {user}: {len(samples)} successful samples")
            
            # å”èª¿æ©Ÿèƒ½çµ±è¨ˆ
            if 'collaboration_stats' in cfs_results:
                stats = cfs_results['collaboration_stats']
                print(f"   â€¢ Collaborative Directions Generated: {stats.get('collaborative_directions_generated', 0)}")
                print(f"   â€¢ Total Collaborations: {stats.get('total_collaborations', 0)}")
        else:
            print(f"   âŒ CFS-Chameleon failed: {cfs_results.get('error', 'Unknown error')}")
            cfs_success_rate = 0
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµæœåˆ†æ
        print(f"\nğŸ“Š BASELINE COMPARISON:")
        if baseline_results['status'] == 'completed':
            baseline_samples = baseline_results['results']
            baseline_success = len([r for r in baseline_samples if r['status'] == 'success'])
            baseline_success_rate = (baseline_success / len(baseline_samples) * 100) if baseline_samples else 0
            
            print(f"   â€¢ Success Rate: {baseline_success_rate:.1f}% ({baseline_success}/{len(baseline_samples)})")
            
            if baseline_success > 0:
                baseline_avg_time = sum(r['generation_time'] for r in baseline_samples if r['status'] == 'success') / baseline_success
                print(f"   â€¢ Average Generation Time: {baseline_avg_time:.2f}s")
        else:
            print(f"   âš ï¸ Baseline failed: {baseline_results.get('error', 'Unknown error')}")
            baseline_success_rate = 0
        
        # ç·åˆè©•ä¾¡
        print(f"\nğŸ¯ END-TO-END DEMO VERDICT:")
        
        if cfs_success_rate == 100:
            e2e_status = "ğŸ† EXCELLENT: Complete E2E success!"
            recommendation = "CFS-Chameleon ready for production deployment"
        elif cfs_success_rate >= 80:
            e2e_status = "âœ… GOOD: Strong E2E performance"
            recommendation = "CFS-Chameleon suitable for pilot deployment"
        elif cfs_success_rate >= 60:
            e2e_status = "âš ï¸ MIXED: Partial E2E success"
            recommendation = "CFS-Chameleon needs improvement before deployment"
        else:
            e2e_status = "âŒ FAILED: E2E test failed"
            recommendation = "CFS-Chameleon requires significant fixes"
        
        print(f"   â€¢ Status: {e2e_status}")
        print(f"   â€¢ Recommendation: {recommendation}")
        
        # æ¯”è¼ƒåˆ†æ
        if baseline_success_rate > 0:
            if cfs_success_rate > baseline_success_rate:
                comparison = f"âœ… CFS-Chameleon outperforms baseline (+{cfs_success_rate - baseline_success_rate:.1f}%)"
            elif cfs_success_rate == baseline_success_rate:
                comparison = f"â¡ï¸ CFS-Chameleon matches baseline performance"
            else:
                comparison = f"âŒ CFS-Chameleon underperforms baseline ({cfs_success_rate - baseline_success_rate:.1f}%)"
        else:
            comparison = f"ğŸ† CFS-Chameleon succeeds where baseline fails"
        
        print(f"   â€¢ Comparison: {comparison}")
        
        return cfs_success_rate >= 80  # E2E success criteria
    
    def run_full_demo(self) -> bool:
        """å®Œå…¨E2Eãƒ‡ãƒ¢å®Ÿè¡Œ"""
        print("\nğŸš€ Starting Full End-to-End Demo...")
        
        try:
            # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            test_samples = self.load_test_data()
            
            # 2. CFS-Chameleonã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
            cfs_results = self.test_cfs_chameleon_system(test_samples)
            
            # 3. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
            baseline_results = self.test_baseline_comparison(test_samples)
            
            # 4. çµæœåˆ†æ
            success = self.analyze_e2e_results(cfs_results, baseline_results)
            
            total_time = time.time() - self.start_time
            
            print(f"\n" + "="*80)
            print("âœ¨ END-TO-END DEMO COMPLETED!")
            print("="*80)
            print(f"ğŸ Total Demo Time: {total_time:.1f}s ({total_time/60:.1f}min)")
            print(f"ğŸ“‹ Demo Success: {'âœ… PASSED' if success else 'âŒ FAILED'}")
            
            return success
            
        except Exception as e:
            error_msg = f"âŒ CRITICAL: E2E demo failed with exception: {e}"
            print(f"\n{error_msg}")
            
            total_time = time.time() - self.start_time
            print(f"\n" + "="*80)
            print("ğŸ’¥ END-TO-END DEMO FAILED!")
            print("="*80)
            print(f"ğŸ Demo Time Before Failure: {total_time:.1f}s")
            print(f"ğŸš¨ Exception: {str(e)[:200]}...")
            
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("\nğŸš€ Initializing End-to-End Demo...")
    
    # GPUç¢ºèª
    import torch
    if torch.cuda.is_available():
        print(f"âœ… GPU Available: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸ Running on CPU")
    
    # E2Eãƒ‡ãƒ¢å®Ÿè¡Œ
    demo_runner = E2EDemoRunner()
    
    try:
        success = demo_runner.run_full_demo()
        
        if success:
            print("\nğŸ‰ CFS-Chameleon E2E Demo: SUCCESSFUL!")
            print("ğŸš€ System ready for production benchmarking!")
        else:
            print("\nğŸ”§ CFS-Chameleon E2E Demo: REQUIRES IMPROVEMENT")
            print("âš ï¸ Address issues before production deployment")
        
        return success
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Demo interrupted by user")
        return False
    except Exception as e:
        print(f"\nğŸ’¥ Demo crashed with exception: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)